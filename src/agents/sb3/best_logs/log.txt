Logging to logs
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 40.9      |
|    ep_rew_mean     | 27.965553 |
| time/              |           |
|    fps             | 64        |
|    iterations      | 1         |
|    time_elapsed    | 63        |
|    total_timesteps | 4096      |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 48.8        |
|    ep_rew_mean          | 34.004574   |
| time/                   |             |
|    fps                  | 63          |
|    iterations           | 2           |
|    time_elapsed         | 129         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.013969418 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.257      |
|    explained_variance   | -0.1        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.485       |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00989    |
|    std                  | 0.25        |
|    value_loss           | 0.635       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 953         |
|    mean_ep_length       | 33          |
|    mean_reward          | 2.35e+03    |
|    speed                | 0.0407      |
|    speed_penalty        | 0.236       |
| time/                   |             |
|    total timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.015719239 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.257      |
|    explained_variance   | 0.0925      |
|    learning_rate        | 0.0001      |
|    loss                 | 0.128       |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.25        |
|    value_loss           | 0.237       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 56.9      |
|    ep_rew_mean     | 40.110653 |
| time/              |           |
|    fps             | 62        |
|    iterations      | 3         |
|    time_elapsed    | 197       |
|    total_timesteps | 12288     |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 56.9        |
|    ep_rew_mean          | 40.017338   |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 4           |
|    time_elapsed         | 265         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.011933504 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.268      |
|    explained_variance   | 0.215       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0825      |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00866    |
|    std                  | 0.25        |
|    value_loss           | 0.238       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 507         |
|    mean_ep_length       | 31          |
|    mean_reward          | 2.23e+03    |
|    speed                | 0.156       |
|    speed_penalty        | 0.0805      |
| time/                   |             |
|    total timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.014893324 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.255      |
|    explained_variance   | 0.249       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.103       |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0142     |
|    std                  | 0.249       |
|    value_loss           | 0.246       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 49.3      |
|    ep_rew_mean     | 35.036755 |
| time/              |           |
|    fps             | 61        |
|    iterations      | 5         |
|    time_elapsed    | 334       |
|    total_timesteps | 20480     |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 52.3        |
|    ep_rew_mean          | 36.802853   |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 6           |
|    time_elapsed         | 402         |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.013423389 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.218      |
|    explained_variance   | 0.254       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0901      |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.248       |
|    value_loss           | 0.255       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 51          |
|    ep_rew_mean          | 37.014187   |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 7           |
|    time_elapsed         | 468         |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.012818728 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.194      |
|    explained_variance   | 0.319       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.137       |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00715    |
|    std                  | 0.248       |
|    value_loss           | 0.253       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 409         |
|    mean_ep_length       | 111         |
|    mean_reward          | 8.13e+03    |
|    speed                | 0.595       |
|    speed_penalty        | 0.107       |
| time/                   |             |
|    total timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.015923582 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.175      |
|    explained_variance   | 0.298       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.173       |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0151     |
|    std                  | 0.247       |
|    value_loss           | 0.266       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 57       |
|    ep_rew_mean     | 42.15275 |
| time/              |          |
|    fps             | 60       |
|    iterations      | 8        |
|    time_elapsed    | 543      |
|    total_timesteps | 32768    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 56.4        |
|    ep_rew_mean          | 41.77825    |
| time/                   |             |
|    fps                  | 60          |
|    iterations           | 9           |
|    time_elapsed         | 608         |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.015314596 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.159      |
|    explained_variance   | 0.361       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0917      |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0149     |
|    std                  | 0.247       |
|    value_loss           | 0.255       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 372         |
|    mean_ep_length       | 152         |
|    mean_reward          | 1.12e+04    |
|    speed                | 0.731       |
|    speed_penalty        | 0.0553      |
| time/                   |             |
|    total timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.014391829 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.141      |
|    explained_variance   | 0.294       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.138       |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.246       |
|    value_loss           | 0.275       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 56.8      |
|    ep_rew_mean     | 42.219048 |
| time/              |           |
|    fps             | 59        |
|    iterations      | 10        |
|    time_elapsed    | 688       |
|    total_timesteps | 40960     |
----------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 62.4         |
|    ep_rew_mean          | 47.324135    |
| time/                   |              |
|    fps                  | 59           |
|    iterations           | 11           |
|    time_elapsed         | 755          |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 0.0150360195 |
|    clip_fraction        | 0.187        |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.116       |
|    explained_variance   | 0.344        |
|    learning_rate        | 0.0001       |
|    loss                 | 0.12         |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.0149      |
|    std                  | 0.245        |
|    value_loss           | 0.32         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 62.9        |
|    ep_rew_mean          | 46.96721    |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 12          |
|    time_elapsed         | 822         |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.013741043 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0929     |
|    explained_variance   | 0.385       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.129       |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.013      |
|    std                  | 0.245       |
|    value_loss           | 0.277       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 386         |
|    mean_ep_length       | 95          |
|    mean_reward          | 7.01e+03    |
|    speed                | 0.513       |
|    speed_penalty        | 0.0695      |
| time/                   |             |
|    total timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.013060633 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0753     |
|    explained_variance   | 0.391       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.107       |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.244       |
|    value_loss           | 0.289       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 68.8     |
|    ep_rew_mean     | 52.15323 |
| time/              |          |
|    fps             | 59       |
|    iterations      | 13       |
|    time_elapsed    | 896      |
|    total_timesteps | 53248    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 64          |
|    ep_rew_mean          | 48.405415   |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 14          |
|    time_elapsed         | 963         |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.014392228 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0724     |
|    explained_variance   | 0.422       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0719      |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.245       |
|    value_loss           | 0.268       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 363         |
|    mean_ep_length       | 153         |
|    mean_reward          | 1.13e+04    |
|    speed                | 0.772       |
|    speed_penalty        | 0.0618      |
| time/                   |             |
|    total timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.013544927 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0752     |
|    explained_variance   | 0.411       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.158       |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.244       |
|    value_loss           | 0.286       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 65.4      |
|    ep_rew_mean     | 49.364452 |
| time/              |           |
|    fps             | 59        |
|    iterations      | 15        |
|    time_elapsed    | 1039      |
|    total_timesteps | 61440     |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 59.8        |
|    ep_rew_mean          | 45.54338    |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 16          |
|    time_elapsed         | 1105        |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.015414459 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0616     |
|    explained_variance   | 0.458       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0992      |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.013      |
|    std                  | 0.244       |
|    value_loss           | 0.274       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 63.3        |
|    ep_rew_mean          | 47.8069     |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 17          |
|    time_elapsed         | 1171        |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.014702195 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0558     |
|    explained_variance   | 0.444       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0774      |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0109     |
|    std                  | 0.244       |
|    value_loss           | 0.273       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 336         |
|    mean_ep_length       | 218         |
|    mean_reward          | 1.61e+04    |
|    speed                | 1.04        |
|    speed_penalty        | 0.0832      |
| time/                   |             |
|    total timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.015609633 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0609     |
|    explained_variance   | 0.48        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0647      |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0123     |
|    std                  | 0.244       |
|    value_loss           | 0.26        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 64.8     |
|    ep_rew_mean     | 50.56567 |
| time/              |          |
|    fps             | 58       |
|    iterations      | 18       |
|    time_elapsed    | 1253     |
|    total_timesteps | 73728    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 61.6       |
|    ep_rew_mean          | 49.028763  |
| time/                   |            |
|    fps                  | 59         |
|    iterations           | 19         |
|    time_elapsed         | 1318       |
|    total_timesteps      | 77824      |
| train/                  |            |
|    approx_kl            | 0.01287458 |
|    clip_fraction        | 0.17       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0593    |
|    explained_variance   | 0.444      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0999     |
|    n_updates            | 180        |
|    policy_gradient_loss | -0.0116    |
|    std                  | 0.244      |
|    value_loss           | 0.275      |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 385         |
|    mean_ep_length       | 132         |
|    mean_reward          | 9.75e+03    |
|    speed                | 0.712       |
|    speed_penalty        | 0.0925      |
| time/                   |             |
|    total timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.016121253 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0439     |
|    explained_variance   | 0.436       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.127       |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.243       |
|    value_loss           | 0.288       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 66.3      |
|    ep_rew_mean     | 52.370903 |
| time/              |           |
|    fps             | 58        |
|    iterations      | 20        |
|    time_elapsed    | 1392      |
|    total_timesteps | 81920     |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 74.1        |
|    ep_rew_mean          | 57.306538   |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 21          |
|    time_elapsed         | 1456        |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.015024122 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0177     |
|    explained_variance   | 0.401       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.137       |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.242       |
|    value_loss           | 0.27        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 445         |
|    mean_ep_length       | 98          |
|    mean_reward          | 7.18e+03    |
|    speed                | 0.519       |
|    speed_penalty        | 0.169       |
| time/                   |             |
|    total timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.013807474 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.00535    |
|    explained_variance   | 0.477       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.13        |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.012      |
|    std                  | 0.242       |
|    value_loss           | 0.265       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 75.4      |
|    ep_rew_mean     | 59.456295 |
| time/              |           |
|    fps             | 58        |
|    iterations      | 22        |
|    time_elapsed    | 1528      |
|    total_timesteps | 90112     |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 78          |
|    ep_rew_mean          | 61.01043    |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 23          |
|    time_elapsed         | 1593        |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.014306298 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.00562     |
|    explained_variance   | 0.431       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.112       |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0112     |
|    std                  | 0.242       |
|    value_loss           | 0.278       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 76.8        |
|    ep_rew_mean          | 60.68599    |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 24          |
|    time_elapsed         | 1658        |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.014941089 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.0112      |
|    explained_variance   | 0.475       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0623      |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0119     |
|    std                  | 0.242       |
|    value_loss           | 0.255       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 279         |
|    mean_ep_length       | 266         |
|    mean_reward          | 1.97e+04    |
|    speed                | 1.12        |
|    speed_penalty        | 0.0594      |
| time/                   |             |
|    total timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.016384821 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.0184      |
|    explained_variance   | 0.477       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0966      |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0119     |
|    std                  | 0.242       |
|    value_loss           | 0.241       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 79        |
|    ep_rew_mean     | 63.474342 |
| time/              |           |
|    fps             | 58        |
|    iterations      | 25        |
|    time_elapsed    | 1742      |
|    total_timesteps | 102400    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 84.8        |
|    ep_rew_mean          | 68.09353    |
| time/                   |             |
|    fps                  | 58          |
|    iterations           | 26          |
|    time_elapsed         | 1805        |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.016339988 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.0343      |
|    explained_variance   | 0.472       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.161       |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.0134     |
|    std                  | 0.241       |
|    value_loss           | 0.26        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 449         |
|    mean_ep_length       | 62          |
|    mean_reward          | 4.52e+03    |
|    speed                | 0.31        |
|    speed_penalty        | 0.113       |
| time/                   |             |
|    total timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.016165052 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.0467      |
|    explained_variance   | 0.538       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.139       |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.012      |
|    std                  | 0.241       |
|    value_loss           | 0.214       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 89.2     |
|    ep_rew_mean     | 72.02418 |
| time/              |          |
|    fps             | 59       |
|    iterations      | 27       |
|    time_elapsed    | 1873     |
|    total_timesteps | 110592   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 87.3        |
|    ep_rew_mean          | 70.77411    |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 28          |
|    time_elapsed         | 1935        |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.012875065 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.0565      |
|    explained_variance   | 0.519       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.172       |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.00923    |
|    std                  | 0.24        |
|    value_loss           | 0.255       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 90.9        |
|    ep_rew_mean          | 74.90767    |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 29          |
|    time_elapsed         | 1996        |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.016311709 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.0765      |
|    explained_variance   | 0.495       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.114       |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0131     |
|    std                  | 0.24        |
|    value_loss           | 0.251       |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0          |
|    cost_of_transport    | 257        |
|    mean_ep_length       | 232        |
|    mean_reward          | 1.72e+04   |
|    speed                | 0.991      |
|    speed_penalty        | 0.033      |
| time/                   |            |
|    total timesteps      | 120000     |
| train/                  |            |
|    approx_kl            | 0.01532045 |
|    clip_fraction        | 0.19       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0908     |
|    explained_variance   | 0.525      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.115      |
|    n_updates            | 290        |
|    policy_gradient_loss | -0.0119    |
|    std                  | 0.24       |
|    value_loss           | 0.249      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 86.3     |
|    ep_rew_mean     | 70.4288  |
| time/              |          |
|    fps             | 59       |
|    iterations      | 30       |
|    time_elapsed    | 2075     |
|    total_timesteps | 122880   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 85.2        |
|    ep_rew_mean          | 69.73032    |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 31          |
|    time_elapsed         | 2138        |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.017479183 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.107       |
|    explained_variance   | 0.53        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0733      |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.0139     |
|    std                  | 0.239       |
|    value_loss           | 0.253       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 299         |
|    mean_ep_length       | 188         |
|    mean_reward          | 1.39e+04    |
|    speed                | 0.85        |
|    speed_penalty        | 0.0906      |
| time/                   |             |
|    total timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.015137705 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.114       |
|    explained_variance   | 0.514       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.162       |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.239       |
|    value_loss           | 0.265       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 92       |
|    ep_rew_mean     | 75.45227 |
| time/              |          |
|    fps             | 59       |
|    iterations      | 32       |
|    time_elapsed    | 2214     |
|    total_timesteps | 131072   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 89          |
|    ep_rew_mean          | 73.041756   |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 33          |
|    time_elapsed         | 2277        |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.016295686 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.108       |
|    explained_variance   | 0.571       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.062       |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.0126     |
|    std                  | 0.239       |
|    value_loss           | 0.227       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 82.9        |
|    ep_rew_mean          | 68.537895   |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 34          |
|    time_elapsed         | 2339        |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.015309066 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.107       |
|    explained_variance   | 0.58        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.117       |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0131     |
|    std                  | 0.239       |
|    value_loss           | 0.251       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 226         |
|    mean_ep_length       | 295         |
|    mean_reward          | 2.19e+04    |
|    speed                | 1.12        |
|    speed_penalty        | 0.0596      |
| time/                   |             |
|    total timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.015524143 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.0964      |
|    explained_variance   | 0.567       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.122       |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.24        |
|    value_loss           | 0.257       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 81.8     |
|    ep_rew_mean     | 67.4151  |
| time/              |          |
|    fps             | 59       |
|    iterations      | 35       |
|    time_elapsed    | 2421     |
|    total_timesteps | 143360   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 88.7       |
|    ep_rew_mean          | 73.68216   |
| time/                   |            |
|    fps                  | 59         |
|    iterations           | 36         |
|    time_elapsed         | 2482       |
|    total_timesteps      | 147456     |
| train/                  |            |
|    approx_kl            | 0.01688456 |
|    clip_fraction        | 0.2        |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.105      |
|    explained_variance   | 0.523      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.105      |
|    n_updates            | 350        |
|    policy_gradient_loss | -0.0128    |
|    std                  | 0.239      |
|    value_loss           | 0.254      |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 256         |
|    mean_ep_length       | 239         |
|    mean_reward          | 1.77e+04    |
|    speed                | 1.08        |
|    speed_penalty        | 0.0225      |
| time/                   |             |
|    total timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.015602815 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.125       |
|    explained_variance   | 0.554       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.137       |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0133     |
|    std                  | 0.238       |
|    value_loss           | 0.229       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 91.9     |
|    ep_rew_mean     | 77.47163 |
| time/              |          |
|    fps             | 59       |
|    iterations      | 37       |
|    time_elapsed    | 2559     |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 101         |
|    ep_rew_mean          | 85.555984   |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 38          |
|    time_elapsed         | 2620        |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.015593687 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.136       |
|    explained_variance   | 0.569       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.11        |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0122     |
|    std                  | 0.238       |
|    value_loss           | 0.247       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 104         |
|    ep_rew_mean          | 87.91697    |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 39          |
|    time_elapsed         | 2680        |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.017664429 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.147       |
|    explained_variance   | 0.661       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.083       |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.238       |
|    value_loss           | 0.17        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 241         |
|    mean_ep_length       | 230         |
|    mean_reward          | 1.71e+04    |
|    speed                | 0.978       |
|    speed_penalty        | 0.0165      |
| time/                   |             |
|    total timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.017821085 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.174       |
|    explained_variance   | 0.637       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0876      |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0139     |
|    std                  | 0.237       |
|    value_loss           | 0.217       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 106       |
|    ep_rew_mean     | 90.495125 |
| time/              |           |
|    fps             | 59        |
|    iterations      | 40        |
|    time_elapsed    | 2758      |
|    total_timesteps | 163840    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 105         |
|    ep_rew_mean          | 90.39663    |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 41          |
|    time_elapsed         | 2818        |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.016556337 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.195       |
|    explained_variance   | 0.584       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0821      |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.236       |
|    value_loss           | 0.231       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 232         |
|    mean_ep_length       | 242         |
|    mean_reward          | 1.8e+04     |
|    speed                | 1.05        |
|    speed_penalty        | 0.0261      |
| time/                   |             |
|    total timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.016812772 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.217       |
|    explained_variance   | 0.664       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0556      |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.236       |
|    value_loss           | 0.209       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 108      |
|    ep_rew_mean     | 92.4971  |
| time/              |          |
|    fps             | 59       |
|    iterations      | 42       |
|    time_elapsed    | 2895     |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 116         |
|    ep_rew_mean          | 99.15315    |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 43          |
|    time_elapsed         | 2956        |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.015138689 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.236       |
|    explained_variance   | 0.668       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0887      |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.00951    |
|    std                  | 0.235       |
|    value_loss           | 0.185       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 256         |
|    mean_ep_length       | 216         |
|    mean_reward          | 1.6e+04     |
|    speed                | 0.871       |
|    speed_penalty        | 0.0383      |
| time/                   |             |
|    total timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.016829362 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.248       |
|    explained_variance   | 0.695       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0866      |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.0123     |
|    std                  | 0.235       |
|    value_loss           | 0.181       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 108       |
|    ep_rew_mean     | 92.357216 |
| time/              |           |
|    fps             | 59        |
|    iterations      | 44        |
|    time_elapsed    | 3036      |
|    total_timesteps | 180224    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 105         |
|    ep_rew_mean          | 89.3124     |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 45          |
|    time_elapsed         | 3097        |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.016552728 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.245       |
|    explained_variance   | 0.634       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.109       |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.0116     |
|    std                  | 0.235       |
|    value_loss           | 0.246       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 101         |
|    ep_rew_mean          | 86.41834    |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 46          |
|    time_elapsed         | 3159        |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.014137702 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.255       |
|    explained_variance   | 0.712       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0413      |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.00887    |
|    std                  | 0.235       |
|    value_loss           | 0.162       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.000293    |
|    cost_of_transport    | 213         |
|    mean_ep_length       | 240         |
|    mean_reward          | 1.78e+04    |
|    speed                | 1.08        |
|    speed_penalty        | 0.0181      |
| time/                   |             |
|    total timesteps      | 190000      |
| train/                  |             |
|    approx_kl            | 0.016384711 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.281       |
|    explained_variance   | 0.646       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0744      |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.234       |
|    value_loss           | 0.219       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 108       |
|    ep_rew_mean     | 92.913574 |
| time/              |           |
|    fps             | 59        |
|    iterations      | 47        |
|    time_elapsed    | 3237      |
|    total_timesteps | 192512    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 105         |
|    ep_rew_mean          | 91.43268    |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 48          |
|    time_elapsed         | 3297        |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.016661514 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.28        |
|    explained_variance   | 0.584       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0789      |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.234       |
|    value_loss           | 0.198       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 3.95e-05    |
|    cost_of_transport    | 226         |
|    mean_ep_length       | 219         |
|    mean_reward          | 1.62e+04    |
|    speed                | 0.995       |
|    speed_penalty        | 0.0164      |
| time/                   |             |
|    total timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.018427264 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.264       |
|    explained_variance   | 0.645       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0956      |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.013      |
|    std                  | 0.235       |
|    value_loss           | 0.185       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 111      |
|    ep_rew_mean     | 96.17207 |
| time/              |          |
|    fps             | 59       |
|    iterations      | 49       |
|    time_elapsed    | 3371     |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 116         |
|    ep_rew_mean          | 101.358986  |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 50          |
|    time_elapsed         | 3430        |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.013885386 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.257       |
|    explained_variance   | 0.663       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0882      |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.00898    |
|    std                  | 0.235       |
|    value_loss           | 0.183       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 118         |
|    ep_rew_mean          | 102.91479   |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 51          |
|    time_elapsed         | 3489        |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.016165175 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.271       |
|    explained_variance   | 0.707       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0432      |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.234       |
|    value_loss           | 0.148       |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0          |
|    cost_of_transport    | 221        |
|    mean_ep_length       | 241        |
|    mean_reward          | 1.79e+04   |
|    speed                | 1.09       |
|    speed_penalty        | 0.0217     |
| time/                   |            |
|    total timesteps      | 210000     |
| train/                  |            |
|    approx_kl            | 0.01689034 |
|    clip_fraction        | 0.215      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.292      |
|    explained_variance   | 0.717      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0546     |
|    n_updates            | 510        |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.234      |
|    value_loss           | 0.163      |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 119       |
|    ep_rew_mean     | 104.62876 |
| time/              |           |
|    fps             | 59        |
|    iterations      | 52        |
|    time_elapsed    | 3563      |
|    total_timesteps | 212992    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 117         |
|    ep_rew_mean          | 102.78125   |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 53          |
|    time_elapsed         | 3622        |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.018403346 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.298       |
|    explained_variance   | 0.664       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0954      |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.234       |
|    value_loss           | 0.188       |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0          |
|    cost_of_transport    | 228        |
|    mean_ep_length       | 240        |
|    mean_reward          | 1.78e+04   |
|    speed                | 1.1        |
|    speed_penalty        | 0.0304     |
| time/                   |            |
|    total timesteps      | 220000     |
| train/                  |            |
|    approx_kl            | 0.01764414 |
|    clip_fraction        | 0.205      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.309      |
|    explained_variance   | 0.669      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0782     |
|    n_updates            | 530        |
|    policy_gradient_loss | -0.0115    |
|    std                  | 0.233      |
|    value_loss           | 0.187      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 112      |
|    ep_rew_mean     | 98.18451 |
| time/              |          |
|    fps             | 59       |
|    iterations      | 54       |
|    time_elapsed    | 3697     |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 113         |
|    ep_rew_mean          | 98.65234    |
| time/                   |             |
|    fps                  | 59          |
|    iterations           | 55          |
|    time_elapsed         | 3757        |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.015287116 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.326       |
|    explained_variance   | 0.652       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0835      |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.00987    |
|    std                  | 0.233       |
|    value_loss           | 0.2         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 118         |
|    ep_rew_mean          | 102.999886  |
| time/                   |             |
|    fps                  | 60          |
|    iterations           | 56          |
|    time_elapsed         | 3813        |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.017943464 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.331       |
|    explained_variance   | 0.645       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0578      |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.012      |
|    std                  | 0.233       |
|    value_loss           | 0.218       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 258         |
|    mean_ep_length       | 187         |
|    mean_reward          | 1.38e+04    |
|    speed                | 0.86        |
|    speed_penalty        | 0.022       |
| time/                   |             |
|    total timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.019101715 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.326       |
|    explained_variance   | 0.646       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0707      |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.014      |
|    std                  | 0.233       |
|    value_loss           | 0.158       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 120       |
|    ep_rew_mean     | 104.33272 |
| time/              |           |
|    fps             | 60        |
|    iterations      | 57        |
|    time_elapsed    | 3884      |
|    total_timesteps | 233472    |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 126        |
|    ep_rew_mean          | 110.99497  |
| time/                   |            |
|    fps                  | 60         |
|    iterations           | 58         |
|    time_elapsed         | 3942       |
|    total_timesteps      | 237568     |
| train/                  |            |
|    approx_kl            | 0.01857109 |
|    clip_fraction        | 0.213      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.326      |
|    explained_variance   | 0.649      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.106      |
|    n_updates            | 570        |
|    policy_gradient_loss | -0.0122    |
|    std                  | 0.233      |
|    value_loss           | 0.18       |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.00119     |
|    cost_of_transport    | 217         |
|    mean_ep_length       | 236         |
|    mean_reward          | 1.75e+04    |
|    speed                | 1.12        |
|    speed_penalty        | 0.0247      |
| time/                   |             |
|    total timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.017541273 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.335       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0446      |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.0142     |
|    std                  | 0.232       |
|    value_loss           | 0.153       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 123       |
|    ep_rew_mean     | 107.77169 |
| time/              |           |
|    fps             | 60        |
|    iterations      | 59        |
|    time_elapsed    | 4014      |
|    total_timesteps | 241664    |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 123        |
|    ep_rew_mean          | 108.877396 |
| time/                   |            |
|    fps                  | 60         |
|    iterations           | 60         |
|    time_elapsed         | 4074       |
|    total_timesteps      | 245760     |
| train/                  |            |
|    approx_kl            | 0.01738351 |
|    clip_fraction        | 0.219      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.348      |
|    explained_variance   | 0.734      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0594     |
|    n_updates            | 590        |
|    policy_gradient_loss | -0.0136    |
|    std                  | 0.232      |
|    value_loss           | 0.181      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 125         |
|    ep_rew_mean          | 110.81829   |
| time/                   |             |
|    fps                  | 60          |
|    iterations           | 61          |
|    time_elapsed         | 4131        |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.018028928 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.359       |
|    explained_variance   | 0.744       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0413      |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.0135     |
|    std                  | 0.232       |
|    value_loss           | 0.146       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.00111     |
|    cost_of_transport    | 206         |
|    mean_ep_length       | 270         |
|    mean_reward          | 2e+04       |
|    speed                | 1.14        |
|    speed_penalty        | 0.0286      |
| time/                   |             |
|    total timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.016504876 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.368       |
|    explained_variance   | 0.736       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0427      |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.0109     |
|    std                  | 0.231       |
|    value_loss           | 0.168       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 127       |
|    ep_rew_mean     | 112.70295 |
| time/              |           |
|    fps             | 60        |
|    iterations      | 62        |
|    time_elapsed    | 4205      |
|    total_timesteps | 253952    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 132         |
|    ep_rew_mean          | 117.3196    |
| time/                   |             |
|    fps                  | 60          |
|    iterations           | 63          |
|    time_elapsed         | 4261        |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.015862446 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.379       |
|    explained_variance   | 0.742       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0416      |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.012      |
|    std                  | 0.231       |
|    value_loss           | 0.145       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0191      |
|    cost_of_transport    | 510         |
|    mean_ep_length       | 14          |
|    mean_reward          | 1e+03       |
|    speed                | -0.0947     |
|    speed_penalty        | 0.346       |
| time/                   |             |
|    total timesteps      | 260000      |
| train/                  |             |
|    approx_kl            | 0.016535439 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.384       |
|    explained_variance   | 0.722       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0365      |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.231       |
|    value_loss           | 0.163       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 133       |
|    ep_rew_mean     | 118.84205 |
| time/              |           |
|    fps             | 60        |
|    iterations      | 64        |
|    time_elapsed    | 4319      |
|    total_timesteps | 262144    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 139         |
|    ep_rew_mean          | 124.25966   |
| time/                   |             |
|    fps                  | 60          |
|    iterations           | 65          |
|    time_elapsed         | 4375        |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.018458644 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.389       |
|    explained_variance   | 0.771       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0247      |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.231       |
|    value_loss           | 0.114       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.00103     |
|    cost_of_transport    | 230         |
|    mean_ep_length       | 225         |
|    mean_reward          | 1.67e+04    |
|    speed                | 0.965       |
|    speed_penalty        | 0.0416      |
| time/                   |             |
|    total timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.018396376 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.397       |
|    explained_variance   | 0.749       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0169      |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.0133     |
|    std                  | 0.231       |
|    value_loss           | 0.135       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 143       |
|    ep_rew_mean     | 128.35065 |
| time/              |           |
|    fps             | 60        |
|    iterations      | 66        |
|    time_elapsed    | 4447      |
|    total_timesteps | 270336    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 145         |
|    ep_rew_mean          | 129.9907    |
| time/                   |             |
|    fps                  | 60          |
|    iterations           | 67          |
|    time_elapsed         | 4504        |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.018529654 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.416       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.102       |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.0102     |
|    std                  | 0.23        |
|    value_loss           | 0.16        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 148       |
|    ep_rew_mean          | 132.95633 |
| time/                   |           |
|    fps                  | 61        |
|    iterations           | 68        |
|    time_elapsed         | 4558      |
|    total_timesteps      | 278528    |
| train/                  |           |
|    approx_kl            | 0.0176894 |
|    clip_fraction        | 0.223     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.449     |
|    explained_variance   | 0.753     |
|    learning_rate        | 0.0001    |
|    loss                 | 0.034     |
|    n_updates            | 670       |
|    policy_gradient_loss | -0.0121   |
|    std                  | 0.229     |
|    value_loss           | 0.137     |
---------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.000459    |
|    cost_of_transport    | 213         |
|    mean_ep_length       | 231         |
|    mean_reward          | 1.72e+04    |
|    speed                | 1.02        |
|    speed_penalty        | 0.0129      |
| time/                   |             |
|    total timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.021064613 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.477       |
|    explained_variance   | 0.849       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0455      |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.228       |
|    value_loss           | 0.0822      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 153       |
|    ep_rew_mean     | 138.57799 |
| time/              |           |
|    fps             | 61        |
|    iterations      | 69        |
|    time_elapsed    | 4628      |
|    total_timesteps | 282624    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 160         |
|    ep_rew_mean          | 145.66736   |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 70          |
|    time_elapsed         | 4683        |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.018398061 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.487       |
|    explained_variance   | 0.852       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00597     |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.228       |
|    value_loss           | 0.0888      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0           |
|    cost_of_transport    | 213         |
|    mean_ep_length       | 242         |
|    mean_reward          | 1.79e+04    |
|    speed                | 1.06        |
|    speed_penalty        | 0.0157      |
| time/                   |             |
|    total timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.018762946 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.486       |
|    explained_variance   | 0.86        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0458      |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.0129     |
|    std                  | 0.228       |
|    value_loss           | 0.0998      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 160       |
|    ep_rew_mean     | 145.19951 |
| time/              |           |
|    fps             | 61        |
|    iterations      | 71        |
|    time_elapsed    | 4755      |
|    total_timesteps | 290816    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 157         |
|    ep_rew_mean          | 143.83046   |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 72          |
|    time_elapsed         | 4810        |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.017369952 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.517       |
|    explained_variance   | 0.751       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0702      |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.227       |
|    value_loss           | 0.167       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 158         |
|    ep_rew_mean          | 143.36075   |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 73          |
|    time_elapsed         | 4865        |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.019214347 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.549       |
|    explained_variance   | 0.804       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0458      |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.0115     |
|    std                  | 0.227       |
|    value_loss           | 0.118       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 5.89e-05    |
|    cost_of_transport    | 193         |
|    mean_ep_length       | 269         |
|    mean_reward          | 2e+04       |
|    speed                | 1.17        |
|    speed_penalty        | 0.0108      |
| time/                   |             |
|    total timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.017610839 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.551       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0476      |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.227       |
|    value_loss           | 0.129       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 160       |
|    ep_rew_mean     | 145.97588 |
| time/              |           |
|    fps             | 61        |
|    iterations      | 74        |
|    time_elapsed    | 4938      |
|    total_timesteps | 303104    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 162         |
|    ep_rew_mean          | 147.1657    |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 75          |
|    time_elapsed         | 4994        |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.018445434 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.564       |
|    explained_variance   | 0.833       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0621      |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.013      |
|    std                  | 0.226       |
|    value_loss           | 0.109       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 8.62e-05    |
|    cost_of_transport    | 199         |
|    mean_ep_length       | 273         |
|    mean_reward          | 2.03e+04    |
|    speed                | 1.17        |
|    speed_penalty        | 0.00889     |
| time/                   |             |
|    total timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.020473007 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.582       |
|    explained_variance   | 0.804       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.031       |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.0123     |
|    std                  | 0.226       |
|    value_loss           | 0.12        |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 163       |
|    ep_rew_mean     | 147.66083 |
| time/              |           |
|    fps             | 61        |
|    iterations      | 76        |
|    time_elapsed    | 5067      |
|    total_timesteps | 311296    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 169         |
|    ep_rew_mean          | 153.83116   |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 77          |
|    time_elapsed         | 5122        |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.020736901 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.591       |
|    explained_variance   | 0.843       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00404     |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.00948    |
|    std                  | 0.226       |
|    value_loss           | 0.0989      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 169        |
|    ep_rew_mean          | 155.37016  |
| time/                   |            |
|    fps                  | 61         |
|    iterations           | 78         |
|    time_elapsed         | 5178       |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.01937836 |
|    clip_fraction        | 0.238      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.607      |
|    explained_variance   | 0.847      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.039      |
|    n_updates            | 770        |
|    policy_gradient_loss | -0.0109    |
|    std                  | 0.225      |
|    value_loss           | 0.104      |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.000532    |
|    cost_of_transport    | 196         |
|    mean_ep_length       | 240         |
|    mean_reward          | 1.78e+04    |
|    speed                | 1.04        |
|    speed_penalty        | 0.00861     |
| time/                   |             |
|    total timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.019656878 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.613       |
|    explained_variance   | 0.832       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.052       |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.225       |
|    value_loss           | 0.115       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 172       |
|    ep_rew_mean     | 157.55046 |
| time/              |           |
|    fps             | 61        |
|    iterations      | 79        |
|    time_elapsed    | 5249      |
|    total_timesteps | 323584    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 178         |
|    ep_rew_mean          | 163.58095   |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 80          |
|    time_elapsed         | 5304        |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.022220474 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.611       |
|    explained_variance   | 0.837       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0387      |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.0132     |
|    std                  | 0.225       |
|    value_loss           | 0.113       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.00165     |
|    cost_of_transport    | 209         |
|    mean_ep_length       | 227         |
|    mean_reward          | 1.68e+04    |
|    speed                | 0.99        |
|    speed_penalty        | 0.011       |
| time/                   |             |
|    total timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.018505167 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.623       |
|    explained_variance   | 0.865       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0116      |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.0109     |
|    std                  | 0.225       |
|    value_loss           | 0.0849      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 173       |
|    ep_rew_mean     | 159.27226 |
| time/              |           |
|    fps             | 61        |
|    iterations      | 81        |
|    time_elapsed    | 5376      |
|    total_timesteps | 331776    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 174         |
|    ep_rew_mean          | 160.34357   |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 82          |
|    time_elapsed         | 5433        |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.018619854 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.628       |
|    explained_variance   | 0.842       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0383      |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.00918    |
|    std                  | 0.225       |
|    value_loss           | 0.113       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 179         |
|    ep_rew_mean          | 167.08589   |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 83          |
|    time_elapsed         | 5487        |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.018081885 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.634       |
|    explained_variance   | 0.875       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0252      |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.224       |
|    value_loss           | 0.0829      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.00356     |
|    cost_of_transport    | 201         |
|    mean_ep_length       | 277         |
|    mean_reward          | 2.06e+04    |
|    speed                | 1.17        |
|    speed_penalty        | 0.00875     |
| time/                   |             |
|    total timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.020787582 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.646       |
|    explained_variance   | 0.889       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0189      |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.014      |
|    std                  | 0.224       |
|    value_loss           | 0.0709      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 176      |
|    ep_rew_mean     | 164.1352 |
| time/              |          |
|    fps             | 61       |
|    iterations      | 84       |
|    time_elapsed    | 5561     |
|    total_timesteps | 344064   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 178         |
|    ep_rew_mean          | 166.80513   |
| time/                   |             |
|    fps                  | 61          |
|    iterations           | 85          |
|    time_elapsed         | 5615        |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.018761538 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.662       |
|    explained_variance   | 0.879       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.05        |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.01       |
|    std                  | 0.223       |
|    value_loss           | 0.0896      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.00258    |
|    cost_of_transport    | 209        |
|    mean_ep_length       | 235        |
|    mean_reward          | 1.75e+04   |
|    speed                | 1          |
|    speed_penalty        | 0.0134     |
| time/                   |            |
|    total timesteps      | 350000     |
| train/                  |            |
|    approx_kl            | 0.01860318 |
|    clip_fraction        | 0.227      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.683      |
|    explained_variance   | 0.875      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0145     |
|    n_updates            | 850        |
|    policy_gradient_loss | -0.0119    |
|    std                  | 0.223      |
|    value_loss           | 0.0876     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 176       |
|    ep_rew_mean     | 165.44217 |
| time/              |           |
|    fps             | 61        |
|    iterations      | 86        |
|    time_elapsed    | 5686      |
|    total_timesteps | 352256    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 174         |
|    ep_rew_mean          | 163.02519   |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 87          |
|    time_elapsed         | 5740        |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.022646615 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.674       |
|    explained_variance   | 0.886       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0454      |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.0175     |
|    std                  | 0.224       |
|    value_loss           | 0.0715      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.00347     |
|    cost_of_transport    | 192         |
|    mean_ep_length       | 281         |
|    mean_reward          | 2.09e+04    |
|    speed                | 1.2         |
|    speed_penalty        | 0.0136      |
| time/                   |             |
|    total timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.019758834 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.657       |
|    explained_variance   | 0.87        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0291      |
|    n_updates            | 870         |
|    policy_gradient_loss | -0.0116     |
|    std                  | 0.224       |
|    value_loss           | 0.0966      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 178       |
|    ep_rew_mean     | 166.91885 |
| time/              |           |
|    fps             | 61        |
|    iterations      | 88        |
|    time_elapsed    | 5814      |
|    total_timesteps | 360448    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 179         |
|    ep_rew_mean          | 168.02762   |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 89          |
|    time_elapsed         | 5868        |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.018495835 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.652       |
|    explained_variance   | 0.873       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.024       |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.00952    |
|    std                  | 0.224       |
|    value_loss           | 0.0813      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 176         |
|    ep_rew_mean          | 165.715     |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 90          |
|    time_elapsed         | 5922        |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.020118505 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.662       |
|    explained_variance   | 0.893       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0237      |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.224       |
|    value_loss           | 0.0777      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.00312     |
|    cost_of_transport    | 202         |
|    mean_ep_length       | 233         |
|    mean_reward          | 1.73e+04    |
|    speed                | 1.02        |
|    speed_penalty        | 0.0122      |
| time/                   |             |
|    total timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.021969855 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.695       |
|    explained_variance   | 0.848       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0411      |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.0112     |
|    std                  | 0.222       |
|    value_loss           | 0.0908      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 180      |
|    ep_rew_mean     | 169.1859 |
| time/              |          |
|    fps             | 62       |
|    iterations      | 91       |
|    time_elapsed    | 5991     |
|    total_timesteps | 372736   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 179         |
|    ep_rew_mean          | 168.3745    |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 92          |
|    time_elapsed         | 6045        |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.017403834 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.712       |
|    explained_variance   | 0.868       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00192    |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.223       |
|    value_loss           | 0.0815      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.00629     |
|    cost_of_transport    | 192         |
|    mean_ep_length       | 265         |
|    mean_reward          | 1.97e+04    |
|    speed                | 1.16        |
|    speed_penalty        | 0.0091      |
| time/                   |             |
|    total timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.022690639 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.716       |
|    explained_variance   | 0.887       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00628     |
|    n_updates            | 920         |
|    policy_gradient_loss | -0.013      |
|    std                  | 0.222       |
|    value_loss           | 0.0758      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 179       |
|    ep_rew_mean     | 168.34418 |
| time/              |           |
|    fps             | 62        |
|    iterations      | 93        |
|    time_elapsed    | 6118      |
|    total_timesteps | 380928    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 180         |
|    ep_rew_mean          | 169.4414    |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 94          |
|    time_elapsed         | 6172        |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.021081753 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.722       |
|    explained_variance   | 0.88        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00731     |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.0135     |
|    std                  | 0.222       |
|    value_loss           | 0.0791      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 184        |
|    ep_rew_mean          | 173.80405  |
| time/                   |            |
|    fps                  | 62         |
|    iterations           | 95         |
|    time_elapsed         | 6224       |
|    total_timesteps      | 389120     |
| train/                  |            |
|    approx_kl            | 0.02007331 |
|    clip_fraction        | 0.247      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.725      |
|    explained_variance   | 0.84       |
|    learning_rate        | 0.0001     |
|    loss                 | 0.017      |
|    n_updates            | 940        |
|    policy_gradient_loss | -0.0104    |
|    std                  | 0.222      |
|    value_loss           | 0.107      |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0134      |
|    cost_of_transport    | 189         |
|    mean_ep_length       | 308         |
|    mean_reward          | 2.29e+04    |
|    speed                | 1.29        |
|    speed_penalty        | 0.00823     |
| time/                   |             |
|    total timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.018068153 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.74        |
|    explained_variance   | 0.888       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0589      |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.222       |
|    value_loss           | 0.0701      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 187       |
|    ep_rew_mean     | 176.89328 |
| time/              |           |
|    fps             | 62        |
|    iterations      | 96        |
|    time_elapsed    | 6295      |
|    total_timesteps | 393216    |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 192       |
|    ep_rew_mean          | 182.09068 |
| time/                   |           |
|    fps                  | 62        |
|    iterations           | 97        |
|    time_elapsed         | 6346      |
|    total_timesteps      | 397312    |
| train/                  |           |
|    approx_kl            | 0.0192567 |
|    clip_fraction        | 0.237     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.763     |
|    explained_variance   | 0.904     |
|    learning_rate        | 0.0001    |
|    loss                 | -0.0198   |
|    n_updates            | 960       |
|    policy_gradient_loss | -0.0103   |
|    std                  | 0.221     |
|    value_loss           | 0.0657    |
---------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0124      |
|    cost_of_transport    | 194         |
|    mean_ep_length       | 274         |
|    mean_reward          | 2.04e+04    |
|    speed                | 1.16        |
|    speed_penalty        | 0.00815     |
| time/                   |             |
|    total timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.021034274 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.778       |
|    explained_variance   | 0.898       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0144     |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.221       |
|    value_loss           | 0.0553      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 197       |
|    ep_rew_mean     | 187.16356 |
| time/              |           |
|    fps             | 62        |
|    iterations      | 98        |
|    time_elapsed    | 6416      |
|    total_timesteps | 401408    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 204         |
|    ep_rew_mean          | 193.7638    |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 99          |
|    time_elapsed         | 6468        |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.019954048 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.769       |
|    explained_variance   | 0.906       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0105      |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.0112     |
|    std                  | 0.222       |
|    value_loss           | 0.0617      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 205        |
|    ep_rew_mean          | 195.29204  |
| time/                   |            |
|    fps                  | 62         |
|    iterations           | 100        |
|    time_elapsed         | 6519       |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.01999835 |
|    clip_fraction        | 0.231      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.761      |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0323     |
|    n_updates            | 990        |
|    policy_gradient_loss | -0.0114    |
|    std                  | 0.221      |
|    value_loss           | 0.0547     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0126      |
|    cost_of_transport    | 179         |
|    mean_ep_length       | 285         |
|    mean_reward          | 2.12e+04    |
|    speed                | 1.19        |
|    speed_penalty        | 0.00921     |
| time/                   |             |
|    total timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.022837536 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.783       |
|    explained_variance   | 0.892       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0138     |
|    n_updates            | 1000        |
|    policy_gradient_loss | -0.0116     |
|    std                  | 0.221       |
|    value_loss           | 0.0671      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 204       |
|    ep_rew_mean     | 193.65605 |
| time/              |           |
|    fps             | 62        |
|    iterations      | 101       |
|    time_elapsed    | 6588      |
|    total_timesteps | 413696    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 204         |
|    ep_rew_mean          | 194.25905   |
| time/                   |             |
|    fps                  | 62          |
|    iterations           | 102         |
|    time_elapsed         | 6640        |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.018178042 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.815       |
|    explained_variance   | 0.893       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0111      |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.00912    |
|    std                  | 0.22        |
|    value_loss           | 0.0805      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0164      |
|    cost_of_transport    | 185         |
|    mean_ep_length       | 281         |
|    mean_reward          | 2.09e+04    |
|    speed                | 1.2         |
|    speed_penalty        | 0.00728     |
| time/                   |             |
|    total timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.020886002 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.85        |
|    explained_variance   | 0.933       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0174      |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.0115     |
|    std                  | 0.219       |
|    value_loss           | 0.0433      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 205       |
|    ep_rew_mean     | 195.37355 |
| time/              |           |
|    fps             | 62        |
|    iterations      | 103       |
|    time_elapsed    | 6708      |
|    total_timesteps | 421888    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 203         |
|    ep_rew_mean          | 194.93318   |
| time/                   |             |
|    fps                  | 63          |
|    iterations           | 104         |
|    time_elapsed         | 6758        |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.017527688 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.865       |
|    explained_variance   | 0.936       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0313      |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.0118     |
|    std                  | 0.219       |
|    value_loss           | 0.0404      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0201      |
|    cost_of_transport    | 183         |
|    mean_ep_length       | 290         |
|    mean_reward          | 2.16e+04    |
|    speed                | 1.25        |
|    speed_penalty        | 0.00507     |
| time/                   |             |
|    total timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.018724754 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.857       |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0218      |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.0091     |
|    std                  | 0.219       |
|    value_loss           | 0.0473      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 205      |
|    ep_rew_mean     | 197.0544 |
| time/              |          |
|    fps             | 62       |
|    iterations      | 105      |
|    time_elapsed    | 6827     |
|    total_timesteps | 430080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 209         |
|    ep_rew_mean          | 201.20645   |
| time/                   |             |
|    fps                  | 63          |
|    iterations           | 106         |
|    time_elapsed         | 6877        |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.023549797 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.876       |
|    explained_variance   | 0.925       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0336      |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.012      |
|    std                  | 0.218       |
|    value_loss           | 0.0596      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 206         |
|    ep_rew_mean          | 198.26665   |
| time/                   |             |
|    fps                  | 63          |
|    iterations           | 107         |
|    time_elapsed         | 6928        |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.019177012 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.909       |
|    explained_variance   | 0.916       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0115      |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.00912    |
|    std                  | 0.217       |
|    value_loss           | 0.0628      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0278      |
|    cost_of_transport    | 193         |
|    mean_ep_length       | 242         |
|    mean_reward          | 1.8e+04     |
|    speed                | 1.06        |
|    speed_penalty        | 0.00645     |
| time/                   |             |
|    total timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.021140834 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.927       |
|    explained_variance   | 0.876       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0365      |
|    n_updates            | 1070        |
|    policy_gradient_loss | -0.0101     |
|    std                  | 0.217       |
|    value_loss           | 0.0809      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 211       |
|    ep_rew_mean     | 203.32834 |
| time/              |           |
|    fps             | 63        |
|    iterations      | 108       |
|    time_elapsed    | 6992      |
|    total_timesteps | 442368    |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 215        |
|    ep_rew_mean          | 207.76059  |
| time/                   |            |
|    fps                  | 63         |
|    iterations           | 109        |
|    time_elapsed         | 7040       |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.01888192 |
|    clip_fraction        | 0.229      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.931      |
|    explained_variance   | 0.946      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.000581   |
|    n_updates            | 1080       |
|    policy_gradient_loss | -0.0101    |
|    std                  | 0.217      |
|    value_loss           | 0.0353     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.029       |
|    cost_of_transport    | 188         |
|    mean_ep_length       | 302         |
|    mean_reward          | 2.25e+04    |
|    speed                | 1.29        |
|    speed_penalty        | 0.00536     |
| time/                   |             |
|    total timesteps      | 450000      |
| train/                  |             |
|    approx_kl            | 0.017370518 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.956       |
|    explained_variance   | 0.955       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0366      |
|    n_updates            | 1090        |
|    policy_gradient_loss | -0.00993    |
|    std                  | 0.216       |
|    value_loss           | 0.031       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 220       |
|    ep_rew_mean     | 212.23273 |
| time/              |           |
|    fps             | 63        |
|    iterations      | 110       |
|    time_elapsed    | 7108      |
|    total_timesteps | 450560    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 219         |
|    ep_rew_mean          | 211.85637   |
| time/                   |             |
|    fps                  | 63          |
|    iterations           | 111         |
|    time_elapsed         | 7158        |
|    total_timesteps      | 454656      |
| train/                  |             |
|    approx_kl            | 0.020325989 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.981       |
|    explained_variance   | 0.925       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0199      |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.00889    |
|    std                  | 0.216       |
|    value_loss           | 0.0559      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 229         |
|    ep_rew_mean          | 221.0943    |
| time/                   |             |
|    fps                  | 63          |
|    iterations           | 112         |
|    time_elapsed         | 7208        |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.017733624 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.982       |
|    explained_variance   | 0.918       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00397     |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.00992    |
|    std                  | 0.216       |
|    value_loss           | 0.055       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0374      |
|    cost_of_transport    | 176         |
|    mean_ep_length       | 307         |
|    mean_reward          | 2.29e+04    |
|    speed                | 1.31        |
|    speed_penalty        | 0.00453     |
| time/                   |             |
|    total timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.019375702 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.967       |
|    explained_variance   | 0.952       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0164      |
|    n_updates            | 1120        |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.216       |
|    value_loss           | 0.0337      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 228       |
|    ep_rew_mean     | 220.23701 |
| time/              |           |
|    fps             | 63        |
|    iterations      | 113       |
|    time_elapsed    | 7276      |
|    total_timesteps | 462848    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 224         |
|    ep_rew_mean          | 215.90239   |
| time/                   |             |
|    fps                  | 63          |
|    iterations           | 114         |
|    time_elapsed         | 7325        |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.020870885 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.953       |
|    explained_variance   | 0.931       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0835      |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.0101     |
|    std                  | 0.216       |
|    value_loss           | 0.0498      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0382      |
|    cost_of_transport    | 179         |
|    mean_ep_length       | 285         |
|    mean_reward          | 2.12e+04    |
|    speed                | 1.22        |
|    speed_penalty        | 0.00462     |
| time/                   |             |
|    total timesteps      | 470000      |
| train/                  |             |
|    approx_kl            | 0.022814669 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.958       |
|    explained_variance   | 0.924       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00656     |
|    n_updates            | 1140        |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.216       |
|    value_loss           | 0.055       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 226       |
|    ep_rew_mean     | 217.04715 |
| time/              |           |
|    fps             | 63        |
|    iterations      | 115       |
|    time_elapsed    | 7394      |
|    total_timesteps | 471040    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 226         |
|    ep_rew_mean          | 218.05719   |
| time/                   |             |
|    fps                  | 63          |
|    iterations           | 116         |
|    time_elapsed         | 7443        |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.018552965 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.967       |
|    explained_variance   | 0.952       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0155      |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.00962    |
|    std                  | 0.216       |
|    value_loss           | 0.0327      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 226         |
|    ep_rew_mean          | 217.9478    |
| time/                   |             |
|    fps                  | 63          |
|    iterations           | 117         |
|    time_elapsed         | 7491        |
|    total_timesteps      | 479232      |
| train/                  |             |
|    approx_kl            | 0.021506097 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.983       |
|    explained_variance   | 0.919       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00254     |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.0133     |
|    std                  | 0.216       |
|    value_loss           | 0.0554      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0424      |
|    cost_of_transport    | 177         |
|    mean_ep_length       | 323         |
|    mean_reward          | 2.41e+04    |
|    speed                | 1.36        |
|    speed_penalty        | 0.00356     |
| time/                   |             |
|    total timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.020350026 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.01        |
|    explained_variance   | 0.936       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0103      |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.00994    |
|    std                  | 0.215       |
|    value_loss           | 0.0445      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 226       |
|    ep_rew_mean     | 218.54184 |
| time/              |           |
|    fps             | 63        |
|    iterations      | 118       |
|    time_elapsed    | 7560      |
|    total_timesteps | 483328    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 232         |
|    ep_rew_mean          | 223.87144   |
| time/                   |             |
|    fps                  | 64          |
|    iterations           | 119         |
|    time_elapsed         | 7608        |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.021960419 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.03        |
|    explained_variance   | 0.942       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0341      |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.00915    |
|    std                  | 0.214       |
|    value_loss           | 0.0393      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0516      |
|    cost_of_transport    | 170         |
|    mean_ep_length       | 333         |
|    mean_reward          | 2.48e+04    |
|    speed                | 1.39        |
|    speed_penalty        | 0.00692     |
| time/                   |             |
|    total timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.023090601 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.04        |
|    explained_variance   | 0.953       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.024       |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.214       |
|    value_loss           | 0.0316      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 234       |
|    ep_rew_mean     | 226.41386 |
| time/              |           |
|    fps             | 64        |
|    iterations      | 120       |
|    time_elapsed    | 7676      |
|    total_timesteps | 491520    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 236         |
|    ep_rew_mean          | 229.08563   |
| time/                   |             |
|    fps                  | 64          |
|    iterations           | 121         |
|    time_elapsed         | 7724        |
|    total_timesteps      | 495616      |
| train/                  |             |
|    approx_kl            | 0.022992305 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.05        |
|    explained_variance   | 0.935       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0379      |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0123     |
|    std                  | 0.214       |
|    value_loss           | 0.0474      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 242         |
|    ep_rew_mean          | 233.74101   |
| time/                   |             |
|    fps                  | 64          |
|    iterations           | 122         |
|    time_elapsed         | 7772        |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.020949354 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.07        |
|    explained_variance   | 0.935       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0451     |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.013      |
|    std                  | 0.214       |
|    value_loss           | 0.039       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0602      |
|    cost_of_transport    | 166         |
|    mean_ep_length       | 322         |
|    mean_reward          | 2.4e+04     |
|    speed                | 1.36        |
|    speed_penalty        | 0.00533     |
| time/                   |             |
|    total timesteps      | 500000      |
| train/                  |             |
|    approx_kl            | 0.022218056 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.07        |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0323      |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.214       |
|    value_loss           | 0.0457      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 239       |
|    ep_rew_mean     | 230.80031 |
| time/              |           |
|    fps             | 64        |
|    iterations      | 123       |
|    time_elapsed    | 7840      |
|    total_timesteps | 503808    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 240         |
|    ep_rew_mean          | 231.7788    |
| time/                   |             |
|    fps                  | 64          |
|    iterations           | 124         |
|    time_elapsed         | 7887        |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.022526301 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.08        |
|    explained_variance   | 0.927       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0218      |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.0102     |
|    std                  | 0.213       |
|    value_loss           | 0.0509      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0592      |
|    cost_of_transport    | 181         |
|    mean_ep_length       | 288         |
|    mean_reward          | 2.15e+04    |
|    speed                | 1.22        |
|    speed_penalty        | 0.00512     |
| time/                   |             |
|    total timesteps      | 510000      |
| train/                  |             |
|    approx_kl            | 0.020588137 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.09        |
|    explained_variance   | 0.947       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0316      |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.213       |
|    value_loss           | 0.0367      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 241       |
|    ep_rew_mean     | 232.39622 |
| time/              |           |
|    fps             | 64        |
|    iterations      | 125       |
|    time_elapsed    | 7953      |
|    total_timesteps | 512000    |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 241        |
|    ep_rew_mean          | 232.2835   |
| time/                   |            |
|    fps                  | 64         |
|    iterations           | 126        |
|    time_elapsed         | 8000       |
|    total_timesteps      | 516096     |
| train/                  |            |
|    approx_kl            | 0.02353808 |
|    clip_fraction        | 0.274      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.1        |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0174     |
|    n_updates            | 1250       |
|    policy_gradient_loss | -0.013     |
|    std                  | 0.213      |
|    value_loss           | 0.0471     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0664      |
|    cost_of_transport    | 168         |
|    mean_ep_length       | 363         |
|    mean_reward          | 2.71e+04    |
|    speed                | 1.45        |
|    speed_penalty        | 0.00503     |
| time/                   |             |
|    total timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.019115932 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.11        |
|    explained_variance   | 0.941       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0334      |
|    n_updates            | 1260        |
|    policy_gradient_loss | -0.0075     |
|    std                  | 0.213       |
|    value_loss           | 0.0395      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 239      |
|    ep_rew_mean     | 231.0629 |
| time/              |          |
|    fps             | 64       |
|    iterations      | 127      |
|    time_elapsed    | 8070     |
|    total_timesteps | 520192   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 242         |
|    ep_rew_mean          | 233.62135   |
| time/                   |             |
|    fps                  | 64          |
|    iterations           | 128         |
|    time_elapsed         | 8117        |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 0.019919207 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.11        |
|    explained_variance   | 0.954       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0197      |
|    n_updates            | 1270        |
|    policy_gradient_loss | -0.00999    |
|    std                  | 0.213       |
|    value_loss           | 0.033       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 244         |
|    ep_rew_mean          | 235.50146   |
| time/                   |             |
|    fps                  | 64          |
|    iterations           | 129         |
|    time_elapsed         | 8165        |
|    total_timesteps      | 528384      |
| train/                  |             |
|    approx_kl            | 0.022417445 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.11        |
|    explained_variance   | 0.954       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00283     |
|    n_updates            | 1280        |
|    policy_gradient_loss | -0.0116     |
|    std                  | 0.213       |
|    value_loss           | 0.0356      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0641      |
|    cost_of_transport    | 181         |
|    mean_ep_length       | 285         |
|    mean_reward          | 2.12e+04    |
|    speed                | 1.2         |
|    speed_penalty        | 0.00458     |
| time/                   |             |
|    total timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.022132378 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.12        |
|    explained_variance   | 0.95        |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00465    |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.00877    |
|    std                  | 0.213       |
|    value_loss           | 0.0365      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 244       |
|    ep_rew_mean     | 235.78116 |
| time/              |           |
|    fps             | 64        |
|    iterations      | 130       |
|    time_elapsed    | 8231      |
|    total_timesteps | 532480    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 244         |
|    ep_rew_mean          | 236.45898   |
| time/                   |             |
|    fps                  | 64          |
|    iterations           | 131         |
|    time_elapsed         | 8278        |
|    total_timesteps      | 536576      |
| train/                  |             |
|    approx_kl            | 0.023027848 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.12        |
|    explained_variance   | 0.941       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00799    |
|    n_updates            | 1300        |
|    policy_gradient_loss | -0.0099     |
|    std                  | 0.213       |
|    value_loss           | 0.0426      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0621      |
|    cost_of_transport    | 182         |
|    mean_ep_length       | 270         |
|    mean_reward          | 2.01e+04    |
|    speed                | 1.12        |
|    speed_penalty        | 0.00598     |
| time/                   |             |
|    total timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.022986175 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.13        |
|    explained_variance   | 0.958       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0156      |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.212       |
|    value_loss           | 0.0279      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 247       |
|    ep_rew_mean     | 239.43639 |
| time/              |           |
|    fps             | 64        |
|    iterations      | 132       |
|    time_elapsed    | 8342      |
|    total_timesteps | 540672    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 243.24252   |
| time/                   |             |
|    fps                  | 64          |
|    iterations           | 133         |
|    time_elapsed         | 8389        |
|    total_timesteps      | 544768      |
| train/                  |             |
|    approx_kl            | 0.024476223 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.15        |
|    explained_variance   | 0.953       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0163      |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.0118     |
|    std                  | 0.212       |
|    value_loss           | 0.0342      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 249         |
|    ep_rew_mean          | 241.48068   |
| time/                   |             |
|    fps                  | 65          |
|    iterations           | 134         |
|    time_elapsed         | 8436        |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.019534625 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.17        |
|    explained_variance   | 0.944       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00888    |
|    n_updates            | 1330        |
|    policy_gradient_loss | -0.00921    |
|    std                  | 0.212       |
|    value_loss           | 0.0396      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0742      |
|    cost_of_transport    | 173         |
|    mean_ep_length       | 335         |
|    mean_reward          | 2.49e+04    |
|    speed                | 1.36        |
|    speed_penalty        | 0.00599     |
| time/                   |             |
|    total timesteps      | 550000      |
| train/                  |             |
|    approx_kl            | 0.024007201 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.17        |
|    explained_variance   | 0.915       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00895     |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.00986    |
|    std                  | 0.211       |
|    value_loss           | 0.0532      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 252       |
|    ep_rew_mean     | 243.90132 |
| time/              |           |
|    fps             | 65        |
|    iterations      | 135       |
|    time_elapsed    | 8504      |
|    total_timesteps | 552960    |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 251        |
|    ep_rew_mean          | 243.33546  |
| time/                   |            |
|    fps                  | 65         |
|    iterations           | 136        |
|    time_elapsed         | 8552       |
|    total_timesteps      | 557056     |
| train/                  |            |
|    approx_kl            | 0.02271511 |
|    clip_fraction        | 0.254      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.18       |
|    explained_variance   | 0.952      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0144    |
|    n_updates            | 1350       |
|    policy_gradient_loss | -0.00995   |
|    std                  | 0.211      |
|    value_loss           | 0.0316     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.081       |
|    cost_of_transport    | 167         |
|    mean_ep_length       | 333         |
|    mean_reward          | 2.48e+04    |
|    speed                | 1.35        |
|    speed_penalty        | 0.00662     |
| time/                   |             |
|    total timesteps      | 560000      |
| train/                  |             |
|    approx_kl            | 0.025216391 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.2         |
|    explained_variance   | 0.901       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.000532    |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.211       |
|    value_loss           | 0.062       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 250       |
|    ep_rew_mean     | 242.22134 |
| time/              |           |
|    fps             | 65        |
|    iterations      | 137       |
|    time_elapsed    | 8619      |
|    total_timesteps | 561152    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 243.2419    |
| time/                   |             |
|    fps                  | 65          |
|    iterations           | 138         |
|    time_elapsed         | 8665        |
|    total_timesteps      | 565248      |
| train/                  |             |
|    approx_kl            | 0.019681886 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.21        |
|    explained_variance   | 0.925       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0311      |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.00756    |
|    std                  | 0.21        |
|    value_loss           | 0.0482      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 255         |
|    ep_rew_mean          | 246.32994   |
| time/                   |             |
|    fps                  | 65          |
|    iterations           | 139         |
|    time_elapsed         | 8711        |
|    total_timesteps      | 569344      |
| train/                  |             |
|    approx_kl            | 0.020762488 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.21        |
|    explained_variance   | 0.944       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0636      |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.00902    |
|    std                  | 0.21        |
|    value_loss           | 0.0347      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.101       |
|    cost_of_transport    | 174         |
|    mean_ep_length       | 383         |
|    mean_reward          | 2.85e+04    |
|    speed                | 1.41        |
|    speed_penalty        | 0.0251      |
| time/                   |             |
|    total timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.019459564 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.21        |
|    explained_variance   | 0.957       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.000672    |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.00904    |
|    std                  | 0.21        |
|    value_loss           | 0.0307      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 258       |
|    ep_rew_mean     | 249.51959 |
| time/              |           |
|    fps             | 65        |
|    iterations      | 140       |
|    time_elapsed    | 8782      |
|    total_timesteps | 573440    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 254         |
|    ep_rew_mean          | 245.19107   |
| time/                   |             |
|    fps                  | 65          |
|    iterations           | 141         |
|    time_elapsed         | 8829        |
|    total_timesteps      | 577536      |
| train/                  |             |
|    approx_kl            | 0.020947833 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.21        |
|    explained_variance   | 0.932       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0169      |
|    n_updates            | 1400        |
|    policy_gradient_loss | -0.00889    |
|    std                  | 0.21        |
|    value_loss           | 0.0421      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0924      |
|    cost_of_transport    | 170         |
|    mean_ep_length       | 366         |
|    mean_reward          | 2.72e+04    |
|    speed                | 1.4         |
|    speed_penalty        | 0.011       |
| time/                   |             |
|    total timesteps      | 580000      |
| train/                  |             |
|    approx_kl            | 0.023691108 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.21        |
|    explained_variance   | 0.928       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00507    |
|    n_updates            | 1410        |
|    policy_gradient_loss | -0.00931    |
|    std                  | 0.21        |
|    value_loss           | 0.0472      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 261       |
|    ep_rew_mean     | 251.58777 |
| time/              |           |
|    fps             | 65        |
|    iterations      | 142       |
|    time_elapsed    | 8899      |
|    total_timesteps | 581632    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 265         |
|    ep_rew_mean          | 254.42732   |
| time/                   |             |
|    fps                  | 65          |
|    iterations           | 143         |
|    time_elapsed         | 8945        |
|    total_timesteps      | 585728      |
| train/                  |             |
|    approx_kl            | 0.023943055 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.21        |
|    explained_variance   | 0.948       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0169     |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.0079     |
|    std                  | 0.211       |
|    value_loss           | 0.0315      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 266         |
|    ep_rew_mean          | 255.88556   |
| time/                   |             |
|    fps                  | 65          |
|    iterations           | 144         |
|    time_elapsed         | 8992        |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.019736977 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.22        |
|    explained_variance   | 0.957       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00785     |
|    n_updates            | 1430        |
|    policy_gradient_loss | -0.0103     |
|    std                  | 0.21        |
|    value_loss           | 0.0279      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.103      |
|    cost_of_transport    | 170        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.47       |
|    speed_penalty        | 0.0114     |
| time/                   |            |
|    total timesteps      | 590000     |
| train/                  |            |
|    approx_kl            | 0.02532094 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.25       |
|    explained_variance   | 0.953      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0354     |
|    n_updates            | 1440       |
|    policy_gradient_loss | -0.0128    |
|    std                  | 0.209      |
|    value_loss           | 0.028      |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 271       |
|    ep_rew_mean     | 260.03772 |
| time/              |           |
|    fps             | 65        |
|    iterations      | 145       |
|    time_elapsed    | 9063      |
|    total_timesteps | 593920    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 276         |
|    ep_rew_mean          | 264.7134    |
| time/                   |             |
|    fps                  | 65          |
|    iterations           | 146         |
|    time_elapsed         | 9108        |
|    total_timesteps      | 598016      |
| train/                  |             |
|    approx_kl            | 0.022253644 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.26        |
|    explained_variance   | 0.965       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0131      |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.209       |
|    value_loss           | 0.0259      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.0853      |
|    cost_of_transport    | 179         |
|    mean_ep_length       | 345         |
|    mean_reward          | 2.57e+04    |
|    speed                | 1.32        |
|    speed_penalty        | 0.0127      |
| time/                   |             |
|    total timesteps      | 600000      |
| train/                  |             |
|    approx_kl            | 0.022480125 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.3         |
|    explained_variance   | 0.965       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00461    |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.00984    |
|    std                  | 0.208       |
|    value_loss           | 0.0249      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 276       |
|    ep_rew_mean     | 265.62656 |
| time/              |           |
|    fps             | 65        |
|    iterations      | 147       |
|    time_elapsed    | 9176      |
|    total_timesteps | 602112    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 277         |
|    ep_rew_mean          | 266.3617    |
| time/                   |             |
|    fps                  | 65          |
|    iterations           | 148         |
|    time_elapsed         | 9223        |
|    total_timesteps      | 606208      |
| train/                  |             |
|    approx_kl            | 0.027486505 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.32        |
|    explained_variance   | 0.953       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0252      |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.00915    |
|    std                  | 0.208       |
|    value_loss           | 0.0302      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.11        |
|    cost_of_transport    | 168         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.44        |
|    speed_penalty        | 0.0249      |
| time/                   |             |
|    total timesteps      | 610000      |
| train/                  |             |
|    approx_kl            | 0.023350466 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.33        |
|    explained_variance   | 0.944       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0118      |
|    n_updates            | 1480        |
|    policy_gradient_loss | -0.00908    |
|    std                  | 0.208       |
|    value_loss           | 0.0388      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 277       |
|    ep_rew_mean     | 266.45792 |
| time/              |           |
|    fps             | 65        |
|    iterations      | 149       |
|    time_elapsed    | 9294      |
|    total_timesteps | 610304    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 276         |
|    ep_rew_mean          | 266.02704   |
| time/                   |             |
|    fps                  | 65          |
|    iterations           | 150         |
|    time_elapsed         | 9340        |
|    total_timesteps      | 614400      |
| train/                  |             |
|    approx_kl            | 0.022766817 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.33        |
|    explained_variance   | 0.966       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0262     |
|    n_updates            | 1490        |
|    policy_gradient_loss | -0.00767    |
|    std                  | 0.208       |
|    value_loss           | 0.0226      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 282         |
|    ep_rew_mean          | 270.26306   |
| time/                   |             |
|    fps                  | 65          |
|    iterations           | 151         |
|    time_elapsed         | 9386        |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.022476181 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.32        |
|    explained_variance   | 0.969       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00212     |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.00837    |
|    std                  | 0.208       |
|    value_loss           | 0.0236      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.108       |
|    cost_of_transport    | 166         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.4         |
|    speed_penalty        | 0.0468      |
| time/                   |             |
|    total timesteps      | 620000      |
| train/                  |             |
|    approx_kl            | 0.023850307 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.32        |
|    explained_variance   | 0.962       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0182      |
|    n_updates            | 1510        |
|    policy_gradient_loss | -0.008      |
|    std                  | 0.208       |
|    value_loss           | 0.0293      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 278      |
|    ep_rew_mean     | 265.5902 |
| time/              |          |
|    fps             | 65       |
|    iterations      | 152      |
|    time_elapsed    | 9458     |
|    total_timesteps | 622592   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 276         |
|    ep_rew_mean          | 263.41354   |
| time/                   |             |
|    fps                  | 65          |
|    iterations           | 153         |
|    time_elapsed         | 9504        |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.022751888 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.32        |
|    explained_variance   | 0.952       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0265      |
|    n_updates            | 1520        |
|    policy_gradient_loss | -0.0104     |
|    std                  | 0.208       |
|    value_loss           | 0.0385      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.119       |
|    cost_of_transport    | 165         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.47        |
|    speed_penalty        | 0.0247      |
| time/                   |             |
|    total timesteps      | 630000      |
| train/                  |             |
|    approx_kl            | 0.020810524 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.33        |
|    explained_variance   | 0.962       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.011      |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.00994    |
|    std                  | 0.207       |
|    value_loss           | 0.0305      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 276      |
|    ep_rew_mean     | 263.2401 |
| time/              |          |
|    fps             | 65       |
|    iterations      | 154      |
|    time_elapsed    | 9575     |
|    total_timesteps | 630784   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 281         |
|    ep_rew_mean          | 267.66876   |
| time/                   |             |
|    fps                  | 65          |
|    iterations           | 155         |
|    time_elapsed         | 9620        |
|    total_timesteps      | 634880      |
| train/                  |             |
|    approx_kl            | 0.024931146 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.36        |
|    explained_variance   | 0.962       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.011       |
|    n_updates            | 1540        |
|    policy_gradient_loss | -0.00796    |
|    std                  | 0.206       |
|    value_loss           | 0.0292      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 284         |
|    ep_rew_mean          | 270.35388   |
| time/                   |             |
|    fps                  | 66          |
|    iterations           | 156         |
|    time_elapsed         | 9664        |
|    total_timesteps      | 638976      |
| train/                  |             |
|    approx_kl            | 0.023420962 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.38        |
|    explained_variance   | 0.962       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00274    |
|    n_updates            | 1550        |
|    policy_gradient_loss | -0.0125     |
|    std                  | 0.206       |
|    value_loss           | 0.026       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.133       |
|    cost_of_transport    | 167         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.42        |
|    speed_penalty        | 0.038       |
| time/                   |             |
|    total timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.019888708 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.4         |
|    explained_variance   | 0.964       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0169     |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.00941    |
|    std                  | 0.206       |
|    value_loss           | 0.0222      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 285       |
|    ep_rew_mean     | 271.74265 |
| time/              |           |
|    fps             | 66        |
|    iterations      | 157       |
|    time_elapsed    | 9734      |
|    total_timesteps | 643072    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 287         |
|    ep_rew_mean          | 274.70227   |
| time/                   |             |
|    fps                  | 66          |
|    iterations           | 158         |
|    time_elapsed         | 9778        |
|    total_timesteps      | 647168      |
| train/                  |             |
|    approx_kl            | 0.021985412 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.42        |
|    explained_variance   | 0.965       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0225      |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.0073     |
|    std                  | 0.205       |
|    value_loss           | 0.0272      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.144       |
|    cost_of_transport    | 177         |
|    mean_ep_length       | 362         |
|    mean_reward          | 2.69e+04    |
|    speed                | 1.42        |
|    speed_penalty        | 0.011       |
| time/                   |             |
|    total timesteps      | 650000      |
| train/                  |             |
|    approx_kl            | 0.021528203 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.42        |
|    explained_variance   | 0.971       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0229     |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.00692    |
|    std                  | 0.206       |
|    value_loss           | 0.0204      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 291       |
|    ep_rew_mean     | 278.94116 |
| time/              |           |
|    fps             | 66        |
|    iterations      | 159       |
|    time_elapsed    | 9843      |
|    total_timesteps | 651264    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 293         |
|    ep_rew_mean          | 282.40506   |
| time/                   |             |
|    fps                  | 66          |
|    iterations           | 160         |
|    time_elapsed         | 9887        |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.020796875 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.42        |
|    explained_variance   | 0.973       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0101      |
|    n_updates            | 1590        |
|    policy_gradient_loss | -0.00954    |
|    std                  | 0.205       |
|    value_loss           | 0.0195      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 294         |
|    ep_rew_mean          | 284.42456   |
| time/                   |             |
|    fps                  | 66          |
|    iterations           | 161         |
|    time_elapsed         | 9930        |
|    total_timesteps      | 659456      |
| train/                  |             |
|    approx_kl            | 0.021473214 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.45        |
|    explained_variance   | 0.957       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00113     |
|    n_updates            | 1600        |
|    policy_gradient_loss | -0.00736    |
|    std                  | 0.204       |
|    value_loss           | 0.0335      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.151      |
|    cost_of_transport    | 168        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.48       |
|    speed_penalty        | 0.0153     |
| time/                   |            |
|    total timesteps      | 660000     |
| train/                  |            |
|    approx_kl            | 0.01907362 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.48       |
|    explained_variance   | 0.97       |
|    learning_rate        | 0.0001     |
|    loss                 | 0.00535    |
|    n_updates            | 1610       |
|    policy_gradient_loss | -0.00894   |
|    std                  | 0.204      |
|    value_loss           | 0.0176     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 298       |
|    ep_rew_mean     | 287.91028 |
| time/              |           |
|    fps             | 66        |
|    iterations      | 162       |
|    time_elapsed    | 9996      |
|    total_timesteps | 663552    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 304         |
|    ep_rew_mean          | 293.35724   |
| time/                   |             |
|    fps                  | 66          |
|    iterations           | 163         |
|    time_elapsed         | 10040       |
|    total_timesteps      | 667648      |
| train/                  |             |
|    approx_kl            | 0.019904062 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.49        |
|    explained_variance   | 0.964       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0399      |
|    n_updates            | 1620        |
|    policy_gradient_loss | -0.00822    |
|    std                  | 0.204       |
|    value_loss           | 0.0228      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.134       |
|    cost_of_transport    | 170         |
|    mean_ep_length       | 350         |
|    mean_reward          | 2.61e+04    |
|    speed                | 1.38        |
|    speed_penalty        | 0.0207      |
| time/                   |             |
|    total timesteps      | 670000      |
| train/                  |             |
|    approx_kl            | 0.022041805 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.49        |
|    explained_variance   | 0.957       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0171      |
|    n_updates            | 1630        |
|    policy_gradient_loss | -0.00907    |
|    std                  | 0.204       |
|    value_loss           | 0.0316      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 309      |
|    ep_rew_mean     | 297.7091 |
| time/              |          |
|    fps             | 66       |
|    iterations      | 164      |
|    time_elapsed    | 10105    |
|    total_timesteps | 671744   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 308        |
|    ep_rew_mean          | 297.67212  |
| time/                   |            |
|    fps                  | 66         |
|    iterations           | 165        |
|    time_elapsed         | 10150      |
|    total_timesteps      | 675840     |
| train/                  |            |
|    approx_kl            | 0.02219807 |
|    clip_fraction        | 0.249      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.48       |
|    explained_variance   | 0.961      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0148    |
|    n_updates            | 1640       |
|    policy_gradient_loss | -0.00914   |
|    std                  | 0.204      |
|    value_loss           | 0.0277     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 312        |
|    ep_rew_mean          | 300.80145  |
| time/                   |            |
|    fps                  | 66         |
|    iterations           | 166        |
|    time_elapsed         | 10194      |
|    total_timesteps      | 679936     |
| train/                  |            |
|    approx_kl            | 0.02018848 |
|    clip_fraction        | 0.245      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.5        |
|    explained_variance   | 0.965      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0295     |
|    n_updates            | 1650       |
|    policy_gradient_loss | -0.00441   |
|    std                  | 0.203      |
|    value_loss           | 0.0154     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.14        |
|    cost_of_transport    | 176         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.45        |
|    speed_penalty        | 0.0243      |
| time/                   |             |
|    total timesteps      | 680000      |
| train/                  |             |
|    approx_kl            | 0.024879403 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.51        |
|    explained_variance   | 0.943       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.028      |
|    n_updates            | 1660        |
|    policy_gradient_loss | -0.00674    |
|    std                  | 0.203       |
|    value_loss           | 0.0385      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 310       |
|    ep_rew_mean     | 299.26172 |
| time/              |           |
|    fps             | 66        |
|    iterations      | 167       |
|    time_elapsed    | 10263     |
|    total_timesteps | 684032    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 310         |
|    ep_rew_mean          | 299.46292   |
| time/                   |             |
|    fps                  | 66          |
|    iterations           | 168         |
|    time_elapsed         | 10307       |
|    total_timesteps      | 688128      |
| train/                  |             |
|    approx_kl            | 0.020447537 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.52        |
|    explained_variance   | 0.954       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0382      |
|    n_updates            | 1670        |
|    policy_gradient_loss | -0.007      |
|    std                  | 0.203       |
|    value_loss           | 0.0324      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.151       |
|    cost_of_transport    | 168         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.5         |
|    speed_penalty        | 0.00954     |
| time/                   |             |
|    total timesteps      | 690000      |
| train/                  |             |
|    approx_kl            | 0.020806553 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.54        |
|    explained_variance   | 0.95        |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00472    |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.00852    |
|    std                  | 0.202       |
|    value_loss           | 0.0343      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 308       |
|    ep_rew_mean     | 296.74927 |
| time/              |           |
|    fps             | 66        |
|    iterations      | 169       |
|    time_elapsed    | 10374     |
|    total_timesteps | 692224    |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 306        |
|    ep_rew_mean          | 295.11588  |
| time/                   |            |
|    fps                  | 66         |
|    iterations           | 170        |
|    time_elapsed         | 10417      |
|    total_timesteps      | 696320     |
| train/                  |            |
|    approx_kl            | 0.02385755 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.55       |
|    explained_variance   | 0.958      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0396     |
|    n_updates            | 1690       |
|    policy_gradient_loss | -0.00647   |
|    std                  | 0.202      |
|    value_loss           | 0.0276     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.178       |
|    cost_of_transport    | 165         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.47        |
|    speed_penalty        | 0.0162      |
| time/                   |             |
|    total timesteps      | 700000      |
| train/                  |             |
|    approx_kl            | 0.024765458 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.54        |
|    explained_variance   | 0.968       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0162     |
|    n_updates            | 1700        |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.203       |
|    value_loss           | 0.019       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 302      |
|    ep_rew_mean     | 291.254  |
| time/              |          |
|    fps             | 66       |
|    iterations      | 171      |
|    time_elapsed    | 10485    |
|    total_timesteps | 700416   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 304         |
|    ep_rew_mean          | 292.93292   |
| time/                   |             |
|    fps                  | 66          |
|    iterations           | 172         |
|    time_elapsed         | 10530       |
|    total_timesteps      | 704512      |
| train/                  |             |
|    approx_kl            | 0.026367977 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.52        |
|    explained_variance   | 0.968       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0145     |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.204       |
|    value_loss           | 0.0233      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 302         |
|    ep_rew_mean          | 291.48303   |
| time/                   |             |
|    fps                  | 67          |
|    iterations           | 173         |
|    time_elapsed         | 10574       |
|    total_timesteps      | 708608      |
| train/                  |             |
|    approx_kl            | 0.020751085 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.53        |
|    explained_variance   | 0.967       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0165      |
|    n_updates            | 1720        |
|    policy_gradient_loss | -0.00819    |
|    std                  | 0.203       |
|    value_loss           | 0.0232      |
-----------------------------------------
---------------------------------------
| eval/                   |           |
|    action_norm_penalty  | 0.168     |
|    cost_of_transport    | 166       |
|    mean_ep_length       | 395       |
|    mean_reward          | 2.94e+04  |
|    speed                | 1.48      |
|    speed_penalty        | 0.0114    |
| time/                   |           |
|    total timesteps      | 710000    |
| train/                  |           |
|    approx_kl            | 0.0246738 |
|    clip_fraction        | 0.274     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.54      |
|    explained_variance   | 0.958     |
|    learning_rate        | 0.0001    |
|    loss                 | -0.00232  |
|    n_updates            | 1730      |
|    policy_gradient_loss | -0.00859  |
|    std                  | 0.203     |
|    value_loss           | 0.031     |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 304       |
|    ep_rew_mean     | 293.51013 |
| time/              |           |
|    fps             | 66        |
|    iterations      | 174       |
|    time_elapsed    | 10641     |
|    total_timesteps | 712704    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 306         |
|    ep_rew_mean          | 294.57202   |
| time/                   |             |
|    fps                  | 67          |
|    iterations           | 175         |
|    time_elapsed         | 10684       |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.024946248 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.55        |
|    explained_variance   | 0.966       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00284     |
|    n_updates            | 1740        |
|    policy_gradient_loss | -0.0122     |
|    std                  | 0.202       |
|    value_loss           | 0.0242      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.186       |
|    cost_of_transport    | 170         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.44        |
|    speed_penalty        | 0.0198      |
| time/                   |             |
|    total timesteps      | 720000      |
| train/                  |             |
|    approx_kl            | 0.024157936 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.55        |
|    explained_variance   | 0.967       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0113      |
|    n_updates            | 1750        |
|    policy_gradient_loss | -0.00862    |
|    std                  | 0.203       |
|    value_loss           | 0.0231      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 303      |
|    ep_rew_mean     | 292.3659 |
| time/              |          |
|    fps             | 67       |
|    iterations      | 176      |
|    time_elapsed    | 10752    |
|    total_timesteps | 720896   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 305        |
|    ep_rew_mean          | 295.02783  |
| time/                   |            |
|    fps                  | 67         |
|    iterations           | 177        |
|    time_elapsed         | 10796      |
|    total_timesteps      | 724992     |
| train/                  |            |
|    approx_kl            | 0.02619036 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.55       |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0092    |
|    n_updates            | 1760       |
|    policy_gradient_loss | -0.0115    |
|    std                  | 0.203      |
|    value_loss           | 0.0352     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 310         |
|    ep_rew_mean          | 298.64352   |
| time/                   |             |
|    fps                  | 67          |
|    iterations           | 178         |
|    time_elapsed         | 10840       |
|    total_timesteps      | 729088      |
| train/                  |             |
|    approx_kl            | 0.023424422 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.56        |
|    explained_variance   | 0.966       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0248      |
|    n_updates            | 1770        |
|    policy_gradient_loss | -0.00882    |
|    std                  | 0.202       |
|    value_loss           | 0.0258      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.167       |
|    cost_of_transport    | 169         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.49        |
|    speed_penalty        | 0.00999     |
| time/                   |             |
|    total timesteps      | 730000      |
| train/                  |             |
|    approx_kl            | 0.021960355 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.59        |
|    explained_variance   | 0.967       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00948    |
|    n_updates            | 1780        |
|    policy_gradient_loss | -0.00917    |
|    std                  | 0.201       |
|    value_loss           | 0.0229      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 313       |
|    ep_rew_mean     | 301.48846 |
| time/              |           |
|    fps             | 67        |
|    iterations      | 179       |
|    time_elapsed    | 10907     |
|    total_timesteps | 733184    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 313         |
|    ep_rew_mean          | 301.7922    |
| time/                   |             |
|    fps                  | 67          |
|    iterations           | 180         |
|    time_elapsed         | 10949       |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.023653716 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.59        |
|    explained_variance   | 0.95        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0209      |
|    n_updates            | 1790        |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.202       |
|    value_loss           | 0.035       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.164       |
|    cost_of_transport    | 173         |
|    mean_ep_length       | 364         |
|    mean_reward          | 2.71e+04    |
|    speed                | 1.4         |
|    speed_penalty        | 0.0126      |
| time/                   |             |
|    total timesteps      | 740000      |
| train/                  |             |
|    approx_kl            | 0.023531705 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.59        |
|    explained_variance   | 0.96        |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0293     |
|    n_updates            | 1800        |
|    policy_gradient_loss | -0.00898    |
|    std                  | 0.202       |
|    value_loss           | 0.0216      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 318       |
|    ep_rew_mean     | 306.14276 |
| time/              |           |
|    fps             | 67        |
|    iterations      | 181       |
|    time_elapsed    | 11014     |
|    total_timesteps | 741376    |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 323        |
|    ep_rew_mean          | 310.39093  |
| time/                   |            |
|    fps                  | 67         |
|    iterations           | 182        |
|    time_elapsed         | 11056      |
|    total_timesteps      | 745472     |
| train/                  |            |
|    approx_kl            | 0.02273876 |
|    clip_fraction        | 0.263      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.59       |
|    explained_variance   | 0.954      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0088     |
|    n_updates            | 1810       |
|    policy_gradient_loss | -0.00772   |
|    std                  | 0.202      |
|    value_loss           | 0.0259     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 326         |
|    ep_rew_mean          | 312.6592    |
| time/                   |             |
|    fps                  | 67          |
|    iterations           | 183         |
|    time_elapsed         | 11098       |
|    total_timesteps      | 749568      |
| train/                  |             |
|    approx_kl            | 0.022771608 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.59        |
|    explained_variance   | 0.953       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00104     |
|    n_updates            | 1820        |
|    policy_gradient_loss | -0.00725    |
|    std                  | 0.202       |
|    value_loss           | 0.0328      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.177      |
|    cost_of_transport    | 174        |
|    mean_ep_length       | 378        |
|    mean_reward          | 2.81e+04   |
|    speed                | 1.43       |
|    speed_penalty        | 0.014      |
| time/                   |            |
|    total timesteps      | 750000     |
| train/                  |            |
|    approx_kl            | 0.02576612 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.6        |
|    explained_variance   | 0.944      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0732     |
|    n_updates            | 1830       |
|    policy_gradient_loss | -0.0104    |
|    std                  | 0.201      |
|    value_loss           | 0.0348     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 331       |
|    ep_rew_mean     | 317.28723 |
| time/              |           |
|    fps             | 67        |
|    iterations      | 184       |
|    time_elapsed    | 11164     |
|    total_timesteps | 753664    |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 330        |
|    ep_rew_mean          | 316.2081   |
| time/                   |            |
|    fps                  | 67         |
|    iterations           | 185        |
|    time_elapsed         | 11206      |
|    total_timesteps      | 757760     |
| train/                  |            |
|    approx_kl            | 0.02211088 |
|    clip_fraction        | 0.251      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.6        |
|    explained_variance   | 0.947      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0406     |
|    n_updates            | 1840       |
|    policy_gradient_loss | -0.00744   |
|    std                  | 0.202      |
|    value_loss           | 0.0287     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.164       |
|    cost_of_transport    | 178         |
|    mean_ep_length       | 306         |
|    mean_reward          | 2.27e+04    |
|    speed                | 1.25        |
|    speed_penalty        | 0.0177      |
| time/                   |             |
|    total timesteps      | 760000      |
| train/                  |             |
|    approx_kl            | 0.023706052 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.61        |
|    explained_variance   | 0.951       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.046      |
|    n_updates            | 1850        |
|    policy_gradient_loss | -0.0103     |
|    std                  | 0.201       |
|    value_loss           | 0.0284      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 326       |
|    ep_rew_mean     | 312.53964 |
| time/              |           |
|    fps             | 67        |
|    iterations      | 186       |
|    time_elapsed    | 11268     |
|    total_timesteps | 761856    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 326         |
|    ep_rew_mean          | 312.24023   |
| time/                   |             |
|    fps                  | 67          |
|    iterations           | 187         |
|    time_elapsed         | 11311       |
|    total_timesteps      | 765952      |
| train/                  |             |
|    approx_kl            | 0.025516037 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.62        |
|    explained_variance   | 0.968       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0213     |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.201       |
|    value_loss           | 0.0157      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.198       |
|    cost_of_transport    | 165         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.53        |
|    speed_penalty        | 0.00633     |
| time/                   |             |
|    total timesteps      | 770000      |
| train/                  |             |
|    approx_kl            | 0.025927689 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.61        |
|    explained_variance   | 0.97        |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00139    |
|    n_updates            | 1870        |
|    policy_gradient_loss | -0.00975    |
|    std                  | 0.201       |
|    value_loss           | 0.0194      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 324      |
|    ep_rew_mean     | 311.4461 |
| time/              |          |
|    fps             | 67       |
|    iterations      | 188      |
|    time_elapsed    | 11376    |
|    total_timesteps | 770048   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 320         |
|    ep_rew_mean          | 307.6521    |
| time/                   |             |
|    fps                  | 67          |
|    iterations           | 189         |
|    time_elapsed         | 11418       |
|    total_timesteps      | 774144      |
| train/                  |             |
|    approx_kl            | 0.025936069 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.62        |
|    explained_variance   | 0.962       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.028       |
|    n_updates            | 1880        |
|    policy_gradient_loss | -0.00922    |
|    std                  | 0.201       |
|    value_loss           | 0.0277      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 320         |
|    ep_rew_mean          | 308.32098   |
| time/                   |             |
|    fps                  | 67          |
|    iterations           | 190         |
|    time_elapsed         | 11460       |
|    total_timesteps      | 778240      |
| train/                  |             |
|    approx_kl            | 0.024990622 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.65        |
|    explained_variance   | 0.947       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00293    |
|    n_updates            | 1890        |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.2         |
|    value_loss           | 0.0365      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.202       |
|    cost_of_transport    | 174         |
|    mean_ep_length       | 368         |
|    mean_reward          | 2.74e+04    |
|    speed                | 1.44        |
|    speed_penalty        | 0.0107      |
| time/                   |             |
|    total timesteps      | 780000      |
| train/                  |             |
|    approx_kl            | 0.020629149 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.69        |
|    explained_variance   | 0.958       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00995    |
|    n_updates            | 1900        |
|    policy_gradient_loss | -0.00873    |
|    std                  | 0.199       |
|    value_loss           | 0.0226      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 318       |
|    ep_rew_mean     | 308.17764 |
| time/              |           |
|    fps             | 67        |
|    iterations      | 191       |
|    time_elapsed    | 11524     |
|    total_timesteps | 782336    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 319         |
|    ep_rew_mean          | 309.2993    |
| time/                   |             |
|    fps                  | 67          |
|    iterations           | 192         |
|    time_elapsed         | 11565       |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.025864996 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.7         |
|    explained_variance   | 0.963       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00165    |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.0102     |
|    std                  | 0.199       |
|    value_loss           | 0.0237      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.208       |
|    cost_of_transport    | 170         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.5         |
|    speed_penalty        | 0.0104      |
| time/                   |             |
|    total timesteps      | 790000      |
| train/                  |             |
|    approx_kl            | 0.019177184 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.71        |
|    explained_variance   | 0.968       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0157      |
|    n_updates            | 1920        |
|    policy_gradient_loss | -0.00848    |
|    std                  | 0.199       |
|    value_loss           | 0.0258      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 322       |
|    ep_rew_mean     | 313.27145 |
| time/              |           |
|    fps             | 67        |
|    iterations      | 193       |
|    time_elapsed    | 11629     |
|    total_timesteps | 790528    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 325         |
|    ep_rew_mean          | 315.91464   |
| time/                   |             |
|    fps                  | 68          |
|    iterations           | 194         |
|    time_elapsed         | 11670       |
|    total_timesteps      | 794624      |
| train/                  |             |
|    approx_kl            | 0.025461879 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.7         |
|    explained_variance   | 0.955       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0133     |
|    n_updates            | 1930        |
|    policy_gradient_loss | -0.00944    |
|    std                  | 0.199       |
|    value_loss           | 0.0305      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 329         |
|    ep_rew_mean          | 319.28366   |
| time/                   |             |
|    fps                  | 68          |
|    iterations           | 195         |
|    time_elapsed         | 11712       |
|    total_timesteps      | 798720      |
| train/                  |             |
|    approx_kl            | 0.020681785 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.72        |
|    explained_variance   | 0.957       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0258     |
|    n_updates            | 1940        |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.199       |
|    value_loss           | 0.0222      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.189       |
|    cost_of_transport    | 167         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.46        |
|    speed_penalty        | 0.0161      |
| time/                   |             |
|    total timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.021577975 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.73        |
|    explained_variance   | 0.941       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0148      |
|    n_updates            | 1950        |
|    policy_gradient_loss | -0.00815    |
|    std                  | 0.199       |
|    value_loss           | 0.0326      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 327       |
|    ep_rew_mean     | 317.65323 |
| time/              |           |
|    fps             | 68        |
|    iterations      | 196       |
|    time_elapsed    | 11779     |
|    total_timesteps | 802816    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 326         |
|    ep_rew_mean          | 317.0689    |
| time/                   |             |
|    fps                  | 68          |
|    iterations           | 197         |
|    time_elapsed         | 11821       |
|    total_timesteps      | 806912      |
| train/                  |             |
|    approx_kl            | 0.022404527 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.71        |
|    explained_variance   | 0.943       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0453      |
|    n_updates            | 1960        |
|    policy_gradient_loss | -0.00955    |
|    std                  | 0.199       |
|    value_loss           | 0.0326      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.208       |
|    cost_of_transport    | 177         |
|    mean_ep_length       | 359         |
|    mean_reward          | 2.67e+04    |
|    speed                | 1.41        |
|    speed_penalty        | 0.0101      |
| time/                   |             |
|    total timesteps      | 810000      |
| train/                  |             |
|    approx_kl            | 0.028400827 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.72        |
|    explained_variance   | 0.94        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00129     |
|    n_updates            | 1970        |
|    policy_gradient_loss | -0.0102     |
|    std                  | 0.199       |
|    value_loss           | 0.0372      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 325       |
|    ep_rew_mean     | 316.19656 |
| time/              |           |
|    fps             | 68        |
|    iterations      | 198       |
|    time_elapsed    | 11884     |
|    total_timesteps | 811008    |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 327        |
|    ep_rew_mean          | 317.52676  |
| time/                   |            |
|    fps                  | 68         |
|    iterations           | 199        |
|    time_elapsed         | 11925      |
|    total_timesteps      | 815104     |
| train/                  |            |
|    approx_kl            | 0.02707836 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.73       |
|    explained_variance   | 0.958      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0503     |
|    n_updates            | 1980       |
|    policy_gradient_loss | -0.0103    |
|    std                  | 0.199      |
|    value_loss           | 0.0274     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 326         |
|    ep_rew_mean          | 316.3205    |
| time/                   |             |
|    fps                  | 68          |
|    iterations           | 200         |
|    time_elapsed         | 11967       |
|    total_timesteps      | 819200      |
| train/                  |             |
|    approx_kl            | 0.023342865 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.74        |
|    explained_variance   | 0.951       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00278    |
|    n_updates            | 1990        |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.199       |
|    value_loss           | 0.0327      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.237       |
|    cost_of_transport    | 176         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.43        |
|    speed_penalty        | 0.022       |
| time/                   |             |
|    total timesteps      | 820000      |
| train/                  |             |
|    approx_kl            | 0.024836766 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.76        |
|    explained_variance   | 0.952       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.000874   |
|    n_updates            | 2000        |
|    policy_gradient_loss | -0.00799    |
|    std                  | 0.198       |
|    value_loss           | 0.0295      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 329       |
|    ep_rew_mean     | 318.37097 |
| time/              |           |
|    fps             | 68        |
|    iterations      | 201       |
|    time_elapsed    | 12031     |
|    total_timesteps | 823296    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 329         |
|    ep_rew_mean          | 318.06815   |
| time/                   |             |
|    fps                  | 68          |
|    iterations           | 202         |
|    time_elapsed         | 12073       |
|    total_timesteps      | 827392      |
| train/                  |             |
|    approx_kl            | 0.020648897 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.77        |
|    explained_variance   | 0.965       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0169     |
|    n_updates            | 2010        |
|    policy_gradient_loss | -0.00602    |
|    std                  | 0.198       |
|    value_loss           | 0.0234      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.238       |
|    cost_of_transport    | 177         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.45        |
|    speed_penalty        | 0.0242      |
| time/                   |             |
|    total timesteps      | 830000      |
| train/                  |             |
|    approx_kl            | 0.025703717 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.78        |
|    explained_variance   | 0.958       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0264      |
|    n_updates            | 2020        |
|    policy_gradient_loss | -0.0104     |
|    std                  | 0.198       |
|    value_loss           | 0.0289      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 326       |
|    ep_rew_mean     | 315.91882 |
| time/              |           |
|    fps             | 68        |
|    iterations      | 203       |
|    time_elapsed    | 12138     |
|    total_timesteps | 831488    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 329         |
|    ep_rew_mean          | 318.1581    |
| time/                   |             |
|    fps                  | 68          |
|    iterations           | 204         |
|    time_elapsed         | 12179       |
|    total_timesteps      | 835584      |
| train/                  |             |
|    approx_kl            | 0.024965748 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.77        |
|    explained_variance   | 0.939       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.017       |
|    n_updates            | 2030        |
|    policy_gradient_loss | -0.0086     |
|    std                  | 0.198       |
|    value_loss           | 0.0392      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 338         |
|    ep_rew_mean          | 326.56183   |
| time/                   |             |
|    fps                  | 68          |
|    iterations           | 205         |
|    time_elapsed         | 12221       |
|    total_timesteps      | 839680      |
| train/                  |             |
|    approx_kl            | 0.020247407 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.77        |
|    explained_variance   | 0.969       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0202     |
|    n_updates            | 2040        |
|    policy_gradient_loss | -0.00901    |
|    std                  | 0.198       |
|    value_loss           | 0.0188      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.231      |
|    cost_of_transport    | 171        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.43       |
|    speed_penalty        | 0.0213     |
| time/                   |            |
|    total timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.02270176 |
|    clip_fraction        | 0.261      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.78       |
|    explained_variance   | 0.947      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0221     |
|    n_updates            | 2050       |
|    policy_gradient_loss | -0.00844   |
|    std                  | 0.198      |
|    value_loss           | 0.0306     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 340       |
|    ep_rew_mean     | 327.74948 |
| time/              |           |
|    fps             | 68        |
|    iterations      | 206       |
|    time_elapsed    | 12287     |
|    total_timesteps | 843776    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 344         |
|    ep_rew_mean          | 331.4435    |
| time/                   |             |
|    fps                  | 68          |
|    iterations           | 207         |
|    time_elapsed         | 12328       |
|    total_timesteps      | 847872      |
| train/                  |             |
|    approx_kl            | 0.023444932 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.78        |
|    explained_variance   | 0.941       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00941     |
|    n_updates            | 2060        |
|    policy_gradient_loss | -0.00841    |
|    std                  | 0.198       |
|    value_loss           | 0.0315      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.238      |
|    cost_of_transport    | 171        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.48       |
|    speed_penalty        | 0.0141     |
| time/                   |            |
|    total timesteps      | 850000     |
| train/                  |            |
|    approx_kl            | 0.02224211 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.78       |
|    explained_variance   | 0.941      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0099    |
|    n_updates            | 2070       |
|    policy_gradient_loss | -0.00684   |
|    std                  | 0.198      |
|    value_loss           | 0.0359     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 342       |
|    ep_rew_mean     | 330.59082 |
| time/              |           |
|    fps             | 68        |
|    iterations      | 208       |
|    time_elapsed    | 12394     |
|    total_timesteps | 851968    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 343         |
|    ep_rew_mean          | 331.02292   |
| time/                   |             |
|    fps                  | 68          |
|    iterations           | 209         |
|    time_elapsed         | 12436       |
|    total_timesteps      | 856064      |
| train/                  |             |
|    approx_kl            | 0.026475217 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.78        |
|    explained_variance   | 0.955       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00436     |
|    n_updates            | 2080        |
|    policy_gradient_loss | -0.00761    |
|    std                  | 0.198       |
|    value_loss           | 0.0264      |
-----------------------------------------
---------------------------------------
| eval/                   |           |
|    action_norm_penalty  | 0.21      |
|    cost_of_transport    | 173       |
|    mean_ep_length       | 400       |
|    mean_reward          | 2.98e+04  |
|    speed                | 1.41      |
|    speed_penalty        | 0.0313    |
| time/                   |           |
|    total timesteps      | 860000    |
| train/                  |           |
|    approx_kl            | 0.0215374 |
|    clip_fraction        | 0.271     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.78      |
|    explained_variance   | 0.962     |
|    learning_rate        | 0.0001    |
|    loss                 | 0.0162    |
|    n_updates            | 2090      |
|    policy_gradient_loss | -0.00641  |
|    std                  | 0.198     |
|    value_loss           | 0.0252    |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 341      |
|    ep_rew_mean     | 329.0924 |
| time/              |          |
|    fps             | 68       |
|    iterations      | 210      |
|    time_elapsed    | 12501    |
|    total_timesteps | 860160   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 341         |
|    ep_rew_mean          | 329.54337   |
| time/                   |             |
|    fps                  | 68          |
|    iterations           | 211         |
|    time_elapsed         | 12543       |
|    total_timesteps      | 864256      |
| train/                  |             |
|    approx_kl            | 0.022990873 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.8         |
|    explained_variance   | 0.95        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00684     |
|    n_updates            | 2100        |
|    policy_gradient_loss | -0.00321    |
|    std                  | 0.198       |
|    value_loss           | 0.0308      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 348         |
|    ep_rew_mean          | 335.27612   |
| time/                   |             |
|    fps                  | 69          |
|    iterations           | 212         |
|    time_elapsed         | 12584       |
|    total_timesteps      | 868352      |
| train/                  |             |
|    approx_kl            | 0.023510957 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.82        |
|    explained_variance   | 0.953       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00498    |
|    n_updates            | 2110        |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.197       |
|    value_loss           | 0.0269      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.238      |
|    cost_of_transport    | 176        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.42       |
|    speed_penalty        | 0.024      |
| time/                   |            |
|    total timesteps      | 870000     |
| train/                  |            |
|    approx_kl            | 0.02428518 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.85       |
|    explained_variance   | 0.953      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0195     |
|    n_updates            | 2120       |
|    policy_gradient_loss | -0.00801   |
|    std                  | 0.196      |
|    value_loss           | 0.031      |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 349       |
|    ep_rew_mean     | 335.61157 |
| time/              |           |
|    fps             | 68        |
|    iterations      | 213       |
|    time_elapsed    | 12649     |
|    total_timesteps | 872448    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 349         |
|    ep_rew_mean          | 336.72177   |
| time/                   |             |
|    fps                  | 69          |
|    iterations           | 214         |
|    time_elapsed         | 12690       |
|    total_timesteps      | 876544      |
| train/                  |             |
|    approx_kl            | 0.024278652 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.86        |
|    explained_variance   | 0.956       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0038     |
|    n_updates            | 2130        |
|    policy_gradient_loss | -0.00605    |
|    std                  | 0.197       |
|    value_loss           | 0.03        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.253       |
|    cost_of_transport    | 172         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.41        |
|    speed_penalty        | 0.0267      |
| time/                   |             |
|    total timesteps      | 880000      |
| train/                  |             |
|    approx_kl            | 0.024148684 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.87        |
|    explained_variance   | 0.946       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0291      |
|    n_updates            | 2140        |
|    policy_gradient_loss | -0.00728    |
|    std                  | 0.196       |
|    value_loss           | 0.034       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 352       |
|    ep_rew_mean     | 340.13123 |
| time/              |           |
|    fps             | 69        |
|    iterations      | 215       |
|    time_elapsed    | 12755     |
|    total_timesteps | 880640    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 355         |
|    ep_rew_mean          | 342.47952   |
| time/                   |             |
|    fps                  | 69          |
|    iterations           | 216         |
|    time_elapsed         | 12796       |
|    total_timesteps      | 884736      |
| train/                  |             |
|    approx_kl            | 0.024416316 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.89        |
|    explained_variance   | 0.961       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.000507   |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.00699    |
|    std                  | 0.196       |
|    value_loss           | 0.0199      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 355         |
|    ep_rew_mean          | 342.30508   |
| time/                   |             |
|    fps                  | 69          |
|    iterations           | 217         |
|    time_elapsed         | 12837       |
|    total_timesteps      | 888832      |
| train/                  |             |
|    approx_kl            | 0.025920749 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.9         |
|    explained_variance   | 0.945       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0289      |
|    n_updates            | 2160        |
|    policy_gradient_loss | -0.00628    |
|    std                  | 0.195       |
|    value_loss           | 0.0378      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.265       |
|    cost_of_transport    | 177         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.43        |
|    speed_penalty        | 0.0218      |
| time/                   |             |
|    total timesteps      | 890000      |
| train/                  |             |
|    approx_kl            | 0.025924208 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.92        |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0158     |
|    n_updates            | 2170        |
|    policy_gradient_loss | -0.0112     |
|    std                  | 0.195       |
|    value_loss           | 0.0366      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 359       |
|    ep_rew_mean     | 346.39276 |
| time/              |           |
|    fps             | 69        |
|    iterations      | 218       |
|    time_elapsed    | 12903     |
|    total_timesteps | 892928    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 362         |
|    ep_rew_mean          | 348.78757   |
| time/                   |             |
|    fps                  | 69          |
|    iterations           | 219         |
|    time_elapsed         | 12945       |
|    total_timesteps      | 897024      |
| train/                  |             |
|    approx_kl            | 0.028270863 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.92        |
|    explained_variance   | 0.938       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0166      |
|    n_updates            | 2180        |
|    policy_gradient_loss | -0.00716    |
|    std                  | 0.195       |
|    value_loss           | 0.0335      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.254       |
|    cost_of_transport    | 173         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.5         |
|    speed_penalty        | 0.00832     |
| time/                   |             |
|    total timesteps      | 900000      |
| train/                  |             |
|    approx_kl            | 0.034020513 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.92        |
|    explained_variance   | 0.954       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0146     |
|    n_updates            | 2190        |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.195       |
|    value_loss           | 0.0284      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 362      |
|    ep_rew_mean     | 349.4243 |
| time/              |          |
|    fps             | 69       |
|    iterations      | 220      |
|    time_elapsed    | 13009    |
|    total_timesteps | 901120   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 363         |
|    ep_rew_mean          | 350.5275    |
| time/                   |             |
|    fps                  | 69          |
|    iterations           | 221         |
|    time_elapsed         | 13050       |
|    total_timesteps      | 905216      |
| train/                  |             |
|    approx_kl            | 0.025905617 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.93        |
|    explained_variance   | 0.935       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0241     |
|    n_updates            | 2200        |
|    policy_gradient_loss | -0.00754    |
|    std                  | 0.195       |
|    value_loss           | 0.0387      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 364        |
|    ep_rew_mean          | 352.0199   |
| time/                   |            |
|    fps                  | 69         |
|    iterations           | 222        |
|    time_elapsed         | 13092      |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.02827362 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.92       |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0204     |
|    n_updates            | 2210       |
|    policy_gradient_loss | -0.00968   |
|    std                  | 0.195      |
|    value_loss           | 0.0366     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.222       |
|    cost_of_transport    | 173         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.55        |
|    speed_penalty        | 0.00554     |
| time/                   |             |
|    total timesteps      | 910000      |
| train/                  |             |
|    approx_kl            | 0.030797023 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.94        |
|    explained_variance   | 0.933       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0105     |
|    n_updates            | 2220        |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.194       |
|    value_loss           | 0.036       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 364       |
|    ep_rew_mean     | 352.59216 |
| time/              |           |
|    fps             | 69        |
|    iterations      | 223       |
|    time_elapsed    | 13157     |
|    total_timesteps | 913408    |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 358        |
|    ep_rew_mean          | 347.75854  |
| time/                   |            |
|    fps                  | 69         |
|    iterations           | 224        |
|    time_elapsed         | 13198      |
|    total_timesteps      | 917504     |
| train/                  |            |
|    approx_kl            | 0.02504352 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.96       |
|    explained_variance   | 0.946      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0277     |
|    n_updates            | 2230       |
|    policy_gradient_loss | -0.0104    |
|    std                  | 0.194      |
|    value_loss           | 0.0351     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.215       |
|    cost_of_transport    | 169         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.54        |
|    speed_penalty        | 0.00437     |
| time/                   |             |
|    total timesteps      | 920000      |
| train/                  |             |
|    approx_kl            | 0.027568556 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.97        |
|    explained_variance   | 0.924       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0216     |
|    n_updates            | 2240        |
|    policy_gradient_loss | -0.0081     |
|    std                  | 0.194       |
|    value_loss           | 0.0341      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 355      |
|    ep_rew_mean     | 345.8807 |
| time/              |          |
|    fps             | 69       |
|    iterations      | 225      |
|    time_elapsed    | 13263    |
|    total_timesteps | 921600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 354         |
|    ep_rew_mean          | 345.49942   |
| time/                   |             |
|    fps                  | 69          |
|    iterations           | 226         |
|    time_elapsed         | 13304       |
|    total_timesteps      | 925696      |
| train/                  |             |
|    approx_kl            | 0.027449053 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.99        |
|    explained_variance   | 0.932       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00939     |
|    n_updates            | 2250        |
|    policy_gradient_loss | -0.00613    |
|    std                  | 0.193       |
|    value_loss           | 0.0375      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 352        |
|    ep_rew_mean          | 343.58868  |
| time/                   |            |
|    fps                  | 69         |
|    iterations           | 227        |
|    time_elapsed         | 13347      |
|    total_timesteps      | 929792     |
| train/                  |            |
|    approx_kl            | 0.02586713 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.98       |
|    explained_variance   | 0.926      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0242     |
|    n_updates            | 2260       |
|    policy_gradient_loss | -0.0108    |
|    std                  | 0.194      |
|    value_loss           | 0.0432     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.23        |
|    cost_of_transport    | 167         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.54        |
|    speed_penalty        | 0.00488     |
| time/                   |             |
|    total timesteps      | 930000      |
| train/                  |             |
|    approx_kl            | 0.025829498 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.94        |
|    explained_variance   | 0.926       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0576      |
|    n_updates            | 2270        |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.195       |
|    value_loss           | 0.041       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 355       |
|    ep_rew_mean     | 347.27512 |
| time/              |           |
|    fps             | 69        |
|    iterations      | 228       |
|    time_elapsed    | 13411     |
|    total_timesteps | 933888    |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 354        |
|    ep_rew_mean          | 346.1606   |
| time/                   |            |
|    fps                  | 69         |
|    iterations           | 229        |
|    time_elapsed         | 13453      |
|    total_timesteps      | 937984     |
| train/                  |            |
|    approx_kl            | 0.02087953 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.92       |
|    explained_variance   | 0.931      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0354     |
|    n_updates            | 2280       |
|    policy_gradient_loss | -0.00522   |
|    std                  | 0.195      |
|    value_loss           | 0.0382     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.19        |
|    cost_of_transport    | 166         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.51        |
|    speed_penalty        | 0.00596     |
| time/                   |             |
|    total timesteps      | 940000      |
| train/                  |             |
|    approx_kl            | 0.027649017 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.93        |
|    explained_variance   | 0.947       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0113     |
|    n_updates            | 2290        |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.195       |
|    value_loss           | 0.0285      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 354       |
|    ep_rew_mean     | 346.61493 |
| time/              |           |
|    fps             | 69        |
|    iterations      | 230       |
|    time_elapsed    | 13518     |
|    total_timesteps | 942080    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 353         |
|    ep_rew_mean          | 345.6987    |
| time/                   |             |
|    fps                  | 69          |
|    iterations           | 231         |
|    time_elapsed         | 13561       |
|    total_timesteps      | 946176      |
| train/                  |             |
|    approx_kl            | 0.025667816 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.94        |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0057     |
|    n_updates            | 2300        |
|    policy_gradient_loss | -0.00876    |
|    std                  | 0.195       |
|    value_loss           | 0.0421      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.183       |
|    cost_of_transport    | 172         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.54        |
|    speed_penalty        | 0.00558     |
| time/                   |             |
|    total timesteps      | 950000      |
| train/                  |             |
|    approx_kl            | 0.025353253 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.94        |
|    explained_variance   | 0.923       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0252      |
|    n_updates            | 2310        |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.195       |
|    value_loss           | 0.0402      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 351      |
|    ep_rew_mean     | 343.8972 |
| time/              |          |
|    fps             | 69       |
|    iterations      | 232      |
|    time_elapsed    | 13627    |
|    total_timesteps | 950272   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 348         |
|    ep_rew_mean          | 341.7407    |
| time/                   |             |
|    fps                  | 69          |
|    iterations           | 233         |
|    time_elapsed         | 13671       |
|    total_timesteps      | 954368      |
| train/                  |             |
|    approx_kl            | 0.026132409 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.94        |
|    explained_variance   | 0.925       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0416      |
|    n_updates            | 2320        |
|    policy_gradient_loss | -0.00696    |
|    std                  | 0.195       |
|    value_loss           | 0.0436      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 346        |
|    ep_rew_mean          | 338.95358  |
| time/                   |            |
|    fps                  | 69         |
|    iterations           | 234        |
|    time_elapsed         | 13714      |
|    total_timesteps      | 958464     |
| train/                  |            |
|    approx_kl            | 0.03400837 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.95       |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0189     |
|    n_updates            | 2330       |
|    policy_gradient_loss | -0.00907   |
|    std                  | 0.195      |
|    value_loss           | 0.039      |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.213       |
|    cost_of_transport    | 168         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.54        |
|    speed_penalty        | 0.00539     |
| time/                   |             |
|    total timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.026419535 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.96        |
|    explained_variance   | 0.888       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0254      |
|    n_updates            | 2340        |
|    policy_gradient_loss | -0.00773    |
|    std                  | 0.195       |
|    value_loss           | 0.0705      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 343      |
|    ep_rew_mean     | 336.4453 |
| time/              |          |
|    fps             | 69       |
|    iterations      | 235      |
|    time_elapsed    | 13781    |
|    total_timesteps | 962560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 342         |
|    ep_rew_mean          | 335.73688   |
| time/                   |             |
|    fps                  | 69          |
|    iterations           | 236         |
|    time_elapsed         | 13823       |
|    total_timesteps      | 966656      |
| train/                  |             |
|    approx_kl            | 0.025902241 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.97        |
|    explained_variance   | 0.931       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0168     |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.194       |
|    value_loss           | 0.0399      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.185       |
|    cost_of_transport    | 167         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.56        |
|    speed_penalty        | 0.00444     |
| time/                   |             |
|    total timesteps      | 970000      |
| train/                  |             |
|    approx_kl            | 0.025213253 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.99        |
|    explained_variance   | 0.932       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0226     |
|    n_updates            | 2360        |
|    policy_gradient_loss | -0.00844    |
|    std                  | 0.194       |
|    value_loss           | 0.0362      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 342       |
|    ep_rew_mean     | 335.83585 |
| time/              |           |
|    fps             | 69        |
|    iterations      | 237       |
|    time_elapsed    | 13889     |
|    total_timesteps | 970752    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 344         |
|    ep_rew_mean          | 337.54288   |
| time/                   |             |
|    fps                  | 69          |
|    iterations           | 238         |
|    time_elapsed         | 13931       |
|    total_timesteps      | 974848      |
| train/                  |             |
|    approx_kl            | 0.024274027 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.01        |
|    explained_variance   | 0.941       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0148      |
|    n_updates            | 2370        |
|    policy_gradient_loss | -0.00563    |
|    std                  | 0.193       |
|    value_loss           | 0.0313      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 347        |
|    ep_rew_mean          | 340.35532  |
| time/                   |            |
|    fps                  | 70         |
|    iterations           | 239        |
|    time_elapsed         | 13972      |
|    total_timesteps      | 978944     |
| train/                  |            |
|    approx_kl            | 0.02484157 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.03       |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0163     |
|    n_updates            | 2380       |
|    policy_gradient_loss | -0.00703   |
|    std                  | 0.193      |
|    value_loss           | 0.0529     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.202       |
|    cost_of_transport    | 169         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.54        |
|    speed_penalty        | 0.00553     |
| time/                   |             |
|    total timesteps      | 980000      |
| train/                  |             |
|    approx_kl            | 0.027525982 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.03        |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.005      |
|    n_updates            | 2390        |
|    policy_gradient_loss | -0.00672    |
|    std                  | 0.193       |
|    value_loss           | 0.0542      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 350       |
|    ep_rew_mean     | 343.05276 |
| time/              |           |
|    fps             | 70        |
|    iterations      | 240       |
|    time_elapsed    | 14038     |
|    total_timesteps | 983040    |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 354       |
|    ep_rew_mean          | 346.8047  |
| time/                   |           |
|    fps                  | 70        |
|    iterations           | 241       |
|    time_elapsed         | 14080     |
|    total_timesteps      | 987136    |
| train/                  |           |
|    approx_kl            | 0.0260147 |
|    clip_fraction        | 0.287     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.02      |
|    explained_variance   | 0.915     |
|    learning_rate        | 0.0001    |
|    loss                 | 0.0113    |
|    n_updates            | 2400      |
|    policy_gradient_loss | -0.00657  |
|    std                  | 0.194     |
|    value_loss           | 0.0358    |
---------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.226      |
|    cost_of_transport    | 169        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.53       |
|    speed_penalty        | 0.00591    |
| time/                   |            |
|    total timesteps      | 990000     |
| train/                  |            |
|    approx_kl            | 0.02313129 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.01       |
|    explained_variance   | 0.917      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0114    |
|    n_updates            | 2410       |
|    policy_gradient_loss | -0.00961   |
|    std                  | 0.194      |
|    value_loss           | 0.0427     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 356       |
|    ep_rew_mean     | 349.00183 |
| time/              |           |
|    fps             | 70        |
|    iterations      | 242       |
|    time_elapsed    | 14146     |
|    total_timesteps | 991232    |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 363         |
|    ep_rew_mean          | 355.17456   |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 243         |
|    time_elapsed         | 14188       |
|    total_timesteps      | 995328      |
| train/                  |             |
|    approx_kl            | 0.024197973 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2           |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0145      |
|    n_updates            | 2420        |
|    policy_gradient_loss | -0.00874    |
|    std                  | 0.194       |
|    value_loss           | 0.047       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 365         |
|    ep_rew_mean          | 357.92554   |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 244         |
|    time_elapsed         | 14231       |
|    total_timesteps      | 999424      |
| train/                  |             |
|    approx_kl            | 0.029215135 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2           |
|    explained_variance   | 0.942       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00196    |
|    n_updates            | 2430        |
|    policy_gradient_loss | -0.0087     |
|    std                  | 0.194       |
|    value_loss           | 0.0281      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.199       |
|    cost_of_transport    | 168         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.53        |
|    speed_penalty        | 0.00655     |
| time/                   |             |
|    total timesteps      | 1000000     |
| train/                  |             |
|    approx_kl            | 0.027660063 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.99        |
|    explained_variance   | 0.936       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00472    |
|    n_updates            | 2440        |
|    policy_gradient_loss | -0.00947    |
|    std                  | 0.194       |
|    value_loss           | 0.0358      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 369       |
|    ep_rew_mean     | 361.72757 |
| time/              |           |
|    fps             | 70        |
|    iterations      | 245       |
|    time_elapsed    | 14299     |
|    total_timesteps | 1003520   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 367         |
|    ep_rew_mean          | 359.75504   |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 246         |
|    time_elapsed         | 14341       |
|    total_timesteps      | 1007616     |
| train/                  |             |
|    approx_kl            | 0.026220264 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.99        |
|    explained_variance   | 0.927       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.000151   |
|    n_updates            | 2450        |
|    policy_gradient_loss | -0.00825    |
|    std                  | 0.194       |
|    value_loss           | 0.0457      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.199       |
|    cost_of_transport    | 165         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.55        |
|    speed_penalty        | 0.00551     |
| time/                   |             |
|    total timesteps      | 1010000     |
| train/                  |             |
|    approx_kl            | 0.027000815 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2           |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0161      |
|    n_updates            | 2460        |
|    policy_gradient_loss | -0.00969    |
|    std                  | 0.194       |
|    value_loss           | 0.0362      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 371       |
|    ep_rew_mean     | 363.51337 |
| time/              |           |
|    fps             | 70        |
|    iterations      | 247       |
|    time_elapsed    | 14410     |
|    total_timesteps | 1011712   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 365         |
|    ep_rew_mean          | 357.6962    |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 248         |
|    time_elapsed         | 14453       |
|    total_timesteps      | 1015808     |
| train/                  |             |
|    approx_kl            | 0.025816843 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2           |
|    explained_variance   | 0.926       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00721     |
|    n_updates            | 2470        |
|    policy_gradient_loss | -0.0073     |
|    std                  | 0.193       |
|    value_loss           | 0.0389      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 366         |
|    ep_rew_mean          | 358.71628   |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 249         |
|    time_elapsed         | 14496       |
|    total_timesteps      | 1019904     |
| train/                  |             |
|    approx_kl            | 0.029179437 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.01        |
|    explained_variance   | 0.929       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0306     |
|    n_updates            | 2480        |
|    policy_gradient_loss | -0.00838    |
|    std                  | 0.193       |
|    value_loss           | 0.0381      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.201       |
|    cost_of_transport    | 159         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.56        |
|    speed_penalty        | 0.0057      |
| time/                   |             |
|    total timesteps      | 1020000     |
| train/                  |             |
|    approx_kl            | 0.024294108 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.03        |
|    explained_variance   | 0.923       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0269     |
|    n_updates            | 2490        |
|    policy_gradient_loss | -0.00913    |
|    std                  | 0.192       |
|    value_loss           | 0.0451      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 358       |
|    ep_rew_mean     | 350.85492 |
| time/              |           |
|    fps             | 70        |
|    iterations      | 250       |
|    time_elapsed    | 14566     |
|    total_timesteps | 1024000   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 360         |
|    ep_rew_mean          | 352.7246    |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 251         |
|    time_elapsed         | 14610       |
|    total_timesteps      | 1028096     |
| train/                  |             |
|    approx_kl            | 0.027690437 |
|    clip_fraction        | 0.325       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.03        |
|    explained_variance   | 0.862       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.000737    |
|    n_updates            | 2500        |
|    policy_gradient_loss | -0.0085     |
|    std                  | 0.193       |
|    value_loss           | 0.0555      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.186       |
|    cost_of_transport    | 164         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.54        |
|    speed_penalty        | 0.00742     |
| time/                   |             |
|    total timesteps      | 1030000     |
| train/                  |             |
|    approx_kl            | 0.022265913 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.04        |
|    explained_variance   | 0.901       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0735      |
|    n_updates            | 2510        |
|    policy_gradient_loss | -0.00863    |
|    std                  | 0.192       |
|    value_loss           | 0.0552      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 359       |
|    ep_rew_mean     | 351.92618 |
| time/              |           |
|    fps             | 70        |
|    iterations      | 252       |
|    time_elapsed    | 14679     |
|    total_timesteps | 1032192   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 361         |
|    ep_rew_mean          | 354.15594   |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 253         |
|    time_elapsed         | 14722       |
|    total_timesteps      | 1036288     |
| train/                  |             |
|    approx_kl            | 0.026157878 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.07        |
|    explained_variance   | 0.932       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0461      |
|    n_updates            | 2520        |
|    policy_gradient_loss | -0.00904    |
|    std                  | 0.192       |
|    value_loss           | 0.0377      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.197       |
|    cost_of_transport    | 167         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.55        |
|    speed_penalty        | 0.00571     |
| time/                   |             |
|    total timesteps      | 1040000     |
| train/                  |             |
|    approx_kl            | 0.027996298 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.08        |
|    explained_variance   | 0.916       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.026       |
|    n_updates            | 2530        |
|    policy_gradient_loss | -0.0103     |
|    std                  | 0.191       |
|    value_loss           | 0.0457      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 361      |
|    ep_rew_mean     | 354.1164 |
| time/              |          |
|    fps             | 70       |
|    iterations      | 254      |
|    time_elapsed    | 14791    |
|    total_timesteps | 1040384  |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 362       |
|    ep_rew_mean          | 354.8013  |
| time/                   |           |
|    fps                  | 70        |
|    iterations           | 255       |
|    time_elapsed         | 14833     |
|    total_timesteps      | 1044480   |
| train/                  |           |
|    approx_kl            | 0.0289968 |
|    clip_fraction        | 0.291     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.07      |
|    explained_variance   | 0.92      |
|    learning_rate        | 0.0001    |
|    loss                 | 0.0351    |
|    n_updates            | 2540      |
|    policy_gradient_loss | -0.00851  |
|    std                  | 0.192     |
|    value_loss           | 0.0427    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 361        |
|    ep_rew_mean          | 353.85892  |
| time/                   |            |
|    fps                  | 70         |
|    iterations           | 256        |
|    time_elapsed         | 14877      |
|    total_timesteps      | 1048576    |
| train/                  |            |
|    approx_kl            | 0.02378567 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.07       |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.0001     |
|    loss                 | -8.54e-05  |
|    n_updates            | 2550       |
|    policy_gradient_loss | -0.00604   |
|    std                  | 0.192      |
|    value_loss           | 0.0386     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.178       |
|    cost_of_transport    | 163         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.57        |
|    speed_penalty        | 0.0048      |
| time/                   |             |
|    total timesteps      | 1050000     |
| train/                  |             |
|    approx_kl            | 0.024507497 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.07        |
|    explained_variance   | 0.919       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00502    |
|    n_updates            | 2560        |
|    policy_gradient_loss | -0.00527    |
|    std                  | 0.192       |
|    value_loss           | 0.0438      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 363       |
|    ep_rew_mean     | 355.76254 |
| time/              |           |
|    fps             | 70        |
|    iterations      | 257       |
|    time_elapsed    | 14945     |
|    total_timesteps | 1052672   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 364         |
|    ep_rew_mean          | 356.90836   |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 258         |
|    time_elapsed         | 14987       |
|    total_timesteps      | 1056768     |
| train/                  |             |
|    approx_kl            | 0.027354177 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.06        |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0228      |
|    n_updates            | 2570        |
|    policy_gradient_loss | -0.0102     |
|    std                  | 0.192       |
|    value_loss           | 0.0483      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.185       |
|    cost_of_transport    | 167         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.54        |
|    speed_penalty        | 0.00855     |
| time/                   |             |
|    total timesteps      | 1060000     |
| train/                  |             |
|    approx_kl            | 0.022777127 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.05        |
|    explained_variance   | 0.91        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0169      |
|    n_updates            | 2580        |
|    policy_gradient_loss | -0.0052     |
|    std                  | 0.192       |
|    value_loss           | 0.0473      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 372       |
|    ep_rew_mean     | 364.69327 |
| time/              |           |
|    fps             | 70        |
|    iterations      | 259       |
|    time_elapsed    | 15054     |
|    total_timesteps | 1060864   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 372         |
|    ep_rew_mean          | 364.48428   |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 260         |
|    time_elapsed         | 15097       |
|    total_timesteps      | 1064960     |
| train/                  |             |
|    approx_kl            | 0.024890428 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.05        |
|    explained_variance   | 0.929       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.000942    |
|    n_updates            | 2590        |
|    policy_gradient_loss | -0.00855    |
|    std                  | 0.193       |
|    value_loss           | 0.0385      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 375         |
|    ep_rew_mean          | 367.0284    |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 261         |
|    time_elapsed         | 15139       |
|    total_timesteps      | 1069056     |
| train/                  |             |
|    approx_kl            | 0.026310699 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.05        |
|    explained_variance   | 0.93        |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0398     |
|    n_updates            | 2600        |
|    policy_gradient_loss | -0.00623    |
|    std                  | 0.192       |
|    value_loss           | 0.0383      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.178      |
|    cost_of_transport    | 166        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.49       |
|    speed_penalty        | 0.012      |
| time/                   |            |
|    total timesteps      | 1070000    |
| train/                  |            |
|    approx_kl            | 0.02984206 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.06       |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.0001     |
|    loss                 | -0.00815   |
|    n_updates            | 2610       |
|    policy_gradient_loss | -0.0128    |
|    std                  | 0.192      |
|    value_loss           | 0.0414     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 374      |
|    ep_rew_mean     | 365.9423 |
| time/              |          |
|    fps             | 70       |
|    iterations      | 262      |
|    time_elapsed    | 15207    |
|    total_timesteps | 1073152  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 374         |
|    ep_rew_mean          | 365.47      |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 263         |
|    time_elapsed         | 15250       |
|    total_timesteps      | 1077248     |
| train/                  |             |
|    approx_kl            | 0.025821362 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.06        |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00914    |
|    n_updates            | 2620        |
|    policy_gradient_loss | -0.01       |
|    std                  | 0.192       |
|    value_loss           | 0.0416      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.198      |
|    cost_of_transport    | 177        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.49       |
|    speed_penalty        | 0.0104     |
| time/                   |            |
|    total timesteps      | 1080000    |
| train/                  |            |
|    approx_kl            | 0.02549125 |
|    clip_fraction        | 0.286      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.06       |
|    explained_variance   | 0.917      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.00444    |
|    n_updates            | 2630       |
|    policy_gradient_loss | -0.0071    |
|    std                  | 0.192      |
|    value_loss           | 0.0457     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 374       |
|    ep_rew_mean     | 365.37582 |
| time/              |           |
|    fps             | 70        |
|    iterations      | 264       |
|    time_elapsed    | 15317     |
|    total_timesteps | 1081344   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 378         |
|    ep_rew_mean          | 369.74078   |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 265         |
|    time_elapsed         | 15360       |
|    total_timesteps      | 1085440     |
| train/                  |             |
|    approx_kl            | 0.025006864 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.06        |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.000955    |
|    n_updates            | 2640        |
|    policy_gradient_loss | -0.00953    |
|    std                  | 0.192       |
|    value_loss           | 0.0382      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 381         |
|    ep_rew_mean          | 371.69138   |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 266         |
|    time_elapsed         | 15402       |
|    total_timesteps      | 1089536     |
| train/                  |             |
|    approx_kl            | 0.027924815 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.05        |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0256      |
|    n_updates            | 2650        |
|    policy_gradient_loss | -0.00612    |
|    std                  | 0.193       |
|    value_loss           | 0.0487      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.21        |
|    cost_of_transport    | 174         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.46        |
|    speed_penalty        | 0.0171      |
| time/                   |             |
|    total timesteps      | 1090000     |
| train/                  |             |
|    approx_kl            | 0.028981403 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.04        |
|    explained_variance   | 0.925       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00845     |
|    n_updates            | 2660        |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.193       |
|    value_loss           | 0.0395      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 377       |
|    ep_rew_mean     | 367.99075 |
| time/              |           |
|    fps             | 70        |
|    iterations      | 267       |
|    time_elapsed    | 15470     |
|    total_timesteps | 1093632   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 378         |
|    ep_rew_mean          | 369.43097   |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 268         |
|    time_elapsed         | 15512       |
|    total_timesteps      | 1097728     |
| train/                  |             |
|    approx_kl            | 0.026562933 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.05        |
|    explained_variance   | 0.929       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0136     |
|    n_updates            | 2670        |
|    policy_gradient_loss | -0.00736    |
|    std                  | 0.192       |
|    value_loss           | 0.0358      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.213       |
|    cost_of_transport    | 172         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.48        |
|    speed_penalty        | 0.0123      |
| time/                   |             |
|    total timesteps      | 1100000     |
| train/                  |             |
|    approx_kl            | 0.022997005 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.06        |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00201     |
|    n_updates            | 2680        |
|    policy_gradient_loss | -0.00797    |
|    std                  | 0.192       |
|    value_loss           | 0.0403      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 376       |
|    ep_rew_mean     | 367.27075 |
| time/              |           |
|    fps             | 70        |
|    iterations      | 269       |
|    time_elapsed    | 15579     |
|    total_timesteps | 1101824   |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 377        |
|    ep_rew_mean          | 368.11664  |
| time/                   |            |
|    fps                  | 70         |
|    iterations           | 270        |
|    time_elapsed         | 15622      |
|    total_timesteps      | 1105920    |
| train/                  |            |
|    approx_kl            | 0.02884632 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.07       |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.00309   |
|    n_updates            | 2690       |
|    policy_gradient_loss | -0.0102    |
|    std                  | 0.192      |
|    value_loss           | 0.0509     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.216       |
|    cost_of_transport    | 173         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.49        |
|    speed_penalty        | 0.0106      |
| time/                   |             |
|    total timesteps      | 1110000     |
| train/                  |             |
|    approx_kl            | 0.028347623 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.07        |
|    explained_variance   | 0.91        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0339      |
|    n_updates            | 2700        |
|    policy_gradient_loss | -0.00718    |
|    std                  | 0.192       |
|    value_loss           | 0.0428      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 375       |
|    ep_rew_mean     | 366.61896 |
| time/              |           |
|    fps             | 70        |
|    iterations      | 271       |
|    time_elapsed    | 15689     |
|    total_timesteps | 1110016   |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 373        |
|    ep_rew_mean          | 364.88382  |
| time/                   |            |
|    fps                  | 70         |
|    iterations           | 272        |
|    time_elapsed         | 15730      |
|    total_timesteps      | 1114112    |
| train/                  |            |
|    approx_kl            | 0.02746278 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.07       |
|    explained_variance   | 0.937      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0466    |
|    n_updates            | 2710       |
|    policy_gradient_loss | -0.00792   |
|    std                  | 0.192      |
|    value_loss           | 0.0298     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 374         |
|    ep_rew_mean          | 364.7725    |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 273         |
|    time_elapsed         | 15772       |
|    total_timesteps      | 1118208     |
| train/                  |             |
|    approx_kl            | 0.023619937 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.08        |
|    explained_variance   | 0.927       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0146      |
|    n_updates            | 2720        |
|    policy_gradient_loss | -0.00741    |
|    std                  | 0.192       |
|    value_loss           | 0.0429      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.213       |
|    cost_of_transport    | 171         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.45        |
|    speed_penalty        | 0.0145      |
| time/                   |             |
|    total timesteps      | 1120000     |
| train/                  |             |
|    approx_kl            | 0.026612652 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.09        |
|    explained_variance   | 0.937       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0126     |
|    n_updates            | 2730        |
|    policy_gradient_loss | -0.00674    |
|    std                  | 0.192       |
|    value_loss           | 0.0309      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 370       |
|    ep_rew_mean     | 360.84238 |
| time/              |           |
|    fps             | 70        |
|    iterations      | 274       |
|    time_elapsed    | 15840     |
|    total_timesteps | 1122304   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 371         |
|    ep_rew_mean          | 361.51605   |
| time/                   |             |
|    fps                  | 70          |
|    iterations           | 275         |
|    time_elapsed         | 15883       |
|    total_timesteps      | 1126400     |
| train/                  |             |
|    approx_kl            | 0.025926787 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.08        |
|    explained_variance   | 0.899       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0366      |
|    n_updates            | 2740        |
|    policy_gradient_loss | -0.00764    |
|    std                  | 0.192       |
|    value_loss           | 0.0539      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.223       |
|    cost_of_transport    | 170         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.45        |
|    speed_penalty        | 0.0141      |
| time/                   |             |
|    total timesteps      | 1130000     |
| train/                  |             |
|    approx_kl            | 0.027341254 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.08        |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00986     |
|    n_updates            | 2750        |
|    policy_gradient_loss | -0.00944    |
|    std                  | 0.192       |
|    value_loss           | 0.0503      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 372       |
|    ep_rew_mean     | 362.14273 |
| time/              |           |
|    fps             | 70        |
|    iterations      | 276       |
|    time_elapsed    | 15950     |
|    total_timesteps | 1130496   |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 372        |
|    ep_rew_mean          | 362.23843  |
| time/                   |            |
|    fps                  | 70         |
|    iterations           | 277        |
|    time_elapsed         | 15992      |
|    total_timesteps      | 1134592    |
| train/                  |            |
|    approx_kl            | 0.02566074 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.08       |
|    explained_variance   | 0.945      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0079     |
|    n_updates            | 2760       |
|    policy_gradient_loss | -0.0099    |
|    std                  | 0.192      |
|    value_loss           | 0.0237     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 373         |
|    ep_rew_mean          | 363.58      |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 278         |
|    time_elapsed         | 16034       |
|    total_timesteps      | 1138688     |
| train/                  |             |
|    approx_kl            | 0.022156944 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.08        |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0573      |
|    n_updates            | 2770        |
|    policy_gradient_loss | -0.00837    |
|    std                  | 0.192       |
|    value_loss           | 0.0499      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.236       |
|    cost_of_transport    | 177         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.44        |
|    speed_penalty        | 0.0138      |
| time/                   |             |
|    total timesteps      | 1140000     |
| train/                  |             |
|    approx_kl            | 0.025753744 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.09        |
|    explained_variance   | 0.892       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0569      |
|    n_updates            | 2780        |
|    policy_gradient_loss | -0.0102     |
|    std                  | 0.192       |
|    value_loss           | 0.0524      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 372      |
|    ep_rew_mean     | 362.5942 |
| time/              |          |
|    fps             | 70       |
|    iterations      | 279      |
|    time_elapsed    | 16101    |
|    total_timesteps | 1142784  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 373         |
|    ep_rew_mean          | 363.65057   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 280         |
|    time_elapsed         | 16145       |
|    total_timesteps      | 1146880     |
| train/                  |             |
|    approx_kl            | 0.026199056 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.09        |
|    explained_variance   | 0.898       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0029      |
|    n_updates            | 2790        |
|    policy_gradient_loss | -0.00556    |
|    std                  | 0.192       |
|    value_loss           | 0.0512      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.241      |
|    cost_of_transport    | 178        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.46       |
|    speed_penalty        | 0.0122     |
| time/                   |            |
|    total timesteps      | 1150000    |
| train/                  |            |
|    approx_kl            | 0.02943957 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.08       |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0142    |
|    n_updates            | 2800       |
|    policy_gradient_loss | -0.00939   |
|    std                  | 0.192      |
|    value_loss           | 0.0468     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 375      |
|    ep_rew_mean     | 364.8454 |
| time/              |          |
|    fps             | 70       |
|    iterations      | 281      |
|    time_elapsed    | 16211    |
|    total_timesteps | 1150976  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 377         |
|    ep_rew_mean          | 367.3234    |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 282         |
|    time_elapsed         | 16254       |
|    total_timesteps      | 1155072     |
| train/                  |             |
|    approx_kl            | 0.020295635 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.08        |
|    explained_variance   | 0.918       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00481    |
|    n_updates            | 2810        |
|    policy_gradient_loss | -0.00269    |
|    std                  | 0.192       |
|    value_loss           | 0.0397      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 379         |
|    ep_rew_mean          | 369.57657   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 283         |
|    time_elapsed         | 16297       |
|    total_timesteps      | 1159168     |
| train/                  |             |
|    approx_kl            | 0.027439762 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.06        |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0117     |
|    n_updates            | 2820        |
|    policy_gradient_loss | -0.00674    |
|    std                  | 0.193       |
|    value_loss           | 0.035       |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.24       |
|    cost_of_transport    | 172        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.48       |
|    speed_penalty        | 0.0122     |
| time/                   |            |
|    total timesteps      | 1160000    |
| train/                  |            |
|    approx_kl            | 0.02565195 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.04       |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0638     |
|    n_updates            | 2830       |
|    policy_gradient_loss | -0.00614   |
|    std                  | 0.193      |
|    value_loss           | 0.0652     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 378      |
|    ep_rew_mean     | 368.763  |
| time/              |          |
|    fps             | 71       |
|    iterations      | 284      |
|    time_elapsed    | 16365    |
|    total_timesteps | 1163264  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 377         |
|    ep_rew_mean          | 367.24625   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 285         |
|    time_elapsed         | 16409       |
|    total_timesteps      | 1167360     |
| train/                  |             |
|    approx_kl            | 0.024360476 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.04        |
|    explained_variance   | 0.913       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0147      |
|    n_updates            | 2840        |
|    policy_gradient_loss | -0.0059     |
|    std                  | 0.193       |
|    value_loss           | 0.0349      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.262      |
|    cost_of_transport    | 178        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.47       |
|    speed_penalty        | 0.0165     |
| time/                   |            |
|    total timesteps      | 1170000    |
| train/                  |            |
|    approx_kl            | 0.03203103 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.05       |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.00313   |
|    n_updates            | 2850       |
|    policy_gradient_loss | -0.0106    |
|    std                  | 0.193      |
|    value_loss           | 0.0438     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 372      |
|    ep_rew_mean     | 362.0848 |
| time/              |          |
|    fps             | 71       |
|    iterations      | 286      |
|    time_elapsed    | 16476    |
|    total_timesteps | 1171456  |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 375       |
|    ep_rew_mean          | 364.87735 |
| time/                   |           |
|    fps                  | 71        |
|    iterations           | 287       |
|    time_elapsed         | 16518     |
|    total_timesteps      | 1175552   |
| train/                  |           |
|    approx_kl            | 0.0267977 |
|    clip_fraction        | 0.305     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.05      |
|    explained_variance   | 0.912     |
|    learning_rate        | 0.0001    |
|    loss                 | 0.0218    |
|    n_updates            | 2860      |
|    policy_gradient_loss | -0.00884  |
|    std                  | 0.193     |
|    value_loss           | 0.0444    |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 375         |
|    ep_rew_mean          | 364.85086   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 288         |
|    time_elapsed         | 16560       |
|    total_timesteps      | 1179648     |
| train/                  |             |
|    approx_kl            | 0.026917353 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.07        |
|    explained_variance   | 0.864       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00214    |
|    n_updates            | 2870        |
|    policy_gradient_loss | -0.00795    |
|    std                  | 0.192       |
|    value_loss           | 0.0587      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.264       |
|    cost_of_transport    | 180         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.4         |
|    speed_penalty        | 0.0283      |
| time/                   |             |
|    total timesteps      | 1180000     |
| train/                  |             |
|    approx_kl            | 0.026515217 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.09        |
|    explained_variance   | 0.906       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0215     |
|    n_updates            | 2880        |
|    policy_gradient_loss | -0.00754    |
|    std                  | 0.192       |
|    value_loss           | 0.0409      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 376      |
|    ep_rew_mean     | 365.5909 |
| time/              |          |
|    fps             | 71       |
|    iterations      | 289      |
|    time_elapsed    | 16627    |
|    total_timesteps | 1183744  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 376         |
|    ep_rew_mean          | 364.91965   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 290         |
|    time_elapsed         | 16669       |
|    total_timesteps      | 1187840     |
| train/                  |             |
|    approx_kl            | 0.030787945 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.1         |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00234    |
|    n_updates            | 2890        |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.192       |
|    value_loss           | 0.0452      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.259       |
|    cost_of_transport    | 175         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.45        |
|    speed_penalty        | 0.0157      |
| time/                   |             |
|    total timesteps      | 1190000     |
| train/                  |             |
|    approx_kl            | 0.028376982 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.12        |
|    explained_variance   | 0.913       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0174      |
|    n_updates            | 2900        |
|    policy_gradient_loss | -0.00696    |
|    std                  | 0.192       |
|    value_loss           | 0.0528      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 374       |
|    ep_rew_mean     | 363.54703 |
| time/              |           |
|    fps             | 71        |
|    iterations      | 291       |
|    time_elapsed    | 16736     |
|    total_timesteps | 1191936   |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 374        |
|    ep_rew_mean          | 363.91055  |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 292        |
|    time_elapsed         | 16779      |
|    total_timesteps      | 1196032    |
| train/                  |            |
|    approx_kl            | 0.02577984 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.11       |
|    explained_variance   | 0.909      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.00215    |
|    n_updates            | 2910       |
|    policy_gradient_loss | -0.00578   |
|    std                  | 0.192      |
|    value_loss           | 0.0417     |
----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.266      |
|    cost_of_transport    | 175        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.44       |
|    speed_penalty        | 0.0192     |
| time/                   |            |
|    total timesteps      | 1200000    |
| train/                  |            |
|    approx_kl            | 0.02843231 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.1        |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.00862   |
|    n_updates            | 2920       |
|    policy_gradient_loss | -0.012     |
|    std                  | 0.192      |
|    value_loss           | 0.0431     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 375       |
|    ep_rew_mean     | 364.72372 |
| time/              |           |
|    fps             | 71        |
|    iterations      | 293       |
|    time_elapsed    | 16845     |
|    total_timesteps | 1200128   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 377         |
|    ep_rew_mean          | 366.41034   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 294         |
|    time_elapsed         | 16888       |
|    total_timesteps      | 1204224     |
| train/                  |             |
|    approx_kl            | 0.028240966 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.1         |
|    explained_variance   | 0.918       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0096     |
|    n_updates            | 2930        |
|    policy_gradient_loss | -0.00773    |
|    std                  | 0.192       |
|    value_loss           | 0.0459      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 382         |
|    ep_rew_mean          | 371.3288    |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 295         |
|    time_elapsed         | 16930       |
|    total_timesteps      | 1208320     |
| train/                  |             |
|    approx_kl            | 0.028698161 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.09        |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.000892    |
|    n_updates            | 2940        |
|    policy_gradient_loss | -0.00966    |
|    std                  | 0.192       |
|    value_loss           | 0.0317      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.259       |
|    cost_of_transport    | 173         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.47        |
|    speed_penalty        | 0.0137      |
| time/                   |             |
|    total timesteps      | 1210000     |
| train/                  |             |
|    approx_kl            | 0.027624141 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.1         |
|    explained_variance   | 0.929       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0144      |
|    n_updates            | 2950        |
|    policy_gradient_loss | -0.0094     |
|    std                  | 0.192       |
|    value_loss           | 0.0427      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 379       |
|    ep_rew_mean     | 368.35703 |
| time/              |           |
|    fps             | 71        |
|    iterations      | 296       |
|    time_elapsed    | 16997     |
|    total_timesteps | 1212416   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 378         |
|    ep_rew_mean          | 367.98172   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 297         |
|    time_elapsed         | 17039       |
|    total_timesteps      | 1216512     |
| train/                  |             |
|    approx_kl            | 0.021971934 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.1         |
|    explained_variance   | 0.923       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0486      |
|    n_updates            | 2960        |
|    policy_gradient_loss | -0.00419    |
|    std                  | 0.192       |
|    value_loss           | 0.0396      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.253       |
|    cost_of_transport    | 180         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.45        |
|    speed_penalty        | 0.0163      |
| time/                   |             |
|    total timesteps      | 1220000     |
| train/                  |             |
|    approx_kl            | 0.027016316 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.1         |
|    explained_variance   | 0.927       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0192      |
|    n_updates            | 2970        |
|    policy_gradient_loss | -0.00819    |
|    std                  | 0.192       |
|    value_loss           | 0.0366      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 381       |
|    ep_rew_mean     | 370.26898 |
| time/              |           |
|    fps             | 71        |
|    iterations      | 298       |
|    time_elapsed    | 17106     |
|    total_timesteps | 1220608   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 383         |
|    ep_rew_mean          | 372.35898   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 299         |
|    time_elapsed         | 17149       |
|    total_timesteps      | 1224704     |
| train/                  |             |
|    approx_kl            | 0.028572347 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.13        |
|    explained_variance   | 0.92        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0145      |
|    n_updates            | 2980        |
|    policy_gradient_loss | -0.00686    |
|    std                  | 0.191       |
|    value_loss           | 0.0455      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 383         |
|    ep_rew_mean          | 373.05417   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 300         |
|    time_elapsed         | 17192       |
|    total_timesteps      | 1228800     |
| train/                  |             |
|    approx_kl            | 0.024743415 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.14        |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0236      |
|    n_updates            | 2990        |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.191       |
|    value_loss           | 0.0434      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.26        |
|    cost_of_transport    | 180         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.43        |
|    speed_penalty        | 0.0202      |
| time/                   |             |
|    total timesteps      | 1230000     |
| train/                  |             |
|    approx_kl            | 0.025601411 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.14        |
|    explained_variance   | 0.933       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0113      |
|    n_updates            | 3000        |
|    policy_gradient_loss | -0.00716    |
|    std                  | 0.191       |
|    value_loss           | 0.0329      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 384      |
|    ep_rew_mean     | 373.7535 |
| time/              |          |
|    fps             | 71       |
|    iterations      | 301      |
|    time_elapsed    | 17259    |
|    total_timesteps | 1232896  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 386         |
|    ep_rew_mean          | 375.74612   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 302         |
|    time_elapsed         | 17300       |
|    total_timesteps      | 1236992     |
| train/                  |             |
|    approx_kl            | 0.027608892 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.14        |
|    explained_variance   | 0.915       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00401    |
|    n_updates            | 3010        |
|    policy_gradient_loss | -0.00676    |
|    std                  | 0.191       |
|    value_loss           | 0.0515      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.275       |
|    cost_of_transport    | 182         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.44        |
|    speed_penalty        | 0.0206      |
| time/                   |             |
|    total timesteps      | 1240000     |
| train/                  |             |
|    approx_kl            | 0.020589352 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.13        |
|    explained_variance   | 0.927       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00962     |
|    n_updates            | 3020        |
|    policy_gradient_loss | -0.00612    |
|    std                  | 0.191       |
|    value_loss           | 0.0345      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 386      |
|    ep_rew_mean     | 376.22   |
| time/              |          |
|    fps             | 71       |
|    iterations      | 303      |
|    time_elapsed    | 17368    |
|    total_timesteps | 1241088  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 386         |
|    ep_rew_mean          | 376.9288    |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 304         |
|    time_elapsed         | 17410       |
|    total_timesteps      | 1245184     |
| train/                  |             |
|    approx_kl            | 0.027020615 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.13        |
|    explained_variance   | 0.916       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00934    |
|    n_updates            | 3030        |
|    policy_gradient_loss | -0.00851    |
|    std                  | 0.191       |
|    value_loss           | 0.0407      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 387         |
|    ep_rew_mean          | 377.77542   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 305         |
|    time_elapsed         | 17452       |
|    total_timesteps      | 1249280     |
| train/                  |             |
|    approx_kl            | 0.025114797 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.13        |
|    explained_variance   | 0.925       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0134      |
|    n_updates            | 3040        |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.191       |
|    value_loss           | 0.044       |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.255      |
|    cost_of_transport    | 178        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.47       |
|    speed_penalty        | 0.0105     |
| time/                   |            |
|    total timesteps      | 1250000    |
| train/                  |            |
|    approx_kl            | 0.02740259 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.13       |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.00429    |
|    n_updates            | 3050       |
|    policy_gradient_loss | -0.00816   |
|    std                  | 0.191      |
|    value_loss           | 0.0419     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 384       |
|    ep_rew_mean     | 375.02667 |
| time/              |           |
|    fps             | 71        |
|    iterations      | 306       |
|    time_elapsed    | 17519     |
|    total_timesteps | 1253376   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 382         |
|    ep_rew_mean          | 373.16513   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 307         |
|    time_elapsed         | 17562       |
|    total_timesteps      | 1257472     |
| train/                  |             |
|    approx_kl            | 0.026249409 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.16        |
|    explained_variance   | 0.874       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00294     |
|    n_updates            | 3060        |
|    policy_gradient_loss | -0.00779    |
|    std                  | 0.19        |
|    value_loss           | 0.0494      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.251       |
|    cost_of_transport    | 182         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.51        |
|    speed_penalty        | 0.00972     |
| time/                   |             |
|    total timesteps      | 1260000     |
| train/                  |             |
|    approx_kl            | 0.025396602 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.15        |
|    explained_variance   | 0.916       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0167      |
|    n_updates            | 3070        |
|    policy_gradient_loss | -0.00785    |
|    std                  | 0.19        |
|    value_loss           | 0.0468      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 379       |
|    ep_rew_mean     | 370.55283 |
| time/              |           |
|    fps             | 71        |
|    iterations      | 308       |
|    time_elapsed    | 17627     |
|    total_timesteps | 1261568   |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 380        |
|    ep_rew_mean          | 371.90216  |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 309        |
|    time_elapsed         | 17670      |
|    total_timesteps      | 1265664    |
| train/                  |            |
|    approx_kl            | 0.02317306 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.16       |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.0001     |
|    loss                 | 0.00334    |
|    n_updates            | 3080       |
|    policy_gradient_loss | -0.00787   |
|    std                  | 0.19       |
|    value_loss           | 0.025      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 379         |
|    ep_rew_mean          | 370.40518   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 310         |
|    time_elapsed         | 17712       |
|    total_timesteps      | 1269760     |
| train/                  |             |
|    approx_kl            | 0.024091763 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.17        |
|    explained_variance   | 0.907       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0113     |
|    n_updates            | 3090        |
|    policy_gradient_loss | -0.00838    |
|    std                  | 0.19        |
|    value_loss           | 0.0467      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.277       |
|    cost_of_transport    | 183         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.46        |
|    speed_penalty        | 0.0127      |
| time/                   |             |
|    total timesteps      | 1270000     |
| train/                  |             |
|    approx_kl            | 0.027164547 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.16        |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0247      |
|    n_updates            | 3100        |
|    policy_gradient_loss | -0.00852    |
|    std                  | 0.191       |
|    value_loss           | 0.043       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 378      |
|    ep_rew_mean     | 369.4884 |
| time/              |          |
|    fps             | 71       |
|    iterations      | 311      |
|    time_elapsed    | 17778    |
|    total_timesteps | 1273856  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 378         |
|    ep_rew_mean          | 369.46732   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 312         |
|    time_elapsed         | 17820       |
|    total_timesteps      | 1277952     |
| train/                  |             |
|    approx_kl            | 0.020219214 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.14        |
|    explained_variance   | 0.912       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0463      |
|    n_updates            | 3110        |
|    policy_gradient_loss | -0.00455    |
|    std                  | 0.191       |
|    value_loss           | 0.042       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.271       |
|    cost_of_transport    | 186         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.45        |
|    speed_penalty        | 0.0153      |
| time/                   |             |
|    total timesteps      | 1280000     |
| train/                  |             |
|    approx_kl            | 0.031464748 |
|    clip_fraction        | 0.325       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.12        |
|    explained_variance   | 0.912       |
|    learning_rate        | 0.0001      |
|    loss                 | -4.41e-05   |
|    n_updates            | 3120        |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.192       |
|    value_loss           | 0.0463      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 378       |
|    ep_rew_mean     | 369.92413 |
| time/              |           |
|    fps             | 71        |
|    iterations      | 313       |
|    time_elapsed    | 17886     |
|    total_timesteps | 1282048   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 379         |
|    ep_rew_mean          | 370.58875   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 314         |
|    time_elapsed         | 17927       |
|    total_timesteps      | 1286144     |
| train/                  |             |
|    approx_kl            | 0.027073491 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.1         |
|    explained_variance   | 0.927       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00937     |
|    n_updates            | 3130        |
|    policy_gradient_loss | -0.00968    |
|    std                  | 0.191       |
|    value_loss           | 0.0383      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.294      |
|    cost_of_transport    | 182        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.48       |
|    speed_penalty        | 0.0108     |
| time/                   |            |
|    total timesteps      | 1290000    |
| train/                  |            |
|    approx_kl            | 0.02364163 |
|    clip_fraction        | 0.283      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.11       |
|    explained_variance   | 0.907      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0519     |
|    n_updates            | 3140       |
|    policy_gradient_loss | -0.00848   |
|    std                  | 0.191      |
|    value_loss           | 0.0463     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 381      |
|    ep_rew_mean     | 372.2514 |
| time/              |          |
|    fps             | 71       |
|    iterations      | 315      |
|    time_elapsed    | 17992    |
|    total_timesteps | 1290240  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 385         |
|    ep_rew_mean          | 375.9489    |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 316         |
|    time_elapsed         | 18034       |
|    total_timesteps      | 1294336     |
| train/                  |             |
|    approx_kl            | 0.024439074 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.13        |
|    explained_variance   | 0.927       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00314     |
|    n_updates            | 3150        |
|    policy_gradient_loss | -0.00962    |
|    std                  | 0.191       |
|    value_loss           | 0.0366      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 388         |
|    ep_rew_mean          | 378.954     |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 317         |
|    time_elapsed         | 18076       |
|    total_timesteps      | 1298432     |
| train/                  |             |
|    approx_kl            | 0.027461085 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.13        |
|    explained_variance   | 0.91        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0267      |
|    n_updates            | 3160        |
|    policy_gradient_loss | -0.00764    |
|    std                  | 0.191       |
|    value_loss           | 0.0448      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.302       |
|    cost_of_transport    | 180         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.48        |
|    speed_penalty        | 0.00977     |
| time/                   |             |
|    total timesteps      | 1300000     |
| train/                  |             |
|    approx_kl            | 0.028474618 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.12        |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0132      |
|    n_updates            | 3170        |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.191       |
|    value_loss           | 0.0472      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 388       |
|    ep_rew_mean     | 378.76343 |
| time/              |           |
|    fps             | 71        |
|    iterations      | 318       |
|    time_elapsed    | 18142     |
|    total_timesteps | 1302528   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 387         |
|    ep_rew_mean          | 378.29227   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 319         |
|    time_elapsed         | 18185       |
|    total_timesteps      | 1306624     |
| train/                  |             |
|    approx_kl            | 0.029703978 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.12        |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0064     |
|    n_updates            | 3180        |
|    policy_gradient_loss | -0.0125     |
|    std                  | 0.192       |
|    value_loss           | 0.0424      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.295       |
|    cost_of_transport    | 180         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.49        |
|    speed_penalty        | 0.00975     |
| time/                   |             |
|    total timesteps      | 1310000     |
| train/                  |             |
|    approx_kl            | 0.025457583 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.11        |
|    explained_variance   | 0.881       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00331     |
|    n_updates            | 3190        |
|    policy_gradient_loss | -0.00814    |
|    std                  | 0.192       |
|    value_loss           | 0.0602      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 386       |
|    ep_rew_mean     | 377.34317 |
| time/              |           |
|    fps             | 71        |
|    iterations      | 320       |
|    time_elapsed    | 18252     |
|    total_timesteps | 1310720   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 384         |
|    ep_rew_mean          | 375.77927   |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 321         |
|    time_elapsed         | 18295       |
|    total_timesteps      | 1314816     |
| train/                  |             |
|    approx_kl            | 0.026334053 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.1         |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0295      |
|    n_updates            | 3200        |
|    policy_gradient_loss | -0.00935    |
|    std                  | 0.192       |
|    value_loss           | 0.0491      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 383         |
|    ep_rew_mean          | 374.862     |
| time/                   |             |
|    fps                  | 71          |
|    iterations           | 322         |
|    time_elapsed         | 18337       |
|    total_timesteps      | 1318912     |
| train/                  |             |
|    approx_kl            | 0.028177988 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.08        |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0156      |
|    n_updates            | 3210        |
|    policy_gradient_loss | -0.00824    |
|    std                  | 0.193       |
|    value_loss           | 0.0456      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.304       |
|    cost_of_transport    | 182         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.5         |
|    speed_penalty        | 0.00677     |
| time/                   |             |
|    total timesteps      | 1320000     |
| train/                  |             |
|    approx_kl            | 0.029429957 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.06        |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0137      |
|    n_updates            | 3220        |
|    policy_gradient_loss | -0.0104     |
|    std                  | 0.193       |
|    value_loss           | 0.0472      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 383      |
|    ep_rew_mean     | 375.2281 |
| time/              |          |
|    fps             | 71       |
|    iterations      | 323      |
|    time_elapsed    | 18403    |
|    total_timesteps | 1323008  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 383        |
|    ep_rew_mean          | 375.28442  |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 324        |
|    time_elapsed         | 18444      |
|    total_timesteps      | 1327104    |
| train/                  |            |
|    approx_kl            | 0.02726398 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.05       |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.000442  |
|    n_updates            | 3230       |
|    policy_gradient_loss | -0.00992   |
|    std                  | 0.193      |
|    value_loss           | 0.0521     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.305       |
|    cost_of_transport    | 177         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.49        |
|    speed_penalty        | 0.00792     |
| time/                   |             |
|    total timesteps      | 1330000     |
| train/                  |             |
|    approx_kl            | 0.024599757 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.06        |
|    explained_variance   | 0.926       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00104     |
|    n_updates            | 3240        |
|    policy_gradient_loss | -0.00789    |
|    std                  | 0.193       |
|    value_loss           | 0.0326      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 385       |
|    ep_rew_mean     | 376.71066 |
| time/              |           |
|    fps             | 71        |
|    iterations      | 325       |
|    time_elapsed    | 18511     |
|    total_timesteps | 1331200   |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 384        |
|    ep_rew_mean          | 376.5705   |
| time/                   |            |
|    fps                  | 71         |
|    iterations           | 326        |
|    time_elapsed         | 18553      |
|    total_timesteps      | 1335296    |
| train/                  |            |
|    approx_kl            | 0.02521579 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.08       |
|    explained_variance   | 0.897      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.00673   |
|    n_updates            | 3250       |
|    policy_gradient_loss | -0.00716   |
|    std                  | 0.192      |
|    value_loss           | 0.0562     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 384        |
|    ep_rew_mean          | 375.88245  |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 327        |
|    time_elapsed         | 18594      |
|    total_timesteps      | 1339392    |
| train/                  |            |
|    approx_kl            | 0.03208084 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.07       |
|    explained_variance   | 0.881      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0053     |
|    n_updates            | 3260       |
|    policy_gradient_loss | -0.00781   |
|    std                  | 0.193      |
|    value_loss           | 0.0536     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.303       |
|    cost_of_transport    | 177         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.47        |
|    speed_penalty        | 0.0126      |
| time/                   |             |
|    total timesteps      | 1340000     |
| train/                  |             |
|    approx_kl            | 0.029613722 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.05        |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.0001      |
|    loss                 | -7.33e-05   |
|    n_updates            | 3270        |
|    policy_gradient_loss | -0.00754    |
|    std                  | 0.193       |
|    value_loss           | 0.0369      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 385      |
|    ep_rew_mean     | 377.6502 |
| time/              |          |
|    fps             | 71       |
|    iterations      | 328      |
|    time_elapsed    | 18661    |
|    total_timesteps | 1343488  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 386         |
|    ep_rew_mean          | 377.72638   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 329         |
|    time_elapsed         | 18703       |
|    total_timesteps      | 1347584     |
| train/                  |             |
|    approx_kl            | 0.025111588 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.03        |
|    explained_variance   | 0.883       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0174     |
|    n_updates            | 3280        |
|    policy_gradient_loss | -0.00721    |
|    std                  | 0.194       |
|    value_loss           | 0.0667      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.291       |
|    cost_of_transport    | 188         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.47        |
|    speed_penalty        | 0.0131      |
| time/                   |             |
|    total timesteps      | 1350000     |
| train/                  |             |
|    approx_kl            | 0.027616303 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.01        |
|    explained_variance   | 0.869       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00181     |
|    n_updates            | 3290        |
|    policy_gradient_loss | -0.00989    |
|    std                  | 0.194       |
|    value_loss           | 0.0583      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 388       |
|    ep_rew_mean     | 379.92047 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 330       |
|    time_elapsed    | 18770     |
|    total_timesteps | 1351680   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 390         |
|    ep_rew_mean          | 381.88208   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 331         |
|    time_elapsed         | 18812       |
|    total_timesteps      | 1355776     |
| train/                  |             |
|    approx_kl            | 0.026338514 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2           |
|    explained_variance   | 0.921       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0304      |
|    n_updates            | 3300        |
|    policy_gradient_loss | -0.00845    |
|    std                  | 0.195       |
|    value_loss           | 0.0347      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 388         |
|    ep_rew_mean          | 380.28305   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 332         |
|    time_elapsed         | 18853       |
|    total_timesteps      | 1359872     |
| train/                  |             |
|    approx_kl            | 0.026047505 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.97        |
|    explained_variance   | 0.898       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0945      |
|    n_updates            | 3310        |
|    policy_gradient_loss | -0.00858    |
|    std                  | 0.195       |
|    value_loss           | 0.055       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.282       |
|    cost_of_transport    | 177         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.5         |
|    speed_penalty        | 0.00964     |
| time/                   |             |
|    total timesteps      | 1360000     |
| train/                  |             |
|    approx_kl            | 0.025566645 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.98        |
|    explained_variance   | 0.892       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0238     |
|    n_updates            | 3320        |
|    policy_gradient_loss | -0.00796    |
|    std                  | 0.195       |
|    value_loss           | 0.0437      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 388       |
|    ep_rew_mean     | 380.38516 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 333       |
|    time_elapsed    | 18919     |
|    total_timesteps | 1363968   |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 388        |
|    ep_rew_mean          | 379.51022  |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 334        |
|    time_elapsed         | 18961      |
|    total_timesteps      | 1368064    |
| train/                  |            |
|    approx_kl            | 0.02715654 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.99       |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.00284    |
|    n_updates            | 3330       |
|    policy_gradient_loss | -0.0091    |
|    std                  | 0.194      |
|    value_loss           | 0.0344     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.274       |
|    cost_of_transport    | 175         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.48        |
|    speed_penalty        | 0.0122      |
| time/                   |             |
|    total timesteps      | 1370000     |
| train/                  |             |
|    approx_kl            | 0.026446283 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.97        |
|    explained_variance   | 0.91        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0137      |
|    n_updates            | 3340        |
|    policy_gradient_loss | -0.00815    |
|    std                  | 0.195       |
|    value_loss           | 0.05        |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 388       |
|    ep_rew_mean     | 379.65286 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 335       |
|    time_elapsed    | 19027     |
|    total_timesteps | 1372160   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 387         |
|    ep_rew_mean          | 378.66907   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 336         |
|    time_elapsed         | 19070       |
|    total_timesteps      | 1376256     |
| train/                  |             |
|    approx_kl            | 0.026352173 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.98        |
|    explained_variance   | 0.918       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0107     |
|    n_updates            | 3350        |
|    policy_gradient_loss | -0.00654    |
|    std                  | 0.194       |
|    value_loss           | 0.0389      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.276       |
|    cost_of_transport    | 182         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.48        |
|    speed_penalty        | 0.0117      |
| time/                   |             |
|    total timesteps      | 1380000     |
| train/                  |             |
|    approx_kl            | 0.026527742 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2           |
|    explained_variance   | 0.928       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0286      |
|    n_updates            | 3360        |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.194       |
|    value_loss           | 0.0345      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 387       |
|    ep_rew_mean     | 378.26477 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 337       |
|    time_elapsed    | 19136     |
|    total_timesteps | 1380352   |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 387        |
|    ep_rew_mean          | 378.0972   |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 338        |
|    time_elapsed         | 19176      |
|    total_timesteps      | 1384448    |
| train/                  |            |
|    approx_kl            | 0.02328606 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2          |
|    explained_variance   | 0.903      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.00122    |
|    n_updates            | 3370       |
|    policy_gradient_loss | -0.00645   |
|    std                  | 0.194      |
|    value_loss           | 0.0579     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 389         |
|    ep_rew_mean          | 380.18524   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 339         |
|    time_elapsed         | 19219       |
|    total_timesteps      | 1388544     |
| train/                  |             |
|    approx_kl            | 0.022776362 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.02        |
|    explained_variance   | 0.93        |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00477    |
|    n_updates            | 3380        |
|    policy_gradient_loss | -0.00864    |
|    std                  | 0.193       |
|    value_loss           | 0.0294      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.324      |
|    cost_of_transport    | 180        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.51       |
|    speed_penalty        | 0.00725    |
| time/                   |            |
|    total timesteps      | 1390000    |
| train/                  |            |
|    approx_kl            | 0.02656327 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.04       |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.00591   |
|    n_updates            | 3390       |
|    policy_gradient_loss | -0.011     |
|    std                  | 0.193      |
|    value_loss           | 0.0403     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 387       |
|    ep_rew_mean     | 378.79913 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 340       |
|    time_elapsed    | 19285     |
|    total_timesteps | 1392640   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 385         |
|    ep_rew_mean          | 377.6839    |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 341         |
|    time_elapsed         | 19326       |
|    total_timesteps      | 1396736     |
| train/                  |             |
|    approx_kl            | 0.023803383 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.05        |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00328     |
|    n_updates            | 3400        |
|    policy_gradient_loss | -0.00673    |
|    std                  | 0.192       |
|    value_loss           | 0.0482      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.31       |
|    cost_of_transport    | 176        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.55       |
|    speed_penalty        | 0.00475    |
| time/                   |            |
|    total timesteps      | 1400000    |
| train/                  |            |
|    approx_kl            | 0.03010201 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.05       |
|    explained_variance   | 0.912      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0641     |
|    n_updates            | 3410       |
|    policy_gradient_loss | -0.0114    |
|    std                  | 0.193      |
|    value_loss           | 0.0396     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 387       |
|    ep_rew_mean     | 379.40234 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 342       |
|    time_elapsed    | 19393     |
|    total_timesteps | 1400832   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 385         |
|    ep_rew_mean          | 377.0671    |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 343         |
|    time_elapsed         | 19435       |
|    total_timesteps      | 1404928     |
| train/                  |             |
|    approx_kl            | 0.022316795 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.05        |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00976    |
|    n_updates            | 3420        |
|    policy_gradient_loss | -0.00824    |
|    std                  | 0.192       |
|    value_loss           | 0.0496      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 383        |
|    ep_rew_mean          | 375.59262  |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 344        |
|    time_elapsed         | 19476      |
|    total_timesteps      | 1409024    |
| train/                  |            |
|    approx_kl            | 0.02744516 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.07       |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.00442   |
|    n_updates            | 3430       |
|    policy_gradient_loss | -0.0117    |
|    std                  | 0.192      |
|    value_loss           | 0.0619     |
----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.346      |
|    cost_of_transport    | 183        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.52       |
|    speed_penalty        | 0.00582    |
| time/                   |            |
|    total timesteps      | 1410000    |
| train/                  |            |
|    approx_kl            | 0.02804596 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.08       |
|    explained_variance   | 0.915      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0378     |
|    n_updates            | 3440       |
|    policy_gradient_loss | -0.00732   |
|    std                  | 0.192      |
|    value_loss           | 0.0438     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 383       |
|    ep_rew_mean     | 376.07483 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 345       |
|    time_elapsed    | 19542     |
|    total_timesteps | 1413120   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 384         |
|    ep_rew_mean          | 377.53027   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 346         |
|    time_elapsed         | 19584       |
|    total_timesteps      | 1417216     |
| train/                  |             |
|    approx_kl            | 0.022369944 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.08        |
|    explained_variance   | 0.901       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0248      |
|    n_updates            | 3450        |
|    policy_gradient_loss | -0.00556    |
|    std                  | 0.191       |
|    value_loss           | 0.0388      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.345       |
|    cost_of_transport    | 180         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.54        |
|    speed_penalty        | 0.00519     |
| time/                   |             |
|    total timesteps      | 1420000     |
| train/                  |             |
|    approx_kl            | 0.026471153 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.08        |
|    explained_variance   | 0.882       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0109      |
|    n_updates            | 3460        |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.192       |
|    value_loss           | 0.0606      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 384       |
|    ep_rew_mean     | 378.16736 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 347       |
|    time_elapsed    | 19650     |
|    total_timesteps | 1421312   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 384         |
|    ep_rew_mean          | 378.31366   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 348         |
|    time_elapsed         | 19693       |
|    total_timesteps      | 1425408     |
| train/                  |             |
|    approx_kl            | 0.026043136 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.06        |
|    explained_variance   | 0.907       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00208     |
|    n_updates            | 3470        |
|    policy_gradient_loss | -0.0104     |
|    std                  | 0.192       |
|    value_loss           | 0.0402      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 380         |
|    ep_rew_mean          | 374.1441    |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 349         |
|    time_elapsed         | 19735       |
|    total_timesteps      | 1429504     |
| train/                  |             |
|    approx_kl            | 0.025739107 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.06        |
|    explained_variance   | 0.908       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0177     |
|    n_updates            | 3480        |
|    policy_gradient_loss | -0.00836    |
|    std                  | 0.192       |
|    value_loss           | 0.0378      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.392       |
|    cost_of_transport    | 185         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.55        |
|    speed_penalty        | 0.00493     |
| time/                   |             |
|    total timesteps      | 1430000     |
| train/                  |             |
|    approx_kl            | 0.031989243 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.05        |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0223      |
|    n_updates            | 3490        |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.192       |
|    value_loss           | 0.0602      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 380       |
|    ep_rew_mean     | 374.16193 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 350       |
|    time_elapsed    | 19800     |
|    total_timesteps | 1433600   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 383         |
|    ep_rew_mean          | 376.67413   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 351         |
|    time_elapsed         | 19842       |
|    total_timesteps      | 1437696     |
| train/                  |             |
|    approx_kl            | 0.022843424 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.05        |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00909     |
|    n_updates            | 3500        |
|    policy_gradient_loss | -0.00686    |
|    std                  | 0.192       |
|    value_loss           | 0.0472      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.395       |
|    cost_of_transport    | 178         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.53        |
|    speed_penalty        | 0.00499     |
| time/                   |             |
|    total timesteps      | 1440000     |
| train/                  |             |
|    approx_kl            | 0.025324177 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.05        |
|    explained_variance   | 0.91        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00541     |
|    n_updates            | 3510        |
|    policy_gradient_loss | -0.00621    |
|    std                  | 0.192       |
|    value_loss           | 0.0433      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 385       |
|    ep_rew_mean     | 378.92706 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 352       |
|    time_elapsed    | 19910     |
|    total_timesteps | 1441792   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 387         |
|    ep_rew_mean          | 380.84482   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 353         |
|    time_elapsed         | 19951       |
|    total_timesteps      | 1445888     |
| train/                  |             |
|    approx_kl            | 0.029990282 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.04        |
|    explained_variance   | 0.883       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0473      |
|    n_updates            | 3520        |
|    policy_gradient_loss | -0.00838    |
|    std                  | 0.193       |
|    value_loss           | 0.0679      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 387         |
|    ep_rew_mean          | 381.24774   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 354         |
|    time_elapsed         | 19993       |
|    total_timesteps      | 1449984     |
| train/                  |             |
|    approx_kl            | 0.027192235 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.02        |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00755     |
|    n_updates            | 3530        |
|    policy_gradient_loss | -0.00772    |
|    std                  | 0.193       |
|    value_loss           | 0.0473      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.383      |
|    cost_of_transport    | 186        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.52       |
|    speed_penalty        | 0.00626    |
| time/                   |            |
|    total timesteps      | 1450000    |
| train/                  |            |
|    approx_kl            | 0.02813975 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.01       |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.0001     |
|    loss                 | -0.00124   |
|    n_updates            | 3540       |
|    policy_gradient_loss | -0.0119    |
|    std                  | 0.193      |
|    value_loss           | 0.0364     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 385       |
|    ep_rew_mean     | 379.31497 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 355       |
|    time_elapsed    | 20059     |
|    total_timesteps | 1454080   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 384         |
|    ep_rew_mean          | 378.02982   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 356         |
|    time_elapsed         | 20100       |
|    total_timesteps      | 1458176     |
| train/                  |             |
|    approx_kl            | 0.028196603 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.02        |
|    explained_variance   | 0.92        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0208      |
|    n_updates            | 3550        |
|    policy_gradient_loss | -0.00887    |
|    std                  | 0.193       |
|    value_loss           | 0.0494      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.404       |
|    cost_of_transport    | 190         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.52        |
|    speed_penalty        | 0.00595     |
| time/                   |             |
|    total timesteps      | 1460000     |
| train/                  |             |
|    approx_kl            | 0.030100659 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.05        |
|    explained_variance   | 0.918       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0761      |
|    n_updates            | 3560        |
|    policy_gradient_loss | -0.0119     |
|    std                  | 0.192       |
|    value_loss           | 0.0399      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 385       |
|    ep_rew_mean     | 379.10284 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 357       |
|    time_elapsed    | 20167     |
|    total_timesteps | 1462272   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 387         |
|    ep_rew_mean          | 381.22504   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 358         |
|    time_elapsed         | 20209       |
|    total_timesteps      | 1466368     |
| train/                  |             |
|    approx_kl            | 0.024814006 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.06        |
|    explained_variance   | 0.908       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0136      |
|    n_updates            | 3570        |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.192       |
|    value_loss           | 0.0381      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.388       |
|    cost_of_transport    | 181         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.52        |
|    speed_penalty        | 0.00513     |
| time/                   |             |
|    total timesteps      | 1470000     |
| train/                  |             |
|    approx_kl            | 0.026205966 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.07        |
|    explained_variance   | 0.899       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0792      |
|    n_updates            | 3580        |
|    policy_gradient_loss | -0.0094     |
|    std                  | 0.192       |
|    value_loss           | 0.0546      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 389       |
|    ep_rew_mean     | 383.24805 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 359       |
|    time_elapsed    | 20276     |
|    total_timesteps | 1470464   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 390         |
|    ep_rew_mean          | 383.9273    |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 360         |
|    time_elapsed         | 20319       |
|    total_timesteps      | 1474560     |
| train/                  |             |
|    approx_kl            | 0.026953075 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.06        |
|    explained_variance   | 0.891       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0347      |
|    n_updates            | 3590        |
|    policy_gradient_loss | -0.00766    |
|    std                  | 0.192       |
|    value_loss           | 0.0567      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 390         |
|    ep_rew_mean          | 384.31604   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 361         |
|    time_elapsed         | 20360       |
|    total_timesteps      | 1478656     |
| train/                  |             |
|    approx_kl            | 0.027761346 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.08        |
|    explained_variance   | 0.924       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00452    |
|    n_updates            | 3600        |
|    policy_gradient_loss | -0.00806    |
|    std                  | 0.191       |
|    value_loss           | 0.0381      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.386       |
|    cost_of_transport    | 175         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.53        |
|    speed_penalty        | 0.00422     |
| time/                   |             |
|    total timesteps      | 1480000     |
| train/                  |             |
|    approx_kl            | 0.027727451 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.1         |
|    explained_variance   | 0.918       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0338      |
|    n_updates            | 3610        |
|    policy_gradient_loss | -0.00686    |
|    std                  | 0.191       |
|    value_loss           | 0.0439      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 389      |
|    ep_rew_mean     | 383.1553 |
| time/              |          |
|    fps             | 72       |
|    iterations      | 362      |
|    time_elapsed    | 20426    |
|    total_timesteps | 1482752  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 388         |
|    ep_rew_mean          | 381.9016    |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 363         |
|    time_elapsed         | 20468       |
|    total_timesteps      | 1486848     |
| train/                  |             |
|    approx_kl            | 0.026314035 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.1         |
|    explained_variance   | 0.933       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00991    |
|    n_updates            | 3620        |
|    policy_gradient_loss | -0.00843    |
|    std                  | 0.191       |
|    value_loss           | 0.0349      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.386       |
|    cost_of_transport    | 182         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.5         |
|    speed_penalty        | 0.00633     |
| time/                   |             |
|    total timesteps      | 1490000     |
| train/                  |             |
|    approx_kl            | 0.030201016 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.09        |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0197      |
|    n_updates            | 3630        |
|    policy_gradient_loss | -0.0069     |
|    std                  | 0.192       |
|    value_loss           | 0.0486      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 390       |
|    ep_rew_mean     | 383.31628 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 364       |
|    time_elapsed    | 20532     |
|    total_timesteps | 1490944   |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 390        |
|    ep_rew_mean          | 383.43774  |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 365        |
|    time_elapsed         | 20574      |
|    total_timesteps      | 1495040    |
| train/                  |            |
|    approx_kl            | 0.02315402 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.07       |
|    explained_variance   | 0.889      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.00619    |
|    n_updates            | 3640       |
|    policy_gradient_loss | -0.00496   |
|    std                  | 0.193      |
|    value_loss           | 0.0534     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 391        |
|    ep_rew_mean          | 384.12183  |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 366        |
|    time_elapsed         | 20615      |
|    total_timesteps      | 1499136    |
| train/                  |            |
|    approx_kl            | 0.02706059 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.05       |
|    explained_variance   | 0.892      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0339     |
|    n_updates            | 3650       |
|    policy_gradient_loss | -0.0118    |
|    std                  | 0.193      |
|    value_loss           | 0.0488     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.396       |
|    cost_of_transport    | 172         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.5         |
|    speed_penalty        | 0.00659     |
| time/                   |             |
|    total timesteps      | 1500000     |
| train/                  |             |
|    approx_kl            | 0.025649967 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.03        |
|    explained_variance   | 0.885       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0208      |
|    n_updates            | 3660        |
|    policy_gradient_loss | -0.00899    |
|    std                  | 0.193       |
|    value_loss           | 0.055       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 391       |
|    ep_rew_mean     | 384.88013 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 367       |
|    time_elapsed    | 20680     |
|    total_timesteps | 1503232   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 391         |
|    ep_rew_mean          | 384.35635   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 368         |
|    time_elapsed         | 20722       |
|    total_timesteps      | 1507328     |
| train/                  |             |
|    approx_kl            | 0.023171794 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.02        |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0209      |
|    n_updates            | 3670        |
|    policy_gradient_loss | -0.00604    |
|    std                  | 0.193       |
|    value_loss           | 0.0444      |
-----------------------------------------
--------------------------------------
| eval/                   |          |
|    action_norm_penalty  | 0.366    |
|    cost_of_transport    | 178      |
|    mean_ep_length       | 400      |
|    mean_reward          | 2.98e+04 |
|    speed                | 1.5      |
|    speed_penalty        | 0.0076   |
| time/                   |          |
|    total timesteps      | 1510000  |
| train/                  |          |
|    approx_kl            | 0.025897 |
|    clip_fraction        | 0.299    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.01     |
|    explained_variance   | 0.897    |
|    learning_rate        | 0.0001   |
|    loss                 | 0.0278   |
|    n_updates            | 3680     |
|    policy_gradient_loss | -0.00993 |
|    std                  | 0.194    |
|    value_loss           | 0.0499   |
--------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 392       |
|    ep_rew_mean     | 385.23593 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 369       |
|    time_elapsed    | 20789     |
|    total_timesteps | 1511424   |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 392       |
|    ep_rew_mean          | 385.22107 |
| time/                   |           |
|    fps                  | 72        |
|    iterations           | 370       |
|    time_elapsed         | 20830     |
|    total_timesteps      | 1515520   |
| train/                  |           |
|    approx_kl            | 0.0296027 |
|    clip_fraction        | 0.316     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2         |
|    explained_variance   | 0.897     |
|    learning_rate        | 0.0001    |
|    loss                 | 0.0635    |
|    n_updates            | 3690      |
|    policy_gradient_loss | -0.00868  |
|    std                  | 0.194     |
|    value_loss           | 0.0536    |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 393         |
|    ep_rew_mean          | 386.09906   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 371         |
|    time_elapsed         | 20873       |
|    total_timesteps      | 1519616     |
| train/                  |             |
|    approx_kl            | 0.030870821 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.01        |
|    explained_variance   | 0.894       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00634    |
|    n_updates            | 3700        |
|    policy_gradient_loss | -0.0101     |
|    std                  | 0.194       |
|    value_loss           | 0.0524      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.357       |
|    cost_of_transport    | 180         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.51        |
|    speed_penalty        | 0.00707     |
| time/                   |             |
|    total timesteps      | 1520000     |
| train/                  |             |
|    approx_kl            | 0.029740995 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2           |
|    explained_variance   | 0.892       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0138      |
|    n_updates            | 3710        |
|    policy_gradient_loss | -0.00876    |
|    std                  | 0.194       |
|    value_loss           | 0.0443      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 393      |
|    ep_rew_mean     | 386.1574 |
| time/              |          |
|    fps             | 72       |
|    iterations      | 372      |
|    time_elapsed    | 20939    |
|    total_timesteps | 1523712  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 393         |
|    ep_rew_mean          | 386.53738   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 373         |
|    time_elapsed         | 20981       |
|    total_timesteps      | 1527808     |
| train/                  |             |
|    approx_kl            | 0.027497226 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.99        |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00724     |
|    n_updates            | 3720        |
|    policy_gradient_loss | -0.0103     |
|    std                  | 0.194       |
|    value_loss           | 0.0463      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.35        |
|    cost_of_transport    | 179         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.5         |
|    speed_penalty        | 0.00577     |
| time/                   |             |
|    total timesteps      | 1530000     |
| train/                  |             |
|    approx_kl            | 0.025802057 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.97        |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0207     |
|    n_updates            | 3730        |
|    policy_gradient_loss | -0.0101     |
|    std                  | 0.195       |
|    value_loss           | 0.0545      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 392       |
|    ep_rew_mean     | 385.51593 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 374       |
|    time_elapsed    | 21046     |
|    total_timesteps | 1531904   |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 393        |
|    ep_rew_mean          | 385.69556  |
| time/                   |            |
|    fps                  | 72         |
|    iterations           | 375        |
|    time_elapsed         | 21088      |
|    total_timesteps      | 1536000    |
| train/                  |            |
|    approx_kl            | 0.02956536 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.95       |
|    explained_variance   | 0.912      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0218     |
|    n_updates            | 3740       |
|    policy_gradient_loss | -0.0108    |
|    std                  | 0.195      |
|    value_loss           | 0.0418     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.355       |
|    cost_of_transport    | 184         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.5         |
|    speed_penalty        | 0.00839     |
| time/                   |             |
|    total timesteps      | 1540000     |
| train/                  |             |
|    approx_kl            | 0.026834674 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.95        |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0249      |
|    n_updates            | 3750        |
|    policy_gradient_loss | -0.00535    |
|    std                  | 0.195       |
|    value_loss           | 0.0542      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 392       |
|    ep_rew_mean     | 384.89343 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 376       |
|    time_elapsed    | 21155     |
|    total_timesteps | 1540096   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 389         |
|    ep_rew_mean          | 382.63626   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 377         |
|    time_elapsed         | 21197       |
|    total_timesteps      | 1544192     |
| train/                  |             |
|    approx_kl            | 0.031218272 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.95        |
|    explained_variance   | 0.893       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0237      |
|    n_updates            | 3760        |
|    policy_gradient_loss | -0.00962    |
|    std                  | 0.195       |
|    value_loss           | 0.0541      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 389         |
|    ep_rew_mean          | 382.12946   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 378         |
|    time_elapsed         | 21240       |
|    total_timesteps      | 1548288     |
| train/                  |             |
|    approx_kl            | 0.030602656 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.93        |
|    explained_variance   | 0.918       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0032      |
|    n_updates            | 3770        |
|    policy_gradient_loss | -0.00857    |
|    std                  | 0.196       |
|    value_loss           | 0.0391      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.384       |
|    cost_of_transport    | 184         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.5         |
|    speed_penalty        | 0.00645     |
| time/                   |             |
|    total timesteps      | 1550000     |
| train/                  |             |
|    approx_kl            | 0.031035569 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.92        |
|    explained_variance   | 0.905       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.05        |
|    n_updates            | 3780        |
|    policy_gradient_loss | -0.0119     |
|    std                  | 0.196       |
|    value_loss           | 0.0517      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 387       |
|    ep_rew_mean     | 380.39832 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 379       |
|    time_elapsed    | 21307     |
|    total_timesteps | 1552384   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 386         |
|    ep_rew_mean          | 379.62933   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 380         |
|    time_elapsed         | 21349       |
|    total_timesteps      | 1556480     |
| train/                  |             |
|    approx_kl            | 0.027865727 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.92        |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0386      |
|    n_updates            | 3790        |
|    policy_gradient_loss | -0.00879    |
|    std                  | 0.196       |
|    value_loss           | 0.0504      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.401       |
|    cost_of_transport    | 185         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.5         |
|    speed_penalty        | 0.00707     |
| time/                   |             |
|    total timesteps      | 1560000     |
| train/                  |             |
|    approx_kl            | 0.023487613 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.91        |
|    explained_variance   | 0.919       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0224      |
|    n_updates            | 3800        |
|    policy_gradient_loss | -0.00735    |
|    std                  | 0.196       |
|    value_loss           | 0.045       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 387       |
|    ep_rew_mean     | 380.37607 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 381       |
|    time_elapsed    | 21416     |
|    total_timesteps | 1560576   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 388         |
|    ep_rew_mean          | 381.28073   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 382         |
|    time_elapsed         | 21458       |
|    total_timesteps      | 1564672     |
| train/                  |             |
|    approx_kl            | 0.025892586 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.91        |
|    explained_variance   | 0.912       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0436      |
|    n_updates            | 3810        |
|    policy_gradient_loss | -0.00727    |
|    std                  | 0.196       |
|    value_loss           | 0.05        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 387         |
|    ep_rew_mean          | 380.6316    |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 383         |
|    time_elapsed         | 21501       |
|    total_timesteps      | 1568768     |
| train/                  |             |
|    approx_kl            | 0.029493464 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.9         |
|    explained_variance   | 0.906       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00356    |
|    n_updates            | 3820        |
|    policy_gradient_loss | -0.00876    |
|    std                  | 0.197       |
|    value_loss           | 0.0458      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.421       |
|    cost_of_transport    | 181         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.5         |
|    speed_penalty        | 0.00725     |
| time/                   |             |
|    total timesteps      | 1570000     |
| train/                  |             |
|    approx_kl            | 0.030788604 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.89        |
|    explained_variance   | 0.929       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.02        |
|    n_updates            | 3830        |
|    policy_gradient_loss | -0.0101     |
|    std                  | 0.196       |
|    value_loss           | 0.0383      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 387       |
|    ep_rew_mean     | 380.26462 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 384       |
|    time_elapsed    | 21569     |
|    total_timesteps | 1572864   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 387         |
|    ep_rew_mean          | 380.82425   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 385         |
|    time_elapsed         | 21611       |
|    total_timesteps      | 1576960     |
| train/                  |             |
|    approx_kl            | 0.027028048 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.9         |
|    explained_variance   | 0.914       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0414      |
|    n_updates            | 3840        |
|    policy_gradient_loss | -0.00605    |
|    std                  | 0.196       |
|    value_loss           | 0.0475      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.452       |
|    cost_of_transport    | 189         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.51        |
|    speed_penalty        | 0.00755     |
| time/                   |             |
|    total timesteps      | 1580000     |
| train/                  |             |
|    approx_kl            | 0.025215589 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.89        |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00798     |
|    n_updates            | 3850        |
|    policy_gradient_loss | -0.006      |
|    std                  | 0.197       |
|    value_loss           | 0.0541      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 387       |
|    ep_rew_mean     | 380.59875 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 386       |
|    time_elapsed    | 21679     |
|    total_timesteps | 1581056   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 388         |
|    ep_rew_mean          | 381.49265   |
| time/                   |             |
|    fps                  | 72          |
|    iterations           | 387         |
|    time_elapsed         | 21722       |
|    total_timesteps      | 1585152     |
| train/                  |             |
|    approx_kl            | 0.029249053 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.89        |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00353    |
|    n_updates            | 3860        |
|    policy_gradient_loss | -0.00986    |
|    std                  | 0.196       |
|    value_loss           | 0.0463      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 388         |
|    ep_rew_mean          | 381.85016   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 388         |
|    time_elapsed         | 21764       |
|    total_timesteps      | 1589248     |
| train/                  |             |
|    approx_kl            | 0.033080615 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.88        |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0274      |
|    n_updates            | 3870        |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.197       |
|    value_loss           | 0.0574      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.443       |
|    cost_of_transport    | 180         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.51        |
|    speed_penalty        | 0.00524     |
| time/                   |             |
|    total timesteps      | 1590000     |
| train/                  |             |
|    approx_kl            | 0.023982283 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.87        |
|    explained_variance   | 0.916       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00559     |
|    n_updates            | 3880        |
|    policy_gradient_loss | -0.00698    |
|    std                  | 0.197       |
|    value_loss           | 0.0395      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 388       |
|    ep_rew_mean     | 381.65985 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 389       |
|    time_elapsed    | 21833     |
|    total_timesteps | 1593344   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 388         |
|    ep_rew_mean          | 382.13452   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 390         |
|    time_elapsed         | 21875       |
|    total_timesteps      | 1597440     |
| train/                  |             |
|    approx_kl            | 0.027894404 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.87        |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0229      |
|    n_updates            | 3890        |
|    policy_gradient_loss | -0.00691    |
|    std                  | 0.197       |
|    value_loss           | 0.0393      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.474       |
|    cost_of_transport    | 180         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.51        |
|    speed_penalty        | 0.00597     |
| time/                   |             |
|    total timesteps      | 1600000     |
| train/                  |             |
|    approx_kl            | 0.022770714 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.86        |
|    explained_variance   | 0.906       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00232     |
|    n_updates            | 3900        |
|    policy_gradient_loss | -0.00474    |
|    std                  | 0.197       |
|    value_loss           | 0.0562      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 386       |
|    ep_rew_mean     | 380.35068 |
| time/              |           |
|    fps             | 72        |
|    iterations      | 391       |
|    time_elapsed    | 21943     |
|    total_timesteps | 1601536   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 387         |
|    ep_rew_mean          | 381.16156   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 392         |
|    time_elapsed         | 21987       |
|    total_timesteps      | 1605632     |
| train/                  |             |
|    approx_kl            | 0.027894821 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.86        |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00307     |
|    n_updates            | 3910        |
|    policy_gradient_loss | -0.00802    |
|    std                  | 0.197       |
|    value_loss           | 0.0488      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 388         |
|    ep_rew_mean          | 382.14423   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 393         |
|    time_elapsed         | 22030       |
|    total_timesteps      | 1609728     |
| train/                  |             |
|    approx_kl            | 0.023907296 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.87        |
|    explained_variance   | 0.919       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00854    |
|    n_updates            | 3920        |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.197       |
|    value_loss           | 0.0336      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.488       |
|    cost_of_transport    | 187         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.51        |
|    speed_penalty        | 0.00563     |
| time/                   |             |
|    total timesteps      | 1610000     |
| train/                  |             |
|    approx_kl            | 0.028078075 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.9         |
|    explained_variance   | 0.879       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0373      |
|    n_updates            | 3930        |
|    policy_gradient_loss | -0.00642    |
|    std                  | 0.196       |
|    value_loss           | 0.0643      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 389       |
|    ep_rew_mean     | 382.85425 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 394       |
|    time_elapsed    | 22097     |
|    total_timesteps | 1613824   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 389         |
|    ep_rew_mean          | 383.8913    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 395         |
|    time_elapsed         | 22140       |
|    total_timesteps      | 1617920     |
| train/                  |             |
|    approx_kl            | 0.023134232 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.9         |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0344      |
|    n_updates            | 3940        |
|    policy_gradient_loss | -0.00606    |
|    std                  | 0.197       |
|    value_loss           | 0.0482      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.483       |
|    cost_of_transport    | 181         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.52        |
|    speed_penalty        | 0.00603     |
| time/                   |             |
|    total timesteps      | 1620000     |
| train/                  |             |
|    approx_kl            | 0.025912998 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.9         |
|    explained_variance   | 0.913       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0305      |
|    n_updates            | 3950        |
|    policy_gradient_loss | -0.0119     |
|    std                  | 0.196       |
|    value_loss           | 0.042       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 392       |
|    ep_rew_mean     | 386.18216 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 396       |
|    time_elapsed    | 22207     |
|    total_timesteps | 1622016   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 389         |
|    ep_rew_mean          | 383.10062   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 397         |
|    time_elapsed         | 22251       |
|    total_timesteps      | 1626112     |
| train/                  |             |
|    approx_kl            | 0.024171442 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.9         |
|    explained_variance   | 0.89        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0448      |
|    n_updates            | 3960        |
|    policy_gradient_loss | -0.00658    |
|    std                  | 0.197       |
|    value_loss           | 0.0578      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.484       |
|    cost_of_transport    | 184         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.51        |
|    speed_penalty        | 0.00636     |
| time/                   |             |
|    total timesteps      | 1630000     |
| train/                  |             |
|    approx_kl            | 0.028926503 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.89        |
|    explained_variance   | 0.876       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0124      |
|    n_updates            | 3970        |
|    policy_gradient_loss | -0.00771    |
|    std                  | 0.197       |
|    value_loss           | 0.0491      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 390       |
|    ep_rew_mean     | 384.21176 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 398       |
|    time_elapsed    | 22319     |
|    total_timesteps | 1630208   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 390         |
|    ep_rew_mean          | 384.40152   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 399         |
|    time_elapsed         | 22361       |
|    total_timesteps      | 1634304     |
| train/                  |             |
|    approx_kl            | 0.035224903 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.87        |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0624      |
|    n_updates            | 3980        |
|    policy_gradient_loss | -0.00723    |
|    std                  | 0.197       |
|    value_loss           | 0.0488      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 390         |
|    ep_rew_mean          | 384.2956    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 400         |
|    time_elapsed         | 22402       |
|    total_timesteps      | 1638400     |
| train/                  |             |
|    approx_kl            | 0.024459407 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.86        |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0373      |
|    n_updates            | 3990        |
|    policy_gradient_loss | -0.00856    |
|    std                  | 0.197       |
|    value_loss           | 0.0518      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.496       |
|    cost_of_transport    | 184         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.54        |
|    speed_penalty        | 0.00612     |
| time/                   |             |
|    total timesteps      | 1640000     |
| train/                  |             |
|    approx_kl            | 0.023495182 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.86        |
|    explained_variance   | 0.904       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00933    |
|    n_updates            | 4000        |
|    policy_gradient_loss | -0.00718    |
|    std                  | 0.197       |
|    value_loss           | 0.0475      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 390       |
|    ep_rew_mean     | 384.40726 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 401       |
|    time_elapsed    | 22470     |
|    total_timesteps | 1642496   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 388         |
|    ep_rew_mean          | 382.42358   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 402         |
|    time_elapsed         | 22513       |
|    total_timesteps      | 1646592     |
| train/                  |             |
|    approx_kl            | 0.028389592 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.86        |
|    explained_variance   | 0.924       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00467    |
|    n_updates            | 4010        |
|    policy_gradient_loss | -0.00888    |
|    std                  | 0.197       |
|    value_loss           | 0.0357      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.519       |
|    cost_of_transport    | 189         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.5         |
|    speed_penalty        | 0.00665     |
| time/                   |             |
|    total timesteps      | 1650000     |
| train/                  |             |
|    approx_kl            | 0.023424251 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.87        |
|    explained_variance   | 0.898       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0362      |
|    n_updates            | 4020        |
|    policy_gradient_loss | -0.00894    |
|    std                  | 0.197       |
|    value_loss           | 0.0603      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 387       |
|    ep_rew_mean     | 381.84784 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 403       |
|    time_elapsed    | 22579     |
|    total_timesteps | 1650688   |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 386        |
|    ep_rew_mean          | 380.65558  |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 404        |
|    time_elapsed         | 22623      |
|    total_timesteps      | 1654784    |
| train/                  |            |
|    approx_kl            | 0.02686107 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.9        |
|    explained_variance   | 0.919      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.00197    |
|    n_updates            | 4030       |
|    policy_gradient_loss | -0.00977   |
|    std                  | 0.196      |
|    value_loss           | 0.034      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 385       |
|    ep_rew_mean          | 380.24014 |
| time/                   |           |
|    fps                  | 73        |
|    iterations           | 405       |
|    time_elapsed         | 22666     |
|    total_timesteps      | 1658880   |
| train/                  |           |
|    approx_kl            | 0.0264859 |
|    clip_fraction        | 0.284     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.91      |
|    explained_variance   | 0.873     |
|    learning_rate        | 0.0001    |
|    loss                 | 0.0197    |
|    n_updates            | 4040      |
|    policy_gradient_loss | -0.00795  |
|    std                  | 0.196     |
|    value_loss           | 0.0612    |
---------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.503       |
|    cost_of_transport    | 195         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.49        |
|    speed_penalty        | 0.00802     |
| time/                   |             |
|    total timesteps      | 1660000     |
| train/                  |             |
|    approx_kl            | 0.029543282 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.9         |
|    explained_variance   | 0.888       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0302      |
|    n_updates            | 4050        |
|    policy_gradient_loss | -0.00636    |
|    std                  | 0.197       |
|    value_loss           | 0.0578      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 385      |
|    ep_rew_mean     | 380.0223 |
| time/              |          |
|    fps             | 73       |
|    iterations      | 406      |
|    time_elapsed    | 22733    |
|    total_timesteps | 1662976  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 389         |
|    ep_rew_mean          | 384.02313   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 407         |
|    time_elapsed         | 22777       |
|    total_timesteps      | 1667072     |
| train/                  |             |
|    approx_kl            | 0.028478649 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.89        |
|    explained_variance   | 0.915       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0259      |
|    n_updates            | 4060        |
|    policy_gradient_loss | -0.00825    |
|    std                  | 0.197       |
|    value_loss           | 0.0361      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.536       |
|    cost_of_transport    | 198         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.49        |
|    speed_penalty        | 0.00685     |
| time/                   |             |
|    total timesteps      | 1670000     |
| train/                  |             |
|    approx_kl            | 0.031713463 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.88        |
|    explained_variance   | 0.891       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0173      |
|    n_updates            | 4070        |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.197       |
|    value_loss           | 0.0559      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 389      |
|    ep_rew_mean     | 383.9523 |
| time/              |          |
|    fps             | 73       |
|    iterations      | 408      |
|    time_elapsed    | 22845    |
|    total_timesteps | 1671168  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 390         |
|    ep_rew_mean          | 384.32043   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 409         |
|    time_elapsed         | 22888       |
|    total_timesteps      | 1675264     |
| train/                  |             |
|    approx_kl            | 0.023121368 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.87        |
|    explained_variance   | 0.889       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00171    |
|    n_updates            | 4080        |
|    policy_gradient_loss | -0.00588    |
|    std                  | 0.198       |
|    value_loss           | 0.0589      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 389         |
|    ep_rew_mean          | 383.293     |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 410         |
|    time_elapsed         | 22931       |
|    total_timesteps      | 1679360     |
| train/                  |             |
|    approx_kl            | 0.025111863 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.84        |
|    explained_variance   | 0.916       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0026      |
|    n_updates            | 4090        |
|    policy_gradient_loss | -0.00714    |
|    std                  | 0.198       |
|    value_loss           | 0.0363      |
-----------------------------------------
---------------------------------------
| eval/                   |           |
|    action_norm_penalty  | 0.551     |
|    cost_of_transport    | 199       |
|    mean_ep_length       | 400       |
|    mean_reward          | 2.98e+04  |
|    speed                | 1.49      |
|    speed_penalty        | 0.00818   |
| time/                   |           |
|    total timesteps      | 1680000   |
| train/                  |           |
|    approx_kl            | 0.0332013 |
|    clip_fraction        | 0.32      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.83      |
|    explained_variance   | 0.914     |
|    learning_rate        | 0.0001    |
|    loss                 | 0.028     |
|    n_updates            | 4100      |
|    policy_gradient_loss | -0.0111   |
|    std                  | 0.198     |
|    value_loss           | 0.046     |
---------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 393       |
|    ep_rew_mean     | 387.19937 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 411       |
|    time_elapsed    | 22998     |
|    total_timesteps | 1683456   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 393         |
|    ep_rew_mean          | 386.6865    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 412         |
|    time_elapsed         | 23041       |
|    total_timesteps      | 1687552     |
| train/                  |             |
|    approx_kl            | 0.026250446 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.82        |
|    explained_variance   | 0.878       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0105      |
|    n_updates            | 4110        |
|    policy_gradient_loss | -0.00731    |
|    std                  | 0.199       |
|    value_loss           | 0.0575      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.581       |
|    cost_of_transport    | 189         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.49        |
|    speed_penalty        | 0.00945     |
| time/                   |             |
|    total timesteps      | 1690000     |
| train/                  |             |
|    approx_kl            | 0.031278223 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.81        |
|    explained_variance   | 0.912       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00495     |
|    n_updates            | 4120        |
|    policy_gradient_loss | -0.00762    |
|    std                  | 0.199       |
|    value_loss           | 0.0337      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 393      |
|    ep_rew_mean     | 386.4467 |
| time/              |          |
|    fps             | 73       |
|    iterations      | 413      |
|    time_elapsed    | 23112    |
|    total_timesteps | 1691648  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 393         |
|    ep_rew_mean          | 386.6816    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 414         |
|    time_elapsed         | 23155       |
|    total_timesteps      | 1695744     |
| train/                  |             |
|    approx_kl            | 0.025960797 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.8         |
|    explained_variance   | 0.879       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0157      |
|    n_updates            | 4130        |
|    policy_gradient_loss | -0.00961    |
|    std                  | 0.2         |
|    value_loss           | 0.0693      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 394        |
|    ep_rew_mean          | 387.2489   |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 415        |
|    time_elapsed         | 23199      |
|    total_timesteps      | 1699840    |
| train/                  |            |
|    approx_kl            | 0.02603892 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.8        |
|    explained_variance   | 0.909      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.00607   |
|    n_updates            | 4140       |
|    policy_gradient_loss | -0.00932   |
|    std                  | 0.199      |
|    value_loss           | 0.0401     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.548       |
|    cost_of_transport    | 197         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.45        |
|    speed_penalty        | 0.0127      |
| time/                   |             |
|    total timesteps      | 1700000     |
| train/                  |             |
|    approx_kl            | 0.026097195 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.81        |
|    explained_variance   | 0.926       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0229     |
|    n_updates            | 4150        |
|    policy_gradient_loss | -0.0125     |
|    std                  | 0.199       |
|    value_loss           | 0.0364      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 393       |
|    ep_rew_mean     | 385.92587 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 416       |
|    time_elapsed    | 23268     |
|    total_timesteps | 1703936   |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 390        |
|    ep_rew_mean          | 383.4243   |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 417        |
|    time_elapsed         | 23311      |
|    total_timesteps      | 1708032    |
| train/                  |            |
|    approx_kl            | 0.02983889 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.81       |
|    explained_variance   | 0.897      |
|    learning_rate        | 0.0001     |
|    loss                 | -3.26e-06  |
|    n_updates            | 4160       |
|    policy_gradient_loss | -0.00858   |
|    std                  | 0.199      |
|    value_loss           | 0.058      |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.536       |
|    cost_of_transport    | 195         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.48        |
|    speed_penalty        | 0.0108      |
| time/                   |             |
|    total timesteps      | 1710000     |
| train/                  |             |
|    approx_kl            | 0.031705733 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.81        |
|    explained_variance   | 0.921       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0141      |
|    n_updates            | 4170        |
|    policy_gradient_loss | -0.0119     |
|    std                  | 0.199       |
|    value_loss           | 0.0343      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 390      |
|    ep_rew_mean     | 383.1239 |
| time/              |          |
|    fps             | 73       |
|    iterations      | 418      |
|    time_elapsed    | 23380    |
|    total_timesteps | 1712128  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 390         |
|    ep_rew_mean          | 382.83093   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 419         |
|    time_elapsed         | 23424       |
|    total_timesteps      | 1716224     |
| train/                  |             |
|    approx_kl            | 0.026965046 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.8         |
|    explained_variance   | 0.893       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0525      |
|    n_updates            | 4180        |
|    policy_gradient_loss | -0.00773    |
|    std                  | 0.199       |
|    value_loss           | 0.0511      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.518      |
|    cost_of_transport    | 194        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.47       |
|    speed_penalty        | 0.0103     |
| time/                   |            |
|    total timesteps      | 1720000    |
| train/                  |            |
|    approx_kl            | 0.02667407 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.79       |
|    explained_variance   | 0.907      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0425     |
|    n_updates            | 4190       |
|    policy_gradient_loss | -0.00935   |
|    std                  | 0.199      |
|    value_loss           | 0.0523     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 388       |
|    ep_rew_mean     | 380.66895 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 420       |
|    time_elapsed    | 23495     |
|    total_timesteps | 1720320   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 387         |
|    ep_rew_mean          | 379.20505   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 421         |
|    time_elapsed         | 23538       |
|    total_timesteps      | 1724416     |
| train/                  |             |
|    approx_kl            | 0.026252061 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.79        |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0298      |
|    n_updates            | 4200        |
|    policy_gradient_loss | -0.00866    |
|    std                  | 0.199       |
|    value_loss           | 0.0427      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 386        |
|    ep_rew_mean          | 377.75714  |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 422        |
|    time_elapsed         | 23581      |
|    total_timesteps      | 1728512    |
| train/                  |            |
|    approx_kl            | 0.03215235 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.8        |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.000524  |
|    n_updates            | 4210       |
|    policy_gradient_loss | -0.0111    |
|    std                  | 0.199      |
|    value_loss           | 0.0558     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.519       |
|    cost_of_transport    | 192         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.46        |
|    speed_penalty        | 0.0117      |
| time/                   |             |
|    total timesteps      | 1730000     |
| train/                  |             |
|    approx_kl            | 0.027301252 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.8         |
|    explained_variance   | 0.913       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0266      |
|    n_updates            | 4220        |
|    policy_gradient_loss | -0.00822    |
|    std                  | 0.199       |
|    value_loss           | 0.0406      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 387       |
|    ep_rew_mean     | 379.19562 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 423       |
|    time_elapsed    | 23652     |
|    total_timesteps | 1732608   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 385         |
|    ep_rew_mean          | 376.67395   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 424         |
|    time_elapsed         | 23697       |
|    total_timesteps      | 1736704     |
| train/                  |             |
|    approx_kl            | 0.028027585 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.8         |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0202      |
|    n_updates            | 4230        |
|    policy_gradient_loss | -0.01       |
|    std                  | 0.199       |
|    value_loss           | 0.0479      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.535      |
|    cost_of_transport    | 196        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.44       |
|    speed_penalty        | 0.011      |
| time/                   |            |
|    total timesteps      | 1740000    |
| train/                  |            |
|    approx_kl            | 0.02790155 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.82       |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.00675   |
|    n_updates            | 4240       |
|    policy_gradient_loss | -0.00682   |
|    std                  | 0.198      |
|    value_loss           | 0.043      |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 384       |
|    ep_rew_mean     | 375.99255 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 425       |
|    time_elapsed    | 23768     |
|    total_timesteps | 1740800   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 384         |
|    ep_rew_mean          | 375.27698   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 426         |
|    time_elapsed         | 23812       |
|    total_timesteps      | 1744896     |
| train/                  |             |
|    approx_kl            | 0.027028255 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.86        |
|    explained_variance   | 0.919       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.000355    |
|    n_updates            | 4250        |
|    policy_gradient_loss | -0.0101     |
|    std                  | 0.198       |
|    value_loss           | 0.0452      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 383         |
|    ep_rew_mean          | 375.3864    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 427         |
|    time_elapsed         | 23857       |
|    total_timesteps      | 1748992     |
| train/                  |             |
|    approx_kl            | 0.024003474 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.88        |
|    explained_variance   | 0.916       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00981    |
|    n_updates            | 4260        |
|    policy_gradient_loss | -0.00658    |
|    std                  | 0.197       |
|    value_loss           | 0.0393      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.487       |
|    cost_of_transport    | 189         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.47        |
|    speed_penalty        | 0.00929     |
| time/                   |             |
|    total timesteps      | 1750000     |
| train/                  |             |
|    approx_kl            | 0.025488399 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.88        |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0653      |
|    n_updates            | 4270        |
|    policy_gradient_loss | -0.00686    |
|    std                  | 0.198       |
|    value_loss           | 0.0396      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 382       |
|    ep_rew_mean     | 374.29614 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 428       |
|    time_elapsed    | 23928     |
|    total_timesteps | 1753088   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 384         |
|    ep_rew_mean          | 376.20914   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 429         |
|    time_elapsed         | 23971       |
|    total_timesteps      | 1757184     |
| train/                  |             |
|    approx_kl            | 0.025406502 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.85        |
|    explained_variance   | 0.932       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0331      |
|    n_updates            | 4280        |
|    policy_gradient_loss | -0.00922    |
|    std                  | 0.198       |
|    value_loss           | 0.0466      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.498       |
|    cost_of_transport    | 187         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.47        |
|    speed_penalty        | 0.0112      |
| time/                   |             |
|    total timesteps      | 1760000     |
| train/                  |             |
|    approx_kl            | 0.022542603 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.84        |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00113     |
|    n_updates            | 4290        |
|    policy_gradient_loss | -0.00993    |
|    std                  | 0.198       |
|    value_loss           | 0.0455      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 381      |
|    ep_rew_mean     | 374.007  |
| time/              |          |
|    fps             | 73       |
|    iterations      | 430      |
|    time_elapsed    | 24044    |
|    total_timesteps | 1761280  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 382         |
|    ep_rew_mean          | 375.01154   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 431         |
|    time_elapsed         | 24088       |
|    total_timesteps      | 1765376     |
| train/                  |             |
|    approx_kl            | 0.032213297 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.84        |
|    explained_variance   | 0.877       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00361    |
|    n_updates            | 4300        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 0.198       |
|    value_loss           | 0.0464      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 382        |
|    ep_rew_mean          | 374.9741   |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 432        |
|    time_elapsed         | 24131      |
|    total_timesteps      | 1769472    |
| train/                  |            |
|    approx_kl            | 0.02486416 |
|    clip_fraction        | 0.287      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.84       |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0628     |
|    n_updates            | 4310       |
|    policy_gradient_loss | -0.00959   |
|    std                  | 0.199      |
|    value_loss           | 0.0492     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.533       |
|    cost_of_transport    | 197         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.44        |
|    speed_penalty        | 0.0138      |
| time/                   |             |
|    total timesteps      | 1770000     |
| train/                  |             |
|    approx_kl            | 0.025247797 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.84        |
|    explained_variance   | 0.905       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0414      |
|    n_updates            | 4320        |
|    policy_gradient_loss | -0.0072     |
|    std                  | 0.199       |
|    value_loss           | 0.0413      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 382       |
|    ep_rew_mean     | 375.21835 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 433       |
|    time_elapsed    | 24204     |
|    total_timesteps | 1773568   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 380         |
|    ep_rew_mean          | 372.83807   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 434         |
|    time_elapsed         | 24248       |
|    total_timesteps      | 1777664     |
| train/                  |             |
|    approx_kl            | 0.026033692 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.84        |
|    explained_variance   | 0.942       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0121     |
|    n_updates            | 4330        |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.198       |
|    value_loss           | 0.0265      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.531      |
|    cost_of_transport    | 193        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.42       |
|    speed_penalty        | 0.0147     |
| time/                   |            |
|    total timesteps      | 1780000    |
| train/                  |            |
|    approx_kl            | 0.02780571 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.85       |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0379     |
|    n_updates            | 4340       |
|    policy_gradient_loss | -0.0096    |
|    std                  | 0.198      |
|    value_loss           | 0.0428     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 379       |
|    ep_rew_mean     | 371.43127 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 435       |
|    time_elapsed    | 24320     |
|    total_timesteps | 1781760   |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 380        |
|    ep_rew_mean          | 372.36368  |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 436        |
|    time_elapsed         | 24366      |
|    total_timesteps      | 1785856    |
| train/                  |            |
|    approx_kl            | 0.02803657 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.84       |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0103    |
|    n_updates            | 4350       |
|    policy_gradient_loss | -0.00693   |
|    std                  | 0.198      |
|    value_loss           | 0.0432     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 379         |
|    ep_rew_mean          | 371.75128   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 437         |
|    time_elapsed         | 24410       |
|    total_timesteps      | 1789952     |
| train/                  |             |
|    approx_kl            | 0.029441988 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.82        |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0352      |
|    n_updates            | 4360        |
|    policy_gradient_loss | -0.00653    |
|    std                  | 0.199       |
|    value_loss           | 0.0502      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.477       |
|    cost_of_transport    | 185         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.48        |
|    speed_penalty        | 0.00938     |
| time/                   |             |
|    total timesteps      | 1790000     |
| train/                  |             |
|    approx_kl            | 0.024363158 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.81        |
|    explained_variance   | 0.883       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00392    |
|    n_updates            | 4370        |
|    policy_gradient_loss | -0.00509    |
|    std                  | 0.199       |
|    value_loss           | 0.063       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 380       |
|    ep_rew_mean     | 372.73187 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 438       |
|    time_elapsed    | 24480     |
|    total_timesteps | 1794048   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 383         |
|    ep_rew_mean          | 375.06152   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 439         |
|    time_elapsed         | 24526       |
|    total_timesteps      | 1798144     |
| train/                  |             |
|    approx_kl            | 0.022293273 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.8         |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00537     |
|    n_updates            | 4380        |
|    policy_gradient_loss | -0.00602    |
|    std                  | 0.2         |
|    value_loss           | 0.0373      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.517      |
|    cost_of_transport    | 186        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.46       |
|    speed_penalty        | 0.0123     |
| time/                   |            |
|    total timesteps      | 1800000    |
| train/                  |            |
|    approx_kl            | 0.02963683 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.8        |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.002      |
|    n_updates            | 4390       |
|    policy_gradient_loss | -0.0116    |
|    std                  | 0.199      |
|    value_loss           | 0.0496     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 384       |
|    ep_rew_mean     | 376.21118 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 440       |
|    time_elapsed    | 24596     |
|    total_timesteps | 1802240   |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 381        |
|    ep_rew_mean          | 374.1313   |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 441        |
|    time_elapsed         | 24641      |
|    total_timesteps      | 1806336    |
| train/                  |            |
|    approx_kl            | 0.02626801 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.8        |
|    explained_variance   | 0.903      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0117     |
|    n_updates            | 4400       |
|    policy_gradient_loss | -0.00984   |
|    std                  | 0.199      |
|    value_loss           | 0.0463     |
----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.536      |
|    cost_of_transport    | 188        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.41       |
|    speed_penalty        | 0.0162     |
| time/                   |            |
|    total timesteps      | 1810000    |
| train/                  |            |
|    approx_kl            | 0.02989798 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.82       |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0176    |
|    n_updates            | 4410       |
|    policy_gradient_loss | -0.0103    |
|    std                  | 0.198      |
|    value_loss           | 0.0324     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 383      |
|    ep_rew_mean     | 375.3107 |
| time/              |          |
|    fps             | 73       |
|    iterations      | 442      |
|    time_elapsed    | 24712    |
|    total_timesteps | 1810432  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 386        |
|    ep_rew_mean          | 378.1657   |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 443        |
|    time_elapsed         | 24756      |
|    total_timesteps      | 1814528    |
| train/                  |            |
|    approx_kl            | 0.02913713 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.85       |
|    explained_variance   | 0.893      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0286     |
|    n_updates            | 4420       |
|    policy_gradient_loss | -0.00901   |
|    std                  | 0.198      |
|    value_loss           | 0.059      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 388        |
|    ep_rew_mean          | 379.83945  |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 444        |
|    time_elapsed         | 24801      |
|    total_timesteps      | 1818624    |
| train/                  |            |
|    approx_kl            | 0.02391572 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.84       |
|    explained_variance   | 0.897      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.00508   |
|    n_updates            | 4430       |
|    policy_gradient_loss | -0.00731   |
|    std                  | 0.199      |
|    value_loss           | 0.0478     |
----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.483      |
|    cost_of_transport    | 185        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.46       |
|    speed_penalty        | 0.0105     |
| time/                   |            |
|    total timesteps      | 1820000    |
| train/                  |            |
|    approx_kl            | 0.03010161 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.82       |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0568     |
|    n_updates            | 4440       |
|    policy_gradient_loss | -0.0117    |
|    std                  | 0.199      |
|    value_loss           | 0.0457     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 389       |
|    ep_rew_mean     | 381.26257 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 445       |
|    time_elapsed    | 24872     |
|    total_timesteps | 1822720   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 392         |
|    ep_rew_mean          | 384.92383   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 446         |
|    time_elapsed         | 24917       |
|    total_timesteps      | 1826816     |
| train/                  |             |
|    approx_kl            | 0.023536198 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.83        |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00887     |
|    n_updates            | 4450        |
|    policy_gradient_loss | -0.00731    |
|    std                  | 0.198       |
|    value_loss           | 0.0501      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.466       |
|    cost_of_transport    | 183         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.46        |
|    speed_penalty        | 0.00911     |
| time/                   |             |
|    total timesteps      | 1830000     |
| train/                  |             |
|    approx_kl            | 0.028808706 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.83        |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0249      |
|    n_updates            | 4460        |
|    policy_gradient_loss | -0.00808    |
|    std                  | 0.199       |
|    value_loss           | 0.0492      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 393      |
|    ep_rew_mean     | 385.4574 |
| time/              |          |
|    fps             | 73       |
|    iterations      | 447      |
|    time_elapsed    | 24990    |
|    total_timesteps | 1830912  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 391         |
|    ep_rew_mean          | 382.9475    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 448         |
|    time_elapsed         | 25036       |
|    total_timesteps      | 1835008     |
| train/                  |             |
|    approx_kl            | 0.025564056 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.83        |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0061     |
|    n_updates            | 4470        |
|    policy_gradient_loss | -0.00907    |
|    std                  | 0.199       |
|    value_loss           | 0.0513      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 390         |
|    ep_rew_mean          | 382.08667   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 449         |
|    time_elapsed         | 25081       |
|    total_timesteps      | 1839104     |
| train/                  |             |
|    approx_kl            | 0.023576207 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.83        |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00893     |
|    n_updates            | 4480        |
|    policy_gradient_loss | -0.00737    |
|    std                  | 0.198       |
|    value_loss           | 0.049       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.49        |
|    cost_of_transport    | 181         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.45        |
|    speed_penalty        | 0.0125      |
| time/                   |             |
|    total timesteps      | 1840000     |
| train/                  |             |
|    approx_kl            | 0.025043365 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.83        |
|    explained_variance   | 0.898       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0308      |
|    n_updates            | 4490        |
|    policy_gradient_loss | -0.00743    |
|    std                  | 0.199       |
|    value_loss           | 0.0518      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 390       |
|    ep_rew_mean     | 381.84583 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 450       |
|    time_elapsed    | 25153     |
|    total_timesteps | 1843200   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 392         |
|    ep_rew_mean          | 383.58807   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 451         |
|    time_elapsed         | 25198       |
|    total_timesteps      | 1847296     |
| train/                  |             |
|    approx_kl            | 0.025099453 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.82        |
|    explained_variance   | 0.912       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00948    |
|    n_updates            | 4500        |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.199       |
|    value_loss           | 0.0427      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.49        |
|    cost_of_transport    | 184         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.45        |
|    speed_penalty        | 0.00995     |
| time/                   |             |
|    total timesteps      | 1850000     |
| train/                  |             |
|    approx_kl            | 0.030559063 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.82        |
|    explained_variance   | 0.914       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0258     |
|    n_updates            | 4510        |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.199       |
|    value_loss           | 0.045       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 390       |
|    ep_rew_mean     | 382.50052 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 452       |
|    time_elapsed    | 25270     |
|    total_timesteps | 1851392   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 387         |
|    ep_rew_mean          | 378.9414    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 453         |
|    time_elapsed         | 25315       |
|    total_timesteps      | 1855488     |
| train/                  |             |
|    approx_kl            | 0.029729595 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.83        |
|    explained_variance   | 0.914       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0575      |
|    n_updates            | 4520        |
|    policy_gradient_loss | -0.00904    |
|    std                  | 0.198       |
|    value_loss           | 0.0477      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 387         |
|    ep_rew_mean          | 378.4761    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 454         |
|    time_elapsed         | 25358       |
|    total_timesteps      | 1859584     |
| train/                  |             |
|    approx_kl            | 0.028439008 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.83        |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00667    |
|    n_updates            | 4530        |
|    policy_gradient_loss | -0.0133     |
|    std                  | 0.199       |
|    value_loss           | 0.0561      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.462       |
|    cost_of_transport    | 182         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.46        |
|    speed_penalty        | 0.0135      |
| time/                   |             |
|    total timesteps      | 1860000     |
| train/                  |             |
|    approx_kl            | 0.024501797 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.83        |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00166     |
|    n_updates            | 4540        |
|    policy_gradient_loss | -0.00881    |
|    std                  | 0.199       |
|    value_loss           | 0.0455      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 387       |
|    ep_rew_mean     | 378.14493 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 455       |
|    time_elapsed    | 25431     |
|    total_timesteps | 1863680   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 384         |
|    ep_rew_mean          | 375.35114   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 456         |
|    time_elapsed         | 25475       |
|    total_timesteps      | 1867776     |
| train/                  |             |
|    approx_kl            | 0.027595371 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.84        |
|    explained_variance   | 0.929       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00361     |
|    n_updates            | 4550        |
|    policy_gradient_loss | -0.00868    |
|    std                  | 0.198       |
|    value_loss           | 0.0365      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.502       |
|    cost_of_transport    | 186         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.47        |
|    speed_penalty        | 0.0105      |
| time/                   |             |
|    total timesteps      | 1870000     |
| train/                  |             |
|    approx_kl            | 0.032786056 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.84        |
|    explained_variance   | 0.883       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0211      |
|    n_updates            | 4560        |
|    policy_gradient_loss | -0.00704    |
|    std                  | 0.199       |
|    value_loss           | 0.0648      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 385      |
|    ep_rew_mean     | 376.9557 |
| time/              |          |
|    fps             | 73       |
|    iterations      | 457      |
|    time_elapsed    | 25546    |
|    total_timesteps | 1871872  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 387        |
|    ep_rew_mean          | 378.10895  |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 458        |
|    time_elapsed         | 25592      |
|    total_timesteps      | 1875968    |
| train/                  |            |
|    approx_kl            | 0.02658579 |
|    clip_fraction        | 0.282      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.85       |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.0001     |
|    loss                 | 7.01e-05   |
|    n_updates            | 4570       |
|    policy_gradient_loss | -0.00854   |
|    std                  | 0.198      |
|    value_loss           | 0.0338     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.523       |
|    cost_of_transport    | 182         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.47        |
|    speed_penalty        | 0.0104      |
| time/                   |             |
|    total timesteps      | 1880000     |
| train/                  |             |
|    approx_kl            | 0.025335036 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.85        |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00729     |
|    n_updates            | 4580        |
|    policy_gradient_loss | -0.00796    |
|    std                  | 0.198       |
|    value_loss           | 0.0531      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 386      |
|    ep_rew_mean     | 377.1457 |
| time/              |          |
|    fps             | 73       |
|    iterations      | 459      |
|    time_elapsed    | 25665    |
|    total_timesteps | 1880064  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 384         |
|    ep_rew_mean          | 375.6741    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 460         |
|    time_elapsed         | 25710       |
|    total_timesteps      | 1884160     |
| train/                  |             |
|    approx_kl            | 0.028050005 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.82        |
|    explained_variance   | 0.889       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0264      |
|    n_updates            | 4590        |
|    policy_gradient_loss | -0.00923    |
|    std                  | 0.199       |
|    value_loss           | 0.0608      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 383         |
|    ep_rew_mean          | 374.66013   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 461         |
|    time_elapsed         | 25755       |
|    total_timesteps      | 1888256     |
| train/                  |             |
|    approx_kl            | 0.027155526 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.79        |
|    explained_variance   | 0.925       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0106     |
|    n_updates            | 4600        |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.2         |
|    value_loss           | 0.0342      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.544      |
|    cost_of_transport    | 186        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.47       |
|    speed_penalty        | 0.0075     |
| time/                   |            |
|    total timesteps      | 1890000    |
| train/                  |            |
|    approx_kl            | 0.02995304 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.81       |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0124     |
|    n_updates            | 4610       |
|    policy_gradient_loss | -0.0131    |
|    std                  | 0.199      |
|    value_loss           | 0.0389     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 384       |
|    ep_rew_mean     | 376.33954 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 462       |
|    time_elapsed    | 25828     |
|    total_timesteps | 1892352   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 383         |
|    ep_rew_mean          | 375.631     |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 463         |
|    time_elapsed         | 25873       |
|    total_timesteps      | 1896448     |
| train/                  |             |
|    approx_kl            | 0.028537665 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.84        |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0197      |
|    n_updates            | 4620        |
|    policy_gradient_loss | -0.00929    |
|    std                  | 0.198       |
|    value_loss           | 0.0524      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.543      |
|    cost_of_transport    | 184        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.46       |
|    speed_penalty        | 0.0118     |
| time/                   |            |
|    total timesteps      | 1900000    |
| train/                  |            |
|    approx_kl            | 0.02469819 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.86       |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0234     |
|    n_updates            | 4630       |
|    policy_gradient_loss | -0.0103    |
|    std                  | 0.197      |
|    value_loss           | 0.0408     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 382      |
|    ep_rew_mean     | 374.8857 |
| time/              |          |
|    fps             | 73       |
|    iterations      | 464      |
|    time_elapsed    | 25947    |
|    total_timesteps | 1900544  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 378         |
|    ep_rew_mean          | 371.38977   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 465         |
|    time_elapsed         | 25993       |
|    total_timesteps      | 1904640     |
| train/                  |             |
|    approx_kl            | 0.032634348 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.88        |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.016       |
|    n_updates            | 4640        |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.197       |
|    value_loss           | 0.0463      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 380        |
|    ep_rew_mean          | 373.62775  |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 466        |
|    time_elapsed         | 26038      |
|    total_timesteps      | 1908736    |
| train/                  |            |
|    approx_kl            | 0.03122995 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.88       |
|    explained_variance   | 0.906      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0341     |
|    n_updates            | 4650       |
|    policy_gradient_loss | -0.00793   |
|    std                  | 0.197      |
|    value_loss           | 0.0474     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.542       |
|    cost_of_transport    | 181         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.47        |
|    speed_penalty        | 0.0136      |
| time/                   |             |
|    total timesteps      | 1910000     |
| train/                  |             |
|    approx_kl            | 0.029764166 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.91        |
|    explained_variance   | 0.893       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0467      |
|    n_updates            | 4660        |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.196       |
|    value_loss           | 0.0585      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 377      |
|    ep_rew_mean     | 370.5342 |
| time/              |          |
|    fps             | 73       |
|    iterations      | 467      |
|    time_elapsed    | 26110    |
|    total_timesteps | 1912832  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 377         |
|    ep_rew_mean          | 370.8276    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 468         |
|    time_elapsed         | 26155       |
|    total_timesteps      | 1916928     |
| train/                  |             |
|    approx_kl            | 0.028043427 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.92        |
|    explained_variance   | 0.899       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0118     |
|    n_updates            | 4670        |
|    policy_gradient_loss | -0.00998    |
|    std                  | 0.196       |
|    value_loss           | 0.0477      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.537       |
|    cost_of_transport    | 177         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.46        |
|    speed_penalty        | 0.00962     |
| time/                   |             |
|    total timesteps      | 1920000     |
| train/                  |             |
|    approx_kl            | 0.025484197 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.92        |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00407    |
|    n_updates            | 4680        |
|    policy_gradient_loss | -0.00892    |
|    std                  | 0.196       |
|    value_loss           | 0.0338      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 374       |
|    ep_rew_mean     | 368.07336 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 469       |
|    time_elapsed    | 26229     |
|    total_timesteps | 1921024   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 375         |
|    ep_rew_mean          | 369.12683   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 470         |
|    time_elapsed         | 26274       |
|    total_timesteps      | 1925120     |
| train/                  |             |
|    approx_kl            | 0.029139407 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.91        |
|    explained_variance   | 0.881       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0428      |
|    n_updates            | 4690        |
|    policy_gradient_loss | -0.00875    |
|    std                  | 0.196       |
|    value_loss           | 0.0613      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 376         |
|    ep_rew_mean          | 369.90903   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 471         |
|    time_elapsed         | 26319       |
|    total_timesteps      | 1929216     |
| train/                  |             |
|    approx_kl            | 0.023814905 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.92        |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00171    |
|    n_updates            | 4700        |
|    policy_gradient_loss | -0.00793    |
|    std                  | 0.196       |
|    value_loss           | 0.0406      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.556       |
|    cost_of_transport    | 183         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.44        |
|    speed_penalty        | 0.0114      |
| time/                   |             |
|    total timesteps      | 1930000     |
| train/                  |             |
|    approx_kl            | 0.026805492 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.93        |
|    explained_variance   | 0.892       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0345      |
|    n_updates            | 4710        |
|    policy_gradient_loss | -0.00701    |
|    std                  | 0.196       |
|    value_loss           | 0.0569      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 377       |
|    ep_rew_mean     | 370.83496 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 472       |
|    time_elapsed    | 26389     |
|    total_timesteps | 1933312   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 378         |
|    ep_rew_mean          | 372.00897   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 473         |
|    time_elapsed         | 26435       |
|    total_timesteps      | 1937408     |
| train/                  |             |
|    approx_kl            | 0.023172524 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.93        |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0124      |
|    n_updates            | 4720        |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.196       |
|    value_loss           | 0.0441      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.539       |
|    cost_of_transport    | 178         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.48        |
|    speed_penalty        | 0.00811     |
| time/                   |             |
|    total timesteps      | 1940000     |
| train/                  |             |
|    approx_kl            | 0.030454258 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.95        |
|    explained_variance   | 0.873       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0796      |
|    n_updates            | 4730        |
|    policy_gradient_loss | -0.00833    |
|    std                  | 0.195       |
|    value_loss           | 0.0595      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 382      |
|    ep_rew_mean     | 376.0887 |
| time/              |          |
|    fps             | 73       |
|    iterations      | 474      |
|    time_elapsed    | 26507    |
|    total_timesteps | 1941504  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 382         |
|    ep_rew_mean          | 375.94055   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 475         |
|    time_elapsed         | 26552       |
|    total_timesteps      | 1945600     |
| train/                  |             |
|    approx_kl            | 0.026324607 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.95        |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0091      |
|    n_updates            | 4740        |
|    policy_gradient_loss | -0.00669    |
|    std                  | 0.195       |
|    value_loss           | 0.037       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 384         |
|    ep_rew_mean          | 377.92172   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 476         |
|    time_elapsed         | 26597       |
|    total_timesteps      | 1949696     |
| train/                  |             |
|    approx_kl            | 0.028538845 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.96        |
|    explained_variance   | 0.905       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00275    |
|    n_updates            | 4750        |
|    policy_gradient_loss | -0.00567    |
|    std                  | 0.195       |
|    value_loss           | 0.0474      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.558       |
|    cost_of_transport    | 177         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.48        |
|    speed_penalty        | 0.00701     |
| time/                   |             |
|    total timesteps      | 1950000     |
| train/                  |             |
|    approx_kl            | 0.024595086 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.96        |
|    explained_variance   | 0.894       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0663      |
|    n_updates            | 4760        |
|    policy_gradient_loss | -0.00811    |
|    std                  | 0.195       |
|    value_loss           | 0.0505      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 385      |
|    ep_rew_mean     | 379.4366 |
| time/              |          |
|    fps             | 73       |
|    iterations      | 477      |
|    time_elapsed    | 26669    |
|    total_timesteps | 1953792  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 386         |
|    ep_rew_mean          | 380.20526   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 478         |
|    time_elapsed         | 26713       |
|    total_timesteps      | 1957888     |
| train/                  |             |
|    approx_kl            | 0.027428873 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.94        |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00876    |
|    n_updates            | 4770        |
|    policy_gradient_loss | -0.00794    |
|    std                  | 0.196       |
|    value_loss           | 0.0479      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.61       |
|    cost_of_transport    | 180        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.49       |
|    speed_penalty        | 0.00589    |
| time/                   |            |
|    total timesteps      | 1960000    |
| train/                  |            |
|    approx_kl            | 0.02790985 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.93       |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.0001     |
|    loss                 | 0.00766    |
|    n_updates            | 4780       |
|    policy_gradient_loss | -0.00944   |
|    std                  | 0.196      |
|    value_loss           | 0.0368     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 390       |
|    ep_rew_mean     | 384.43195 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 479       |
|    time_elapsed    | 26786     |
|    total_timesteps | 1961984   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 389         |
|    ep_rew_mean          | 383.02176   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 480         |
|    time_elapsed         | 26832       |
|    total_timesteps      | 1966080     |
| train/                  |             |
|    approx_kl            | 0.025951738 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.9         |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0706      |
|    n_updates            | 4790        |
|    policy_gradient_loss | -0.00697    |
|    std                  | 0.197       |
|    value_loss           | 0.05        |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.602       |
|    cost_of_transport    | 176         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.48        |
|    speed_penalty        | 0.00606     |
| time/                   |             |
|    total timesteps      | 1970000     |
| train/                  |             |
|    approx_kl            | 0.032635078 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.88        |
|    explained_variance   | 0.89        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0281      |
|    n_updates            | 4800        |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.197       |
|    value_loss           | 0.0544      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 388      |
|    ep_rew_mean     | 382.6765 |
| time/              |          |
|    fps             | 73       |
|    iterations      | 481      |
|    time_elapsed    | 26905    |
|    total_timesteps | 1970176  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 388         |
|    ep_rew_mean          | 382.25534   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 482         |
|    time_elapsed         | 26951       |
|    total_timesteps      | 1974272     |
| train/                  |             |
|    approx_kl            | 0.028064504 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.89        |
|    explained_variance   | 0.935       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00154     |
|    n_updates            | 4810        |
|    policy_gradient_loss | -0.0079     |
|    std                  | 0.197       |
|    value_loss           | 0.0352      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 389         |
|    ep_rew_mean          | 383.39578   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 483         |
|    time_elapsed         | 26997       |
|    total_timesteps      | 1978368     |
| train/                  |             |
|    approx_kl            | 0.026709612 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.91        |
|    explained_variance   | 0.919       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.01       |
|    n_updates            | 4820        |
|    policy_gradient_loss | -0.00759    |
|    std                  | 0.196       |
|    value_loss           | 0.035       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.629       |
|    cost_of_transport    | 176         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.48        |
|    speed_penalty        | 0.00885     |
| time/                   |             |
|    total timesteps      | 1980000     |
| train/                  |             |
|    approx_kl            | 0.025997518 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.9         |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.0001      |
|    loss                 | 3.22e-05    |
|    n_updates            | 4830        |
|    policy_gradient_loss | -0.00871    |
|    std                  | 0.197       |
|    value_loss           | 0.0586      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 388       |
|    ep_rew_mean     | 382.71857 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 484       |
|    time_elapsed    | 27068     |
|    total_timesteps | 1982464   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 388         |
|    ep_rew_mean          | 382.7766    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 485         |
|    time_elapsed         | 27115       |
|    total_timesteps      | 1986560     |
| train/                  |             |
|    approx_kl            | 0.023022857 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.9         |
|    explained_variance   | 0.93        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0197      |
|    n_updates            | 4840        |
|    policy_gradient_loss | -0.00579    |
|    std                  | 0.196       |
|    value_loss           | 0.0337      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.655      |
|    cost_of_transport    | 179        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.47       |
|    speed_penalty        | 0.0102     |
| time/                   |            |
|    total timesteps      | 1990000    |
| train/                  |            |
|    approx_kl            | 0.03087799 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.9        |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.057      |
|    n_updates            | 4850       |
|    policy_gradient_loss | -0.00972   |
|    std                  | 0.196      |
|    value_loss           | 0.0491     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 391       |
|    ep_rew_mean     | 385.55124 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 486       |
|    time_elapsed    | 27188     |
|    total_timesteps | 1990656   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 391         |
|    ep_rew_mean          | 386.0009    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 487         |
|    time_elapsed         | 27233       |
|    total_timesteps      | 1994752     |
| train/                  |             |
|    approx_kl            | 0.029474597 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.9         |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.0001      |
|    loss                 | 0.024       |
|    n_updates            | 4860        |
|    policy_gradient_loss | -0.00999    |
|    std                  | 0.196       |
|    value_loss           | 0.0594      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 391         |
|    ep_rew_mean          | 385.66113   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 488         |
|    time_elapsed         | 27279       |
|    total_timesteps      | 1998848     |
| train/                  |             |
|    approx_kl            | 0.022008393 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.9         |
|    explained_variance   | 0.927       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0564      |
|    n_updates            | 4870        |
|    policy_gradient_loss | -0.00637    |
|    std                  | 0.197       |
|    value_loss           | 0.0325      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.659      |
|    cost_of_transport    | 174        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.44       |
|    speed_penalty        | 0.00913    |
| time/                   |            |
|    total timesteps      | 2000000    |
| train/                  |            |
|    approx_kl            | 0.02858574 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.88       |
|    explained_variance   | 0.912      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.00459   |
|    n_updates            | 4880       |
|    policy_gradient_loss | -0.0089    |
|    std                  | 0.197      |
|    value_loss           | 0.0462     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 388      |
|    ep_rew_mean     | 383.2206 |
| time/              |          |
|    fps             | 73       |
|    iterations      | 489      |
|    time_elapsed    | 27352    |
|    total_timesteps | 2002944  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 388         |
|    ep_rew_mean          | 383.46878   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 490         |
|    time_elapsed         | 27396       |
|    total_timesteps      | 2007040     |
| train/                  |             |
|    approx_kl            | 0.032571536 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.88        |
|    explained_variance   | 0.908       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00964    |
|    n_updates            | 4890        |
|    policy_gradient_loss | -0.00952    |
|    std                  | 0.197       |
|    value_loss           | 0.0511      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.647       |
|    cost_of_transport    | 180         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.45        |
|    speed_penalty        | 0.00982     |
| time/                   |             |
|    total timesteps      | 2010000     |
| train/                  |             |
|    approx_kl            | 0.028243512 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.88        |
|    explained_variance   | 0.92        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0165      |
|    n_updates            | 4900        |
|    policy_gradient_loss | -0.00998    |
|    std                  | 0.197       |
|    value_loss           | 0.0375      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 389       |
|    ep_rew_mean     | 383.90668 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 491       |
|    time_elapsed    | 27469     |
|    total_timesteps | 2011136   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 385         |
|    ep_rew_mean          | 379.70685   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 492         |
|    time_elapsed         | 27514       |
|    total_timesteps      | 2015232     |
| train/                  |             |
|    approx_kl            | 0.029520892 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.88        |
|    explained_variance   | 0.906       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00727     |
|    n_updates            | 4910        |
|    policy_gradient_loss | -0.00513    |
|    std                  | 0.197       |
|    value_loss           | 0.041       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 384         |
|    ep_rew_mean          | 378.61194   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 493         |
|    time_elapsed         | 27558       |
|    total_timesteps      | 2019328     |
| train/                  |             |
|    approx_kl            | 0.032041088 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.87        |
|    explained_variance   | 0.877       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.05        |
|    n_updates            | 4920        |
|    policy_gradient_loss | -0.0115     |
|    std                  | 0.197       |
|    value_loss           | 0.0635      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.655       |
|    cost_of_transport    | 182         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.45        |
|    speed_penalty        | 0.0116      |
| time/                   |             |
|    total timesteps      | 2020000     |
| train/                  |             |
|    approx_kl            | 0.024347465 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.88        |
|    explained_variance   | 0.905       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00748    |
|    n_updates            | 4930        |
|    policy_gradient_loss | -0.00972    |
|    std                  | 0.196       |
|    value_loss           | 0.0439      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 384       |
|    ep_rew_mean     | 379.13184 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 494       |
|    time_elapsed    | 27631     |
|    total_timesteps | 2023424   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 384         |
|    ep_rew_mean          | 378.23813   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 495         |
|    time_elapsed         | 27674       |
|    total_timesteps      | 2027520     |
| train/                  |             |
|    approx_kl            | 0.029032107 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.89        |
|    explained_variance   | 0.899       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0207      |
|    n_updates            | 4940        |
|    policy_gradient_loss | -0.00777    |
|    std                  | 0.197       |
|    value_loss           | 0.0486      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.663       |
|    cost_of_transport    | 187         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.42        |
|    speed_penalty        | 0.0138      |
| time/                   |             |
|    total timesteps      | 2030000     |
| train/                  |             |
|    approx_kl            | 0.024974238 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.87        |
|    explained_variance   | 0.898       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0513      |
|    n_updates            | 4950        |
|    policy_gradient_loss | -0.00886    |
|    std                  | 0.197       |
|    value_loss           | 0.0513      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 382       |
|    ep_rew_mean     | 376.88745 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 496       |
|    time_elapsed    | 27745     |
|    total_timesteps | 2031616   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 380         |
|    ep_rew_mean          | 374.74084   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 497         |
|    time_elapsed         | 27790       |
|    total_timesteps      | 2035712     |
| train/                  |             |
|    approx_kl            | 0.026261922 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.86        |
|    explained_variance   | 0.916       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00711    |
|    n_updates            | 4960        |
|    policy_gradient_loss | -0.00778    |
|    std                  | 0.197       |
|    value_loss           | 0.0393      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 382         |
|    ep_rew_mean          | 375.9757    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 498         |
|    time_elapsed         | 27835       |
|    total_timesteps      | 2039808     |
| train/                  |             |
|    approx_kl            | 0.027477851 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.87        |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0658      |
|    n_updates            | 4970        |
|    policy_gradient_loss | -0.0084     |
|    std                  | 0.196       |
|    value_loss           | 0.0493      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.692       |
|    cost_of_transport    | 186         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.44        |
|    speed_penalty        | 0.0117      |
| time/                   |             |
|    total timesteps      | 2040000     |
| train/                  |             |
|    approx_kl            | 0.029047444 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.9         |
|    explained_variance   | 0.88        |
|    learning_rate        | 0.0001      |
|    loss                 | 0.035       |
|    n_updates            | 4980        |
|    policy_gradient_loss | -0.00638    |
|    std                  | 0.196       |
|    value_loss           | 0.0611      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 381       |
|    ep_rew_mean     | 374.74277 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 499       |
|    time_elapsed    | 27905     |
|    total_timesteps | 2043904   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 380         |
|    ep_rew_mean          | 374.2126    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 500         |
|    time_elapsed         | 27950       |
|    total_timesteps      | 2048000     |
| train/                  |             |
|    approx_kl            | 0.021834446 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.92        |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00512     |
|    n_updates            | 4990        |
|    policy_gradient_loss | -0.00719    |
|    std                  | 0.195       |
|    value_loss           | 0.0427      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.635       |
|    cost_of_transport    | 183         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.44        |
|    speed_penalty        | 0.0103      |
| time/                   |             |
|    total timesteps      | 2050000     |
| train/                  |             |
|    approx_kl            | 0.028119026 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.93        |
|    explained_variance   | 0.914       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00481     |
|    n_updates            | 5000        |
|    policy_gradient_loss | -0.0102     |
|    std                  | 0.195       |
|    value_loss           | 0.0432      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 383      |
|    ep_rew_mean     | 377.0878 |
| time/              |          |
|    fps             | 73       |
|    iterations      | 501      |
|    time_elapsed    | 28021    |
|    total_timesteps | 2052096  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 386         |
|    ep_rew_mean          | 380.3238    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 502         |
|    time_elapsed         | 28066       |
|    total_timesteps      | 2056192     |
| train/                  |             |
|    approx_kl            | 0.026976492 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.93        |
|    explained_variance   | 0.889       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0064      |
|    n_updates            | 5010        |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.195       |
|    value_loss           | 0.0519      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.655      |
|    cost_of_transport    | 193        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.44       |
|    speed_penalty        | 0.0103     |
| time/                   |            |
|    total timesteps      | 2060000    |
| train/                  |            |
|    approx_kl            | 0.02658587 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.95       |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0243    |
|    n_updates            | 5020       |
|    policy_gradient_loss | -0.00951   |
|    std                  | 0.195      |
|    value_loss           | 0.0355     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 386       |
|    ep_rew_mean     | 380.24442 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 503       |
|    time_elapsed    | 28138     |
|    total_timesteps | 2060288   |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 386        |
|    ep_rew_mean          | 380.07938  |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 504        |
|    time_elapsed         | 28182      |
|    total_timesteps      | 2064384    |
| train/                  |            |
|    approx_kl            | 0.02693585 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.97       |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0221     |
|    n_updates            | 5030       |
|    policy_gradient_loss | -0.00746   |
|    std                  | 0.194      |
|    value_loss           | 0.052      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 386         |
|    ep_rew_mean          | 380.3975    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 505         |
|    time_elapsed         | 28226       |
|    total_timesteps      | 2068480     |
| train/                  |             |
|    approx_kl            | 0.027070299 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.97        |
|    explained_variance   | 0.914       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0604      |
|    n_updates            | 5040        |
|    policy_gradient_loss | -0.0065     |
|    std                  | 0.195       |
|    value_loss           | 0.0488      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.675       |
|    cost_of_transport    | 183         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.43        |
|    speed_penalty        | 0.0134      |
| time/                   |             |
|    total timesteps      | 2070000     |
| train/                  |             |
|    approx_kl            | 0.031796567 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.95        |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0456      |
|    n_updates            | 5050        |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.195       |
|    value_loss           | 0.0412      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 389       |
|    ep_rew_mean     | 383.37796 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 506       |
|    time_elapsed    | 28297     |
|    total_timesteps | 2072576   |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 391        |
|    ep_rew_mean          | 385.7161   |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 507        |
|    time_elapsed         | 28341      |
|    total_timesteps      | 2076672    |
| train/                  |            |
|    approx_kl            | 0.02622233 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.94       |
|    explained_variance   | 0.9        |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0316     |
|    n_updates            | 5060       |
|    policy_gradient_loss | -0.00775   |
|    std                  | 0.195      |
|    value_loss           | 0.0508     |
----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.63        |
|    cost_of_transport    | 183         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.45        |
|    speed_penalty        | 0.00978     |
| time/                   |             |
|    total timesteps      | 2080000     |
| train/                  |             |
|    approx_kl            | 0.028604586 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.92        |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00209    |
|    n_updates            | 5070        |
|    policy_gradient_loss | -0.00681    |
|    std                  | 0.196       |
|    value_loss           | 0.0527      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 393       |
|    ep_rew_mean     | 387.26544 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 508       |
|    time_elapsed    | 28413     |
|    total_timesteps | 2080768   |
----------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 392        |
|    ep_rew_mean          | 386.36975  |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 509        |
|    time_elapsed         | 28458      |
|    total_timesteps      | 2084864    |
| train/                  |            |
|    approx_kl            | 0.02610121 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.9        |
|    explained_variance   | 0.904      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0353    |
|    n_updates            | 5080       |
|    policy_gradient_loss | -0.00625   |
|    std                  | 0.196      |
|    value_loss           | 0.0416     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 393         |
|    ep_rew_mean          | 387.36078   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 510         |
|    time_elapsed         | 28502       |
|    total_timesteps      | 2088960     |
| train/                  |             |
|    approx_kl            | 0.031278875 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.9         |
|    explained_variance   | 0.881       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0153      |
|    n_updates            | 5090        |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.196       |
|    value_loss           | 0.057       |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.63       |
|    cost_of_transport    | 187        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.44       |
|    speed_penalty        | 0.0112     |
| time/                   |            |
|    total timesteps      | 2090000    |
| train/                  |            |
|    approx_kl            | 0.02882007 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.9        |
|    explained_variance   | 0.887      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0279     |
|    n_updates            | 5100       |
|    policy_gradient_loss | -0.0107    |
|    std                  | 0.196      |
|    value_loss           | 0.0473     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 392       |
|    ep_rew_mean     | 386.53986 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 511       |
|    time_elapsed    | 28574     |
|    total_timesteps | 2093056   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 392         |
|    ep_rew_mean          | 386.40445   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 512         |
|    time_elapsed         | 28619       |
|    total_timesteps      | 2097152     |
| train/                  |             |
|    approx_kl            | 0.023379512 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.88        |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0206     |
|    n_updates            | 5110        |
|    policy_gradient_loss | -0.00707    |
|    std                  | 0.197       |
|    value_loss           | 0.035       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.63        |
|    cost_of_transport    | 186         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.39        |
|    speed_penalty        | 0.0164      |
| time/                   |             |
|    total timesteps      | 2100000     |
| train/                  |             |
|    approx_kl            | 0.027656756 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.86        |
|    explained_variance   | 0.883       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0124     |
|    n_updates            | 5120        |
|    policy_gradient_loss | -0.00806    |
|    std                  | 0.197       |
|    value_loss           | 0.0618      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 392       |
|    ep_rew_mean     | 386.47577 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 513       |
|    time_elapsed    | 28690     |
|    total_timesteps | 2101248   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 393         |
|    ep_rew_mean          | 387.81726   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 514         |
|    time_elapsed         | 28737       |
|    total_timesteps      | 2105344     |
| train/                  |             |
|    approx_kl            | 0.029863387 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.85        |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0155      |
|    n_updates            | 5130        |
|    policy_gradient_loss | -0.00962    |
|    std                  | 0.197       |
|    value_loss           | 0.0447      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 393        |
|    ep_rew_mean          | 387.73624  |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 515        |
|    time_elapsed         | 28783      |
|    total_timesteps      | 2109440    |
| train/                  |            |
|    approx_kl            | 0.02461505 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.86       |
|    explained_variance   | 0.892      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0681     |
|    n_updates            | 5140       |
|    policy_gradient_loss | -0.00978   |
|    std                  | 0.197      |
|    value_loss           | 0.0544     |
----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.654      |
|    cost_of_transport    | 187        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.41       |
|    speed_penalty        | 0.0142     |
| time/                   |            |
|    total timesteps      | 2110000    |
| train/                  |            |
|    approx_kl            | 0.02863633 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.87       |
|    explained_variance   | 0.896      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.00295    |
|    n_updates            | 5150       |
|    policy_gradient_loss | -0.00675   |
|    std                  | 0.197      |
|    value_loss           | 0.0539     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 393      |
|    ep_rew_mean     | 387.6477 |
| time/              |          |
|    fps             | 73       |
|    iterations      | 516      |
|    time_elapsed    | 28858    |
|    total_timesteps | 2113536  |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 391        |
|    ep_rew_mean          | 386.04855  |
| time/                   |            |
|    fps                  | 73         |
|    iterations           | 517        |
|    time_elapsed         | 28905      |
|    total_timesteps      | 2117632    |
| train/                  |            |
|    approx_kl            | 0.02372358 |
|    clip_fraction        | 0.286      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.86       |
|    explained_variance   | 0.904      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0437     |
|    n_updates            | 5160       |
|    policy_gradient_loss | -0.00988   |
|    std                  | 0.197      |
|    value_loss           | 0.0491     |
----------------------------------------
---------------------------------------
| eval/                   |           |
|    action_norm_penalty  | 0.639     |
|    cost_of_transport    | 191       |
|    mean_ep_length       | 400       |
|    mean_reward          | 2.98e+04  |
|    speed                | 1.42      |
|    speed_penalty        | 0.011     |
| time/                   |           |
|    total timesteps      | 2120000   |
| train/                  |           |
|    approx_kl            | 0.0265172 |
|    clip_fraction        | 0.313     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.85      |
|    explained_variance   | 0.916     |
|    learning_rate        | 0.0001    |
|    loss                 | -0.00121  |
|    n_updates            | 5170      |
|    policy_gradient_loss | -0.0102   |
|    std                  | 0.197     |
|    value_loss           | 0.0426    |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 392      |
|    ep_rew_mean     | 386.9012 |
| time/              |          |
|    fps             | 73       |
|    iterations      | 518      |
|    time_elapsed    | 28977    |
|    total_timesteps | 2121728  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 394         |
|    ep_rew_mean          | 388.3509    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 519         |
|    time_elapsed         | 29025       |
|    total_timesteps      | 2125824     |
| train/                  |             |
|    approx_kl            | 0.025937803 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.85        |
|    explained_variance   | 0.901       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00423     |
|    n_updates            | 5180        |
|    policy_gradient_loss | -0.0101     |
|    std                  | 0.197       |
|    value_loss           | 0.0549      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 394         |
|    ep_rew_mean          | 388.79874   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 520         |
|    time_elapsed         | 29072       |
|    total_timesteps      | 2129920     |
| train/                  |             |
|    approx_kl            | 0.028789777 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.86        |
|    explained_variance   | 0.899       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0147      |
|    n_updates            | 5190        |
|    policy_gradient_loss | -0.00856    |
|    std                  | 0.197       |
|    value_loss           | 0.0472      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.597       |
|    cost_of_transport    | 188         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.4         |
|    speed_penalty        | 0.016       |
| time/                   |             |
|    total timesteps      | 2130000     |
| train/                  |             |
|    approx_kl            | 0.025440145 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.87        |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0113      |
|    n_updates            | 5200        |
|    policy_gradient_loss | -0.00944    |
|    std                  | 0.197       |
|    value_loss           | 0.053       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 394       |
|    ep_rew_mean     | 388.98492 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 521       |
|    time_elapsed    | 29147     |
|    total_timesteps | 2134016   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 395         |
|    ep_rew_mean          | 389.58536   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 522         |
|    time_elapsed         | 29195       |
|    total_timesteps      | 2138112     |
| train/                  |             |
|    approx_kl            | 0.023060728 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.88        |
|    explained_variance   | 0.866       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0298      |
|    n_updates            | 5210        |
|    policy_gradient_loss | -0.00739    |
|    std                  | 0.197       |
|    value_loss           | 0.0678      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.608       |
|    cost_of_transport    | 188         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.42        |
|    speed_penalty        | 0.014       |
| time/                   |             |
|    total timesteps      | 2140000     |
| train/                  |             |
|    approx_kl            | 0.027893003 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.86        |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00662     |
|    n_updates            | 5220        |
|    policy_gradient_loss | -0.00924    |
|    std                  | 0.197       |
|    value_loss           | 0.047       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 393       |
|    ep_rew_mean     | 387.19855 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 523       |
|    time_elapsed    | 29271     |
|    total_timesteps | 2142208   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 392         |
|    ep_rew_mean          | 386.51788   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 524         |
|    time_elapsed         | 29316       |
|    total_timesteps      | 2146304     |
| train/                  |             |
|    approx_kl            | 0.028806478 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.85        |
|    explained_variance   | 0.888       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.0134     |
|    n_updates            | 5230        |
|    policy_gradient_loss | -0.00689    |
|    std                  | 0.197       |
|    value_loss           | 0.0589      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.612       |
|    cost_of_transport    | 188         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.41        |
|    speed_penalty        | 0.0162      |
| time/                   |             |
|    total timesteps      | 2150000     |
| train/                  |             |
|    approx_kl            | 0.023956684 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.85        |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.0001      |
|    loss                 | -0.00462    |
|    n_updates            | 5240        |
|    policy_gradient_loss | -0.00688    |
|    std                  | 0.197       |
|    value_loss           | 0.042       |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 392       |
|    ep_rew_mean     | 386.47797 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 525       |
|    time_elapsed    | 29391     |
|    total_timesteps | 2150400   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 392         |
|    ep_rew_mean          | 385.74188   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 526         |
|    time_elapsed         | 29437       |
|    total_timesteps      | 2154496     |
| train/                  |             |
|    approx_kl            | 0.031163193 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.84        |
|    explained_variance   | 0.906       |
|    learning_rate        | 0.0001      |
|    loss                 | -4.61e-05   |
|    n_updates            | 5250        |
|    policy_gradient_loss | -0.00792    |
|    std                  | 0.197       |
|    value_loss           | 0.047       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 393         |
|    ep_rew_mean          | 386.61932   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 527         |
|    time_elapsed         | 29483       |
|    total_timesteps      | 2158592     |
| train/                  |             |
|    approx_kl            | 0.029044287 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.84        |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00948     |
|    n_updates            | 5260        |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.197       |
|    value_loss           | 0.0572      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.63       |
|    cost_of_transport    | 198        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.39       |
|    speed_penalty        | 0.017      |
| time/                   |            |
|    total timesteps      | 2160000    |
| train/                  |            |
|    approx_kl            | 0.02603698 |
|    clip_fraction        | 0.279      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.85       |
|    explained_variance   | 0.915      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0244     |
|    n_updates            | 5270       |
|    policy_gradient_loss | -0.0095    |
|    std                  | 0.197      |
|    value_loss           | 0.0424     |
----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 391       |
|    ep_rew_mean     | 384.48325 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 528       |
|    time_elapsed    | 29558     |
|    total_timesteps | 2162688   |
----------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 391       |
|    ep_rew_mean          | 384.19833 |
| time/                   |           |
|    fps                  | 73        |
|    iterations           | 529       |
|    time_elapsed         | 29604     |
|    total_timesteps      | 2166784   |
| train/                  |           |
|    approx_kl            | 0.0245461 |
|    clip_fraction        | 0.284     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.85      |
|    explained_variance   | 0.896     |
|    learning_rate        | 0.0001    |
|    loss                 | 0.0195    |
|    n_updates            | 5280      |
|    policy_gradient_loss | -0.00887  |
|    std                  | 0.197     |
|    value_loss           | 0.0589    |
---------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.631       |
|    cost_of_transport    | 187         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.4         |
|    speed_penalty        | 0.0173      |
| time/                   |             |
|    total timesteps      | 2170000     |
| train/                  |             |
|    approx_kl            | 0.025207695 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.85        |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0451      |
|    n_updates            | 5290        |
|    policy_gradient_loss | -0.00663    |
|    std                  | 0.197       |
|    value_loss           | 0.0551      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 390       |
|    ep_rew_mean     | 383.61026 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 530       |
|    time_elapsed    | 29679     |
|    total_timesteps | 2170880   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 392         |
|    ep_rew_mean          | 385.1029    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 531         |
|    time_elapsed         | 29725       |
|    total_timesteps      | 2174976     |
| train/                  |             |
|    approx_kl            | 0.029265389 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.86        |
|    explained_variance   | 0.927       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.000757    |
|    n_updates            | 5300        |
|    policy_gradient_loss | -0.00894    |
|    std                  | 0.197       |
|    value_loss           | 0.0327      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 391         |
|    ep_rew_mean          | 384.3103    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 532         |
|    time_elapsed         | 29770       |
|    total_timesteps      | 2179072     |
| train/                  |             |
|    approx_kl            | 0.027387751 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.86        |
|    explained_variance   | 0.894       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00484     |
|    n_updates            | 5310        |
|    policy_gradient_loss | -0.0092     |
|    std                  | 0.197       |
|    value_loss           | 0.0543      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.653       |
|    cost_of_transport    | 195         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.37        |
|    speed_penalty        | 0.0244      |
| time/                   |             |
|    total timesteps      | 2180000     |
| train/                  |             |
|    approx_kl            | 0.027000297 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.85        |
|    explained_variance   | 0.907       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0155      |
|    n_updates            | 5320        |
|    policy_gradient_loss | -0.00874    |
|    std                  | 0.197       |
|    value_loss           | 0.0438      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 393       |
|    ep_rew_mean     | 385.98077 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 533       |
|    time_elapsed    | 29845     |
|    total_timesteps | 2183168   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 393         |
|    ep_rew_mean          | 385.7881    |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 534         |
|    time_elapsed         | 29892       |
|    total_timesteps      | 2187264     |
| train/                  |             |
|    approx_kl            | 0.027788538 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.86        |
|    explained_variance   | 0.918       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00258     |
|    n_updates            | 5330        |
|    policy_gradient_loss | -0.00883    |
|    std                  | 0.197       |
|    value_loss           | 0.035       |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.647       |
|    cost_of_transport    | 190         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.4         |
|    speed_penalty        | 0.0181      |
| time/                   |             |
|    total timesteps      | 2190000     |
| train/                  |             |
|    approx_kl            | 0.025468498 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.84        |
|    explained_variance   | 0.905       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0458      |
|    n_updates            | 5340        |
|    policy_gradient_loss | -0.00612    |
|    std                  | 0.198       |
|    value_loss           | 0.0557      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 391      |
|    ep_rew_mean     | 384.4118 |
| time/              |          |
|    fps             | 73       |
|    iterations      | 535      |
|    time_elapsed    | 29964    |
|    total_timesteps | 2191360  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 392         |
|    ep_rew_mean          | 385.445     |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 536         |
|    time_elapsed         | 30011       |
|    total_timesteps      | 2195456     |
| train/                  |             |
|    approx_kl            | 0.024849124 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.83        |
|    explained_variance   | 0.907       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00455     |
|    n_updates            | 5350        |
|    policy_gradient_loss | -0.0118     |
|    std                  | 0.197       |
|    value_loss           | 0.0389      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 392         |
|    ep_rew_mean          | 385.323     |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 537         |
|    time_elapsed         | 30057       |
|    total_timesteps      | 2199552     |
| train/                  |             |
|    approx_kl            | 0.027808331 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.84        |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0171      |
|    n_updates            | 5360        |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.197       |
|    value_loss           | 0.0526      |
-----------------------------------------
-----------------------------------------
| eval/                   |             |
|    action_norm_penalty  | 0.626       |
|    cost_of_transport    | 185         |
|    mean_ep_length       | 400         |
|    mean_reward          | 2.98e+04    |
|    speed                | 1.39        |
|    speed_penalty        | 0.0195      |
| time/                   |             |
|    total timesteps      | 2200000     |
| train/                  |             |
|    approx_kl            | 0.023985926 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.84        |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0382      |
|    n_updates            | 5370        |
|    policy_gradient_loss | -0.00935    |
|    std                  | 0.197       |
|    value_loss           | 0.0505      |
-----------------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 390       |
|    ep_rew_mean     | 383.59204 |
| time/              |           |
|    fps             | 73        |
|    iterations      | 538       |
|    time_elapsed    | 30131     |
|    total_timesteps | 2203648   |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 390         |
|    ep_rew_mean          | 382.50586   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 539         |
|    time_elapsed         | 30178       |
|    total_timesteps      | 2207744     |
| train/                  |             |
|    approx_kl            | 0.034844212 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.83        |
|    explained_variance   | 0.884       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.00873     |
|    n_updates            | 5380        |
|    policy_gradient_loss | -0.00973    |
|    std                  | 0.198       |
|    value_loss           | 0.0553      |
-----------------------------------------
----------------------------------------
| eval/                   |            |
|    action_norm_penalty  | 0.615      |
|    cost_of_transport    | 195        |
|    mean_ep_length       | 400        |
|    mean_reward          | 2.98e+04   |
|    speed                | 1.38       |
|    speed_penalty        | 0.0194     |
| time/                   |            |
|    total timesteps      | 2210000    |
| train/                  |            |
|    approx_kl            | 0.02419581 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.83       |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.0001     |
|    loss                 | 0.0025     |
|    n_updates            | 5390       |
|    policy_gradient_loss | -0.0104    |
|    std                  | 0.197      |
|    value_loss           | 0.0416     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 389      |
|    ep_rew_mean     | 382.3    |
| time/              |          |
|    fps             | 73       |
|    iterations      | 540      |
|    time_elapsed    | 30251    |
|    total_timesteps | 2211840  |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 388         |
|    ep_rew_mean          | 380.97665   |
| time/                   |             |
|    fps                  | 73          |
|    iterations           | 541         |
|    time_elapsed         | 30296       |
|    total_timesteps      | 2215936     |
| train/                  |             |
|    approx_kl            | 0.026422402 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.85        |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.0001      |
|    loss                 | 0.0128      |
|    n_updates            | 5400        |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.197       |
|    value_loss           | 0.0511      |
-----------------------------------------
